--- a/src/java/org/apache/cassandra/db/ReadCommand.java
+++ b/src/java/org/apache/cassandra/db/ReadCommand.java
@@ -383,21 +383,8 @@
             Tracing.trace("Executing read on {}.{} using index {}", cfs.metadata.keyspace, cfs.metadata.name, index.getIndexMetadata().name);
         }
 
-<<<<<<<
-        UnfilteredPartitionIterator iterator = (null == searcher) ? queryStorage(cfs, executionController) : searcher.search(executionController);
-=======
-        if (isTrackingRepairedStatus())
-        {
-            final DataLimits.Counter repairedReadCount = limits().newCounter(nowInSec(),
-                                                                             false,
-                                                                             selectsFullPartition(),
-                                                                             metadata().enforceStrictLiveness()).onlyCount();
-            repairedDataInfo = new RepairedDataInfo(repairedReadCount);
-        }
-
         UnfilteredPartitionIterator iterator = (null == searcher) ? queryStorage(cfs, executionController)
                                                                   : searchStorage(searcher, executionController);
->>>>>>>
         iterator = RTBoundValidator.validate(iterator, Stage.MERGED, false);
 
         try
--- a/src/java/org/apache/cassandra/service/reads/range/RangeCommandIterator.java
+++ b/src/java/org/apache/cassandra/service/reads/range/RangeCommandIterator.java
@@ -188,89 +188,7 @@
         return concurrencyFactor;
     }
 
-<<<<<<<
-    /**
-     * Queries the provided sub-range.
-     *
-     * @param replicaPlan the subRange to query.
-     * @param isFirst in the case where multiple queries are sent in parallel, whether that's the first query on
-     * that batch or not. The reason it matters is that whe paging queries, the command (more specifically the
-     * {@code DataLimits}) may have "state" information and that state may only be valid for the first query (in
-     * that it's the query that "continues" whatever we're previously queried).
-     */
-    private SingleRangeResponse query(ReplicaPlan.ForRangeRead replicaPlan, boolean isFirst)
-    {
-        PartitionRangeReadCommand rangeCommand = command.forSubRange(replicaPlan.range(), isFirst);
-        
-        // If enabled, request repaired data tracking info from full replicas, but
-        // only if there are multiple full replicas to compare results from.
-        boolean trackRepairedStatus = DatabaseDescriptor.getRepairedDataTrackingForRangeReadsEnabled()
-                                      && replicaPlan.contacts().filter(Replica::isFull).size() > 1;
-
-        ReplicaPlan.SharedForRangeRead sharedReplicaPlan = ReplicaPlan.shared(replicaPlan);
-        ReadRepair<EndpointsForRange, ReplicaPlan.ForRangeRead> readRepair =
-                ReadRepair.create(command, sharedReplicaPlan, queryStartNanoTime);
-        DataResolver<EndpointsForRange, ReplicaPlan.ForRangeRead> resolver =
-                new DataResolver<>(rangeCommand, sharedReplicaPlan, readRepair, queryStartNanoTime, trackRepairedStatus);
-        ReadCallback<EndpointsForRange, ReplicaPlan.ForRangeRead> handler =
-                new ReadCallback<>(resolver, rangeCommand, sharedReplicaPlan, queryStartNanoTime);
-
-        if (replicaPlan.contacts().size() == 1 && replicaPlan.contacts().get(0).isSelf())
-        {
-            Stage.READ.execute(new StorageProxy.LocalReadRunnable(rangeCommand, handler, trackRepairedStatus));
-        }
-        else
-        {
-            for (Replica replica : replicaPlan.contacts())
-            {
-                Tracing.trace("Enqueuing request to {}", replica);
-                ReadCommand command = replica.isFull() ? rangeCommand : rangeCommand.copyAsTransientQuery(replica);
-                Message<ReadCommand> message = command.createMessage(trackRepairedStatus && replica.isFull());
-                MessagingService.instance().sendWithCallback(message, replica.endpoint(), handler);
-            }
-        }
-
-        return new SingleRangeResponse(resolver, handler, readRepair);
-    }
-
-    private PartitionIterator sendNextRequests()
-    {
-        List<PartitionIterator> concurrentQueries = new ArrayList<>(concurrencyFactor);
-        List<ReadRepair<?, ?>> readRepairs = new ArrayList<>(concurrencyFactor);
-
-        try
-        {
-            for (int i = 0; i < concurrencyFactor && replicaPlans.hasNext(); )
-            {
-                ReplicaPlan.ForRangeRead replicaPlan = replicaPlans.next();
-
-                @SuppressWarnings("resource") // response will be closed by concatAndBlockOnRepair, or in the catch block below
-                SingleRangeResponse response = query(replicaPlan, i == 0);
-                concurrentQueries.add(response);
-                readRepairs.add(response.getReadRepair());
-                // due to RangeMerger, coordinator may fetch more ranges than required by concurrency factor.
-                rangesQueried += replicaPlan.vnodeCount();
-                i += replicaPlan.vnodeCount();
-            }
-            batchesRequested++;
-        }
-        catch (Throwable t)
-        {
-            for (PartitionIterator response : concurrentQueries)
-                response.close();
-            throw t;
-        }
-
-        Tracing.trace("Submitted {} concurrent range requests", concurrentQueries.size());
-        // We want to count the results for the sake of updating the concurrency factor (see updateConcurrencyFactor)
-        // but we don't want to enforce any particular limit at this point (this could break code than rely on
-        // postReconciliationProcessing), hence the DataLimits.NONE.
-        counter = DataLimits.NONE.newCounter(command.nowInSec(), true, command.selectsFullPartition(), enforceStrictLiveness);
-        return counter.applyTo(StorageProxy.concatAndBlockOnRepair(concurrentQueries, readRepairs));
-    }
-=======
     protected abstract PartitionIterator sendNextRequests();
->>>>>>>
 
     @Override
     public void close()
