--- a/src/java/org/apache/cassandra/auth/AuthSchemaChangeListener.java
+++ b/src/java/org/apache/cassandra/auth/AuthSchemaChangeListener.java
@@ -30,25 +30,15 @@
 public class AuthSchemaChangeListener implements SchemaChangeListener
 {
     @Override
-<<<<<<<
-    public void onDropKeyspace(KeyspaceMetadata keyspace)
-    {
-        DatabaseDescriptor.getAuthorizer().revokeAllOn(DataResource.keyspace(keyspace.name));
-=======
     public void onDropKeyspace(KeyspaceMetadata keyspace, boolean dropData)
     {
         DatabaseDescriptor.getAuthorizer().revokeAllOn(DataResource.keyspace(keyspace.name));
         DatabaseDescriptor.getAuthorizer().revokeAllOn(DataResource.allTables(keyspace.name));
->>>>>>>
         DatabaseDescriptor.getAuthorizer().revokeAllOn(FunctionResource.keyspace(keyspace.name));
     }
 
     @Override
-<<<<<<<
-    public void onDropTable(TableMetadata table)
-=======
     public void onDropTable(TableMetadata table, boolean dropData)
->>>>>>>
     {
         DatabaseDescriptor.getAuthorizer().revokeAllOn(DataResource.table(table.keyspace, table.name));
     }
--- a/src/java/org/apache/cassandra/cache/AutoSavingCache.java
+++ b/src/java/org/apache/cassandra/cache/AutoSavingCache.java
@@ -17,21 +17,6 @@
  */
 package org.apache.cassandra.cache;
 
-<<<<<<<
-import java.io.BufferedInputStream;
-import java.io.File;
-import java.io.FileNotFoundException;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.OutputStream;
-import java.util.ArrayDeque;
-import java.util.Iterator;
-import java.util.Set;
-import java.util.UUID;
-import java.util.concurrent.Callable;
-import java.util.concurrent.Executors;
-import java.util.concurrent.Future;
-=======
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.nio.file.NoSuchFileException;
@@ -40,22 +25,15 @@
 import java.util.LinkedHashMap;
 import java.util.Set;
 import java.util.UUID;
->>>>>>>
 import java.util.concurrent.ScheduledFuture;
 import java.util.concurrent.TimeUnit;
 import javax.annotation.concurrent.NotThreadSafe;
 
-import com.google.common.util.concurrent.ListenableFuture;
-import com.google.common.util.concurrent.ListeningExecutorService;
-import com.google.common.util.concurrent.MoreExecutors;
 import org.cliffc.high_scale_lib.NonBlockingHashSet;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-<<<<<<<
-=======
 import org.apache.cassandra.concurrent.ExecutorPlus;
->>>>>>>
 import org.apache.cassandra.concurrent.ScheduledExecutors;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.ColumnFamilyStore;
@@ -70,16 +48,11 @@
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.DataInputPlus.DataInputStreamPlus;
 import org.apache.cassandra.io.util.DataOutputPlus;
-<<<<<<<
 import org.apache.cassandra.io.util.DataOutputStreamPlus;
 import org.apache.cassandra.io.util.File;
 import org.apache.cassandra.io.util.FileInputStreamPlus;
 import org.apache.cassandra.io.util.FileOutputStreamPlus;
 import org.apache.cassandra.io.util.FileUtils;
-=======
-import org.apache.cassandra.io.util.FileUtils;
-import org.apache.cassandra.io.util.LengthAvailableInputStream;
->>>>>>>
 import org.apache.cassandra.io.util.SequentialWriterOption;
 import org.apache.cassandra.io.util.WrappedDataOutputStreamPlus;
 import org.apache.cassandra.schema.Schema;
--- a/src/java/org/apache/cassandra/config/CassandraRelevantProperties.java
+++ b/src/java/org/apache/cassandra/config/CassandraRelevantProperties.java
@@ -152,20 +152,7 @@
      * A comma-delimited list of SSL/TLS cipher suites to enable.
      * Used in conjunction with com.sun.management.jmxremote.ssl - com.sun.management.jmxremote.ssl.enabled.cipher.suites
      */
-<<<<<<<
-    COM_SUN_MANAGEMENT_JMXREMOTE_SSL_ENABLED_CIPHER_SUITES ("com.sun.management.jmxremote.ssl.enabled.cipher.suites"),
-
-    /** mx4jaddress */
-    MX4JADDRESS ("mx4jaddress"),
-
-    /** mx4jport */
-    MX4JPORT ("mx4jport"),
-
-    RING_DELAY("cassandra.ring_delay_ms", "30000"),
-
-=======
     COM_SUN_MANAGEMENT_JMXREMOTE_SSL_ENABLED_CIPHER_SUITES("com.sun.management.jmxremote.ssl.enabled.cipher.suites"),
->>>>>>>
     /**
      * A comma-delimited list of SSL/TLS protocol versions to enable.
      * Used in conjunction with com.sun.management.jmxremote.ssl - com.sun.management.jmxremote.ssl.enabled.protocols
@@ -858,29 +845,6 @@
     }
 
     /**
-<<<<<<<
-     * Gets the value of a system property as a long.
-     * @return system property long value if it exists, defaultValue otherwise.
-     */
-    public long getLong()
-    {
-        String value = System.getProperty(key);
-
-        return LONG_CONVERTER.convert(value == null ? defaultVal : value);
-    }
-
-    /**
-     * Gets the value of a system property as a long.
-     * @return system property long value if it exists, overrideDefaultValue otherwise.
-     */
-    public long getLong(int overrideDefaultValue)
-    {
-        String value = System.getProperty(key);
-        if (value == null)
-            return overrideDefaultValue;
-
-        return LONG_CONVERTER.convert(value);
-=======
      * Sets the value into system properties.
      * @param value to set
      * @return Previous value or null if it did not have one.
@@ -932,28 +896,18 @@
     {
         String value = System.getProperty(key, defaultVal);
         return Enum.valueOf(enumClass, toUppercase ? value.toUpperCase() : value);
->>>>>>>
     }
 
     /**
      * Sets the value into system properties.
      * @param value to set
      */
-<<<<<<<
     public void setEnum(Enum<?> value)
     {
         System.setProperty(key, value.name());
     }
 
     public interface PropertyConverter<T>
-=======
-    public void setLong(long value)
-    {
-        System.setProperty(key, Long.toString(value));
-    }
-
-    private interface PropertyConverter<T>
->>>>>>>
     {
         T convert(String value);
     }
@@ -984,9 +938,6 @@
         catch (NumberFormatException e)
         {
             throw new ConfigurationException(String.format("Invalid value for system property: " +
-<<<<<<<
-                                                           "expected integer value but got '%s'", value));
-=======
                                                            "expected long value but got '%s'", value));
         }
     };
@@ -1014,7 +965,6 @@
         {
             throw new ConfigurationException(String.format("Invalid value for system property: " +
                                                            "expected floating point value but got '%s'", value));
->>>>>>>
         }
     };
 
--- a/src/java/org/apache/cassandra/cql3/QueryProcessor.java
+++ b/src/java/org/apache/cassandra/cql3/QueryProcessor.java
@@ -30,6 +30,8 @@
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.stream.Collectors;
 
+import com.github.benmanes.caffeine.cache.Cache;
+import com.github.benmanes.caffeine.cache.Caffeine;
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.base.Predicate;
 import com.google.common.collect.Iterables;
@@ -38,37 +40,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-<<<<<<<
-import com.github.benmanes.caffeine.cache.Cache;
-import com.github.benmanes.caffeine.cache.Caffeine;
-import org.antlr.runtime.RecognitionException;
-import org.apache.cassandra.concurrent.ScheduledExecutors;
-import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.cql3.functions.Function;
-import org.apache.cassandra.cql3.functions.FunctionName;
-import org.apache.cassandra.cql3.functions.UDAggregate;
-import org.apache.cassandra.cql3.functions.UDFunction;
-import org.apache.cassandra.cql3.statements.BatchStatement;
-import org.apache.cassandra.cql3.statements.ModificationStatement;
-import org.apache.cassandra.cql3.statements.QualifiedStatement;
-import org.apache.cassandra.cql3.statements.SelectStatement;
-import org.apache.cassandra.db.ConsistencyLevel;
-import org.apache.cassandra.db.SystemKeyspace;
-import org.apache.cassandra.db.marshal.AbstractType;
-import org.apache.cassandra.db.partitions.PartitionIterator;
-import org.apache.cassandra.db.partitions.PartitionIterators;
-import org.apache.cassandra.db.rows.RowIterator;
-import org.apache.cassandra.exceptions.CassandraException;
-import org.apache.cassandra.exceptions.InvalidRequestException;
-import org.apache.cassandra.exceptions.IsBootstrappingException;
-import org.apache.cassandra.exceptions.RequestExecutionException;
-import org.apache.cassandra.exceptions.RequestValidationException;
-import org.apache.cassandra.exceptions.SyntaxException;
-import org.apache.cassandra.gms.Gossiper;
-import org.apache.cassandra.metrics.CQLMetrics;
-import org.apache.cassandra.metrics.ClientRequestMetrics;
-import org.apache.cassandra.metrics.ClientRequestsMetricsHolder;
-=======
 import org.antlr.runtime.*;
 import org.apache.cassandra.concurrent.ImmediateExecutor;
 import org.apache.cassandra.concurrent.ScheduledExecutors;
@@ -79,13 +50,11 @@
 import org.apache.cassandra.metrics.ClientRequestsMetricsHolder;
 import org.apache.cassandra.net.Message;
 import org.apache.cassandra.net.MessagingService;
->>>>>>>
 import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.SchemaChangeListener;
 import org.apache.cassandra.schema.SchemaConstants;
 import org.apache.cassandra.schema.TableMetadata;
-<<<<<<<
 import org.apache.cassandra.cql3.functions.UDAggregate;
 import org.apache.cassandra.cql3.functions.UDFunction;
 import org.apache.cassandra.cql3.functions.Function;
@@ -102,27 +71,13 @@
 import org.apache.cassandra.gms.Gossiper;
 import org.apache.cassandra.metrics.CQLMetrics;
 import org.apache.cassandra.service.*;
-=======
-import org.apache.cassandra.service.ClientState;
-import org.apache.cassandra.service.QueryState;
-import org.apache.cassandra.service.StorageService;
->>>>>>>
 import org.apache.cassandra.service.pager.QueryPager;
 import org.apache.cassandra.tracing.Tracing;
 import org.apache.cassandra.transport.ProtocolVersion;
 import org.apache.cassandra.transport.messages.ResultMessage;
-<<<<<<<
 import org.apache.cassandra.utils.*;
 import org.apache.cassandra.utils.concurrent.Future;
 import org.apache.cassandra.utils.concurrent.FutureCombiner;
-=======
-import org.apache.cassandra.utils.ByteBufferUtil;
-import org.apache.cassandra.utils.CassandraVersion;
-import org.apache.cassandra.utils.FBUtilities;
-import org.apache.cassandra.utils.JVMStabilityInspector;
-import org.apache.cassandra.utils.MD5Digest;
-import org.apache.cassandra.utils.ObjectSizes;
->>>>>>>
 
 import static org.apache.cassandra.config.CassandraRelevantProperties.ENABLE_NODELOCAL_QUERIES;
 import static org.apache.cassandra.cql3.statements.RequestValidations.checkTrue;
@@ -1103,22 +1058,14 @@
         }
 
         @Override
-<<<<<<<
-        public void onDropKeyspace(KeyspaceMetadata keyspace)
-=======
         public void onDropKeyspace(KeyspaceMetadata keyspace, boolean dropData)
->>>>>>>
         {
             logger.trace("Keyspace {} was dropped, invalidating related prepared statements", keyspace.name);
             removeInvalidPreparedStatements(keyspace.name, null);
         }
 
         @Override
-<<<<<<<
-        public void onDropTable(TableMetadata table)
-=======
         public void onDropTable(TableMetadata table, boolean dropData)
->>>>>>>
         {
             logger.trace("Table {}.{} was dropped, invalidating related prepared statements", table.keyspace, table.name);
             removeInvalidPreparedStatements(table.keyspace, table.name);
--- a/src/java/org/apache/cassandra/cql3/statements/schema/AlterTableStatement.java
+++ b/src/java/org/apache/cassandra/cql3/statements/schema/AlterTableStatement.java
@@ -87,8 +87,6 @@
         this.ifExists = ifExists;
     }
 
-<<<<<<<
-=======
     @Override
     public void validate(ClientState state)
     {
@@ -98,7 +96,6 @@
         this.state = state;
     }
 
->>>>>>>
     public Keyspaces apply(Keyspaces schema)
     {
         KeyspaceMetadata keyspace = schema.getNullable(keyspaceName);
--- a/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
+++ b/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
@@ -22,61 +22,32 @@
 import java.lang.reflect.Constructor;
 import java.lang.reflect.InvocationTargetException;
 import java.nio.ByteBuffer;
-<<<<<<<
-import java.nio.file.Files;
-=======
 import java.time.Instant;
->>>>>>>
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
-<<<<<<<
 import java.util.Comparator;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.LinkedHashSet;
-=======
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
->>>>>>>
 import java.util.List;
 import java.util.Map;
 import java.util.Objects;
 import java.util.Set;
-<<<<<<<
-import java.util.UUID;
-import java.util.concurrent.Callable;
-import java.util.concurrent.CompletableFuture;
-import java.util.concurrent.CountDownLatch;
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
-import java.util.concurrent.Future;
-import java.util.concurrent.LinkedBlockingQueue;
-import java.util.concurrent.ThreadPoolExecutor;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.TimeoutException;
-import java.util.concurrent.atomic.AtomicInteger;
-=======
 import java.util.concurrent.Callable;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
->>>>>>>
 import java.util.concurrent.atomic.AtomicReference;
 import java.util.function.Consumer;
 import java.util.function.Supplier;
 import java.util.regex.Pattern;
-<<<<<<<
-=======
 import java.util.stream.Collectors;
->>>>>>>
 import javax.management.MalformedObjectNameException;
 import javax.management.ObjectName;
 import javax.management.openmbean.CompositeData;
@@ -91,21 +62,12 @@
 import com.google.common.base.Joiner;
 import com.google.common.base.Predicate;
 import com.google.common.base.Predicates;
-<<<<<<<
-=======
 import com.google.common.base.Strings;
->>>>>>>
 import com.google.common.base.Throwables;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Iterables;
 import com.google.common.collect.Lists;
 import com.google.common.collect.Sets;
-<<<<<<<
-=======
-import com.google.common.util.concurrent.ListenableFuture;
-import com.google.common.util.concurrent.ListenableFutureTask;
-import com.google.common.util.concurrent.MoreExecutors;
->>>>>>>
 import com.google.common.util.concurrent.RateLimiter;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -114,7 +76,6 @@
 import org.apache.cassandra.cache.IRowCacheEntry;
 import org.apache.cassandra.cache.RowCacheKey;
 import org.apache.cassandra.cache.RowCacheSentinel;
-<<<<<<<
 import org.apache.cassandra.concurrent.ExecutorPlus;
 import org.apache.cassandra.concurrent.FutureTask;
 import org.apache.cassandra.config.DatabaseDescriptor;
@@ -127,20 +88,6 @@
 import org.apache.cassandra.db.compaction.CompactionManager;
 import org.apache.cassandra.db.compaction.CompactionStrategyManager;
 import org.apache.cassandra.db.compaction.OperationType;
-=======
-import org.apache.cassandra.concurrent.JMXEnabledThreadPoolExecutor;
-import org.apache.cassandra.concurrent.NamedThreadFactory;
-import org.apache.cassandra.concurrent.ScheduledExecutors;
-import org.apache.cassandra.concurrent.Stage;
-import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.db.commitlog.CommitLog;
-import org.apache.cassandra.db.commitlog.CommitLogPosition;
-import org.apache.cassandra.db.compaction.AbstractCompactionStrategy;
-import org.apache.cassandra.db.compaction.CompactionManager;
-import org.apache.cassandra.db.compaction.CompactionStrategyManager;
-import org.apache.cassandra.db.compaction.OperationType;
-import org.apache.cassandra.db.compaction.Verifier;
->>>>>>>
 import org.apache.cassandra.db.filter.ClusteringIndexFilter;
 import org.apache.cassandra.db.filter.DataLimits;
 import org.apache.cassandra.db.lifecycle.LifecycleNewTracker;
@@ -148,12 +95,9 @@
 import org.apache.cassandra.db.lifecycle.SSTableSet;
 import org.apache.cassandra.db.lifecycle.Tracker;
 import org.apache.cassandra.db.lifecycle.View;
-<<<<<<<
-=======
 import org.apache.cassandra.db.memtable.Flushing;
 import org.apache.cassandra.db.memtable.Memtable;
 import org.apache.cassandra.db.memtable.ShardBoundaries;
->>>>>>>
 import org.apache.cassandra.db.partitions.CachedPartition;
 import org.apache.cassandra.db.partitions.PartitionUpdate;
 import org.apache.cassandra.db.repair.CassandraTableRepairManager;
@@ -164,10 +108,7 @@
 import org.apache.cassandra.dht.Bounds;
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.Range;
-<<<<<<<
-=======
 import org.apache.cassandra.dht.Splitter;
->>>>>>>
 import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.exceptions.StartupException;
@@ -185,18 +126,11 @@
 import org.apache.cassandra.io.sstable.SSTableIdFactory;
 import org.apache.cassandra.io.sstable.SSTableMultiWriter;
 import org.apache.cassandra.io.sstable.format.SSTableFormat;
-<<<<<<<
 import org.apache.cassandra.io.sstable.format.SSTableFormat.Components;
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.io.sstable.format.Version;
 import org.apache.cassandra.io.util.File;
 import org.apache.cassandra.io.util.FileOutputStreamPlus;
-=======
-import org.apache.cassandra.io.sstable.format.SSTableReader;
-import org.apache.cassandra.io.sstable.format.Version;
-import org.apache.cassandra.io.sstable.metadata.MetadataCollector;
-import org.apache.cassandra.io.util.FileUtils;
->>>>>>>
 import org.apache.cassandra.metrics.Sampler;
 import org.apache.cassandra.metrics.Sampler.Sample;
 import org.apache.cassandra.metrics.Sampler.SamplerType;
@@ -231,7 +165,6 @@
 import org.apache.cassandra.utils.ExecutorUtils;
 import org.apache.cassandra.utils.FBUtilities;
 import org.apache.cassandra.utils.JVMStabilityInspector;
-<<<<<<<
 import org.apache.cassandra.utils.JsonUtils;
 import org.apache.cassandra.utils.MBeanWrapper;
 import org.apache.cassandra.utils.NoSpamLogger;
@@ -250,18 +183,6 @@
 import static org.apache.cassandra.utils.Clock.Global.currentTimeMillis;
 import static org.apache.cassandra.utils.Clock.Global.nanoTime;
 import static org.apache.cassandra.utils.FBUtilities.now;
-=======
-import org.apache.cassandra.utils.MBeanWrapper;
-import org.apache.cassandra.utils.NoSpamLogger;
-import org.apache.cassandra.utils.WrappedRunnable;
-import org.apache.cassandra.utils.concurrent.OpOrder;
-import org.apache.cassandra.utils.concurrent.Refs;
-import org.apache.cassandra.utils.memory.MemtableAllocator;
-import org.json.simple.JSONArray;
-import org.json.simple.JSONObject;
-
-import static java.util.concurrent.TimeUnit.NANOSECONDS;
->>>>>>>
 import static org.apache.cassandra.utils.Throwables.maybeFail;
 import static org.apache.cassandra.utils.Throwables.merge;
 import static org.apache.cassandra.utils.concurrent.CountDownLatch.newCountDownLatch;
--- a/src/java/org/apache/cassandra/db/Keyspace.java
+++ b/src/java/org/apache/cassandra/db/Keyspace.java
@@ -145,17 +145,6 @@
         }
     }
 
-    /**
-     * Never use it in production code.
-     *
-     * Useful when creating a fake Schema so that it does not manage Keyspace instances (and CFS)
-     */
-    @VisibleForTesting
-    public static void unsetInitialized()
-    {
-        initialized = false;
-    }
-
     public static Keyspace open(String keyspaceName)
     {
         assert initialized || SchemaConstants.isLocalSystemKeyspace(keyspaceName) : "Initialized: " + initialized;
@@ -408,11 +397,7 @@
     // disassociate a cfs from this keyspace instance.
     private void unloadCf(ColumnFamilyStore cfs, boolean dropData)
     {
-<<<<<<<
-        cfs.forceBlockingFlush();
-=======
         cfs.unloadCf();
->>>>>>>
         cfs.invalidate(true, dropData);
     }
 
--- a/src/java/org/apache/cassandra/db/SchemaCQLHelper.java
+++ b/src/java/org/apache/cassandra/db/SchemaCQLHelper.java
@@ -50,44 +50,10 @@
         // Types come first, as table can't be created without them
         Stream<String> udts = SchemaCQLHelper.getUserTypesAsCQL(metadata, keyspaceMetadata.types, true);
 
-<<<<<<<
         Stream<String> tableMatadata = Stream.of(SchemaCQLHelper.getTableMetadataAsCQL(metadata, keyspaceMetadata));
 
         Stream<String> indexes = SchemaCQLHelper.getIndexesAsCQL(metadata, true);
         return Stream.of(udts, tableMatadata, indexes).flatMap(Function.identity());
-=======
-        return Stream.concat(udts,
-                             reCreateStatements(metadata,
-                                                true,
-                                                true,
-                                                true,
-                                                true,
-                                                keyspaceMetadata));
-    }
-
-    public static Stream<String> reCreateStatements(TableMetadata metadata,
-                                                    boolean includeDroppedColumns,
-                                                    boolean internals,
-                                                    boolean ifNotExists,
-                                                    boolean includeIndexes,
-                                                    KeyspaceMetadata keyspaceMetadata)
-    {
-        // Record re-create schema statements
-        Stream<String> r = Stream.of(metadata)
-                                         .map((tm) -> SchemaCQLHelper.getTableMetadataAsCQL(tm,
-                                                                                            includeDroppedColumns,
-                                                                                            internals,
-                                                                                            ifNotExists,
-                                                                                            keyspaceMetadata));
-
-        if (includeIndexes)
-        {
-            // Indexes applied as last, since otherwise they may interfere with column drops / re-additions
-            r = Stream.concat(r, SchemaCQLHelper.getIndexesAsCQL(metadata, ifNotExists));
-        }
-
-        return r;
->>>>>>>
     }
 
     /**
@@ -97,15 +63,7 @@
      * that will not contain everything needed for user types.
      */
     @VisibleForTesting
-<<<<<<<
-    public static String getTableMetadataAsCQL(TableMetadata metadata,
-                                               boolean includeDroppedColumns,
-                                               boolean internals,
-                                               boolean ifNotExists,
-                                               KeyspaceMetadata keyspaceMetadata)
-=======
     public static String getTableMetadataAsCQL(TableMetadata metadata, KeyspaceMetadata keyspaceMetadata)
->>>>>>>
     {
         if (metadata.isView())
         {
--- a/src/java/org/apache/cassandra/db/SizeEstimatesRecorder.java
+++ b/src/java/org/apache/cassandra/db/SizeEstimatesRecorder.java
@@ -181,11 +181,7 @@
     }
 
     @Override
-<<<<<<<
-    public void onDropTable(TableMetadata table)
-=======
     public void onDropTable(TableMetadata table, boolean dropData)
->>>>>>>
     {
         SystemKeyspace.clearEstimates(table.keyspace, table.name);
     }
--- a/src/java/org/apache/cassandra/db/commitlog/AbstractCommitLogSegmentManager.java
+++ b/src/java/org/apache/cassandra/db/commitlog/AbstractCommitLogSegmentManager.java
@@ -18,30 +18,13 @@
 package org.apache.cassandra.db.commitlog;
 
 import java.io.IOException;
-<<<<<<<
 import java.util.*;
 import java.util.concurrent.ConcurrentLinkedQueue;
-=======
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.concurrent.ConcurrentLinkedQueue;
-import java.util.concurrent.Future;
->>>>>>>
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicLong;
 import java.util.function.BooleanSupplier;
 
 import com.google.common.annotations.VisibleForTesting;
-<<<<<<<
-=======
-import com.google.common.util.concurrent.Futures;
-import com.google.common.util.concurrent.ListenableFuture;
-import com.google.common.util.concurrent.Uninterruptibles;
->>>>>>>
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -60,13 +43,8 @@
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.TableId;
 import org.apache.cassandra.schema.TableMetadata;
-<<<<<<<
 import org.apache.cassandra.utils.FBUtilities;
 import org.apache.cassandra.utils.concurrent.*;
-=======
-import org.apache.cassandra.utils.WrappedRunnable;
-import org.apache.cassandra.utils.concurrent.WaitQueue;
->>>>>>>
 
 import static org.apache.cassandra.concurrent.ExecutorFactory.Global.executorFactory;
 import static org.apache.cassandra.concurrent.InfiniteLoopExecutor.Daemon.NON_DAEMON;
--- a/src/java/org/apache/cassandra/dht/BootStrapper.java
+++ b/src/java/org/apache/cassandra/dht/BootStrapper.java
@@ -24,11 +24,7 @@
 import java.util.Set;
 import java.util.concurrent.atomic.AtomicInteger;
 
-<<<<<<<
-import com.google.common.util.concurrent.ListenableFuture;
-=======
 import org.apache.cassandra.utils.concurrent.Future;
->>>>>>>
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
--- a/src/java/org/apache/cassandra/gms/Gossiper.java
+++ b/src/java/org/apache/cassandra/gms/Gossiper.java
@@ -22,20 +22,14 @@
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
-<<<<<<<
-=======
 import java.util.Comparator;
->>>>>>>
 import java.util.EnumMap;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Map.Entry;
-<<<<<<<
-=======
 import java.util.Objects;
->>>>>>>
 import java.util.Random;
 import java.util.Set;
 import java.util.UUID;
@@ -64,14 +58,8 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-<<<<<<<
-import org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor;
-import org.apache.cassandra.concurrent.JMXEnabledSingleThreadExecutor;
-import org.apache.cassandra.concurrent.JMXEnabledThreadPoolExecutor;
-=======
 import org.apache.cassandra.concurrent.FutureTask;
 import org.apache.cassandra.concurrent.ScheduledExecutorPlus;
->>>>>>>
 import org.apache.cassandra.concurrent.Stage;
 import org.apache.cassandra.config.CassandraRelevantProperties;
 import org.apache.cassandra.config.DatabaseDescriptor;
--- a/src/java/org/apache/cassandra/index/SecondaryIndexManager.java
+++ b/src/java/org/apache/cassandra/index/SecondaryIndexManager.java
@@ -19,25 +19,8 @@
 
 import java.io.UncheckedIOException;
 import java.lang.reflect.Constructor;
-<<<<<<<
 import java.util.*;
 import java.util.concurrent.Callable;
-=======
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Objects;
-import java.util.Optional;
-import java.util.Set;
-import java.util.concurrent.Callable;
-import java.util.concurrent.Future;
-import java.util.concurrent.LinkedBlockingQueue;
->>>>>>>
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
 import java.util.concurrent.atomic.AtomicInteger;
@@ -58,14 +41,6 @@
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
 import com.google.common.util.concurrent.FutureCallback;
-<<<<<<<
-=======
-import com.google.common.util.concurrent.Futures;
-import com.google.common.util.concurrent.ListenableFuture;
-import com.google.common.util.concurrent.ListeningExecutorService;
-import com.google.common.util.concurrent.MoreExecutors;
-import com.google.common.util.concurrent.SettableFuture;
->>>>>>>
 import org.apache.commons.lang3.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -74,25 +49,7 @@
 import org.apache.cassandra.concurrent.FutureTask;
 import org.apache.cassandra.concurrent.ImmediateExecutor;
 import org.apache.cassandra.config.DatabaseDescriptor;
-<<<<<<<
-import org.apache.cassandra.cql3.statements.schema.IndexTarget;
-import org.apache.cassandra.db.Clustering;
-import org.apache.cassandra.db.ColumnFamilyStore;
-import org.apache.cassandra.db.DecoratedKey;
-import org.apache.cassandra.db.DeletionTime;
-import org.apache.cassandra.db.Directories;
-import org.apache.cassandra.db.Keyspace;
-import org.apache.cassandra.db.LivenessInfo;
-import org.apache.cassandra.db.MutableDeletionInfo;
-import org.apache.cassandra.db.RangeTombstone;
-import org.apache.cassandra.db.ReadExecutionController;
-import org.apache.cassandra.db.RegularAndStaticColumns;
-import org.apache.cassandra.db.SinglePartitionReadCommand;
-import org.apache.cassandra.db.SystemKeyspace;
-import org.apache.cassandra.db.WriteContext;
-=======
 import org.apache.cassandra.db.*;
->>>>>>>
 import org.apache.cassandra.db.compaction.CompactionManager;
 import org.apache.cassandra.db.filter.ClusteringIndexSliceFilter;
 import org.apache.cassandra.db.filter.ColumnFilter;
@@ -100,24 +57,10 @@
 import org.apache.cassandra.db.filter.RowFilter;
 import org.apache.cassandra.db.lifecycle.SSTableSet;
 import org.apache.cassandra.db.lifecycle.View;
-<<<<<<<
 import org.apache.cassandra.db.memtable.Memtable;
 import org.apache.cassandra.db.partitions.PartitionUpdate;
 import org.apache.cassandra.db.partitions.UnfilteredPartitionIterator;
 import org.apache.cassandra.db.rows.*;
-=======
-import org.apache.cassandra.db.partitions.PartitionUpdate;
-import org.apache.cassandra.db.partitions.UnfilteredPartitionIterator;
-import org.apache.cassandra.db.rows.BTreeRow;
-import org.apache.cassandra.db.rows.Cell;
-import org.apache.cassandra.db.rows.Cells;
-import org.apache.cassandra.db.rows.RangeTombstoneMarker;
-import org.apache.cassandra.db.rows.Row;
-import org.apache.cassandra.db.rows.RowDiffListener;
-import org.apache.cassandra.db.rows.Rows;
-import org.apache.cassandra.db.rows.Unfiltered;
-import org.apache.cassandra.db.rows.UnfilteredRowIterator;
->>>>>>>
 import org.apache.cassandra.exceptions.InvalidRequestException;
 import org.apache.cassandra.index.Index.IndexBuildingSupport;
 import org.apache.cassandra.index.internal.CassandraIndex;
@@ -964,12 +907,9 @@
         markAllIndexesRemoved();
         if (dropData)
             invalidateAllIndexesBlocking();
-<<<<<<<
-=======
 
         // TODO: Determine whether "dropData" should guard this or be passed to Group#invalidate()
         indexGroups.forEach((key, group) -> group.invalidate());
->>>>>>>
     }
 
     @VisibleForTesting
--- a/src/java/org/apache/cassandra/io/sstable/CQLSSTableWriter.java
+++ b/src/java/org/apache/cassandra/io/sstable/CQLSSTableWriter.java
@@ -32,10 +32,7 @@
 import com.google.common.base.Preconditions;
 import com.google.common.collect.Sets;
 
-<<<<<<<
-=======
 import org.apache.cassandra.config.CassandraRelevantProperties;
->>>>>>>
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.cql3.ColumnSpecification;
 import org.apache.cassandra.cql3.QueryOptions;
@@ -44,29 +41,18 @@
 import org.apache.cassandra.cql3.functions.types.TypeCodec;
 import org.apache.cassandra.cql3.functions.types.UserType;
 import org.apache.cassandra.cql3.statements.ModificationStatement;
-<<<<<<<
-import org.apache.cassandra.cql3.statements.UpdateStatement;
-import org.apache.cassandra.cql3.statements.schema.CreateTableStatement;
-import org.apache.cassandra.cql3.statements.schema.CreateTypeStatement;
-import org.apache.cassandra.db.Clustering;
-=======
 import org.apache.cassandra.cql3.statements.schema.CreateTableStatement;
 import org.apache.cassandra.cql3.statements.schema.CreateTypeStatement;
 import org.apache.cassandra.db.Clustering;
 import org.apache.cassandra.db.Slice;
 import org.apache.cassandra.db.Slices;
->>>>>>>
 import org.apache.cassandra.db.marshal.AbstractType;
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.Murmur3Partitioner;
 import org.apache.cassandra.exceptions.InvalidRequestException;
 import org.apache.cassandra.exceptions.SyntaxException;
 import org.apache.cassandra.io.sstable.format.SSTableFormat;
-<<<<<<<
 import org.apache.cassandra.io.util.File;
-=======
-import org.apache.cassandra.schema.Functions;
->>>>>>>
 import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.KeyspaceParams;
 import org.apache.cassandra.schema.Schema;
@@ -76,10 +62,7 @@
 import org.apache.cassandra.schema.TableMetadataRef;
 import org.apache.cassandra.schema.Tables;
 import org.apache.cassandra.schema.Types;
-<<<<<<<
-=======
 import org.apache.cassandra.schema.UserFunctions;
->>>>>>>
 import org.apache.cassandra.schema.Views;
 import org.apache.cassandra.service.ClientState;
 import org.apache.cassandra.transport.ProtocolVersion;
@@ -132,11 +115,7 @@
 
     static
     {
-<<<<<<<
         CassandraRelevantProperties.FORCE_LOAD_LOCAL_KEYSPACES.setBoolean(true);
-=======
-        System.setProperty("cassandra.schema.force_load_local_keyspaces", "true");
->>>>>>>
         DatabaseDescriptor.clientInitialization(false);
         // Partitioner is not set in client mode.
         if (DatabaseDescriptor.getPartitioner() == null)
@@ -586,31 +565,19 @@
                 throw new IllegalStateException("No modification (INSERT/UPDATE/DELETE) statement specified, you should provide a modification statement through using()");
 
             Preconditions.checkState(Sets.difference(SchemaConstants.LOCAL_SYSTEM_KEYSPACE_NAMES, Schema.instance.getKeyspaces()).isEmpty(),
-<<<<<<<
                                      "Local keyspaces were not loaded. If this is running as a client, please make sure to add %s=true system property.",
                                      CassandraRelevantProperties.FORCE_LOAD_LOCAL_KEYSPACES.getKey());
-=======
-                                     "Local keyspaces were not loaded. If this is running as a client, please make sure to add %s=true system property.", Schema.FORCE_LOAD_LOCAL_KEYSPACES_PROP);
->>>>>>>
             synchronized (CQLSSTableWriter.class)
             {
 
                 String keyspaceName = schemaStatement.keyspace();
 
                 Schema.instance.transform(SchemaTransformations.addKeyspace(KeyspaceMetadata.create(keyspaceName,
-<<<<<<<
-                                                                                                           KeyspaceParams.simple(1),
-                                                                                                           Tables.none(),
-                                                                                                           Views.none(),
-                                                                                                           Types.none(),
-                                                                                                           Functions.none()), true));
-=======
                                                                                                     KeyspaceParams.simple(1),
                                                                                                     Tables.none(),
                                                                                                     Views.none(),
                                                                                                     Types.none(),
                                                                                                     UserFunctions.none()), true));
->>>>>>>
 
                 KeyspaceMetadata ksm = Schema.instance.getKeyspaceMetadata(keyspaceName);
 
--- a/src/java/org/apache/cassandra/metrics/TableMetrics.java
+++ b/src/java/org/apache/cassandra/metrics/TableMetrics.java
@@ -30,10 +30,7 @@
 import java.util.function.Predicate;
 
 import com.google.common.annotations.VisibleForTesting;
-<<<<<<<
-=======
 import com.google.common.collect.ImmutableMap;
->>>>>>>
 import com.google.common.collect.Iterables;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
@@ -44,17 +41,6 @@
 import com.codahale.metrics.Histogram;
 import com.codahale.metrics.Meter;
 import com.codahale.metrics.Metric;
-<<<<<<<
-import com.codahale.metrics.RatioGauge;
-import com.codahale.metrics.Timer;
-import org.apache.cassandra.db.ColumnFamilyStore;
-import org.apache.cassandra.db.Keyspace;
-import org.apache.cassandra.db.Memtable;
-import org.apache.cassandra.db.lifecycle.SSTableSet;
-import org.apache.cassandra.db.lifecycle.View;
-import org.apache.cassandra.index.SecondaryIndexManager;
-import org.apache.cassandra.io.compress.CompressionMetadata;
-=======
 import com.codahale.metrics.Timer;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.ColumnFamilyStore;
@@ -66,14 +52,12 @@
 import org.apache.cassandra.io.compress.CompressionMetadata;
 import org.apache.cassandra.io.sstable.GaugeProvider;
 import org.apache.cassandra.io.sstable.format.SSTableFormat;
->>>>>>>
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.io.sstable.metadata.MetadataCollector;
 import org.apache.cassandra.metrics.Sampler.SamplerType;
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.SchemaConstants;
 import org.apache.cassandra.utils.EstimatedHistogram;
-<<<<<<<
 import org.apache.cassandra.utils.ExpMovingAverage;
 import org.apache.cassandra.utils.MovingAverage;
 import org.apache.cassandra.utils.Pair;
@@ -81,11 +65,6 @@
 import static java.util.concurrent.TimeUnit.MICROSECONDS;
 import static org.apache.cassandra.metrics.CassandraMetricsRegistry.Metrics;
 import static org.apache.cassandra.utils.Clock.Global.nanoTime;
-=======
-import org.apache.cassandra.utils.Pair;
-
-import static org.apache.cassandra.metrics.CassandraMetricsRegistry.Metrics;
->>>>>>>
 
 /**
  * Metrics for {@link ColumnFamilyStore}.
--- a/src/java/org/apache/cassandra/net/Message.java
+++ b/src/java/org/apache/cassandra/net/Message.java
@@ -25,10 +25,6 @@
 import java.util.Map;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicInteger;
-<<<<<<<
-=======
-import javax.annotation.Nullable;
->>>>>>>
 
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.primitives.Ints;
@@ -54,12 +50,6 @@
 import static java.util.concurrent.TimeUnit.NANOSECONDS;
 import static org.apache.cassandra.db.TypeSizes.sizeof;
 import static org.apache.cassandra.db.TypeSizes.sizeofUnsignedVInt;
-<<<<<<<
-=======
-import static org.apache.cassandra.locator.InetAddressAndPort.Serializer.inetAddressAndPortSerializer;
-import static org.apache.cassandra.net.MessagingService.VERSION_30;
-import static org.apache.cassandra.net.MessagingService.VERSION_3014;
->>>>>>>
 import static org.apache.cassandra.net.MessagingService.VERSION_40;
 import static org.apache.cassandra.net.MessagingService.VERSION_50;
 import static org.apache.cassandra.utils.FBUtilities.getBroadcastAddressAndPort;
--- a/src/java/org/apache/cassandra/net/MessagingService.java
+++ b/src/java/org/apache/cassandra/net/MessagingService.java
@@ -30,11 +30,8 @@
 import java.util.stream.Collectors;
 
 import com.google.common.annotations.VisibleForTesting;
-<<<<<<<
-=======
 import com.google.common.collect.Lists;
 import io.netty.util.concurrent.Future; //checkstyle: permit this import
->>>>>>>
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -208,11 +205,7 @@
  * implemented in {@link org.apache.cassandra.db.virtual.InternodeInboundTable} and
  * {@link org.apache.cassandra.db.virtual.InternodeOutboundTable} respectively.
  */
-<<<<<<<
-public class MessagingService extends MessagingServiceMBeanImpl
-=======
 public class MessagingService extends MessagingServiceMBeanImpl implements MessageDelivery
->>>>>>>
 {
     private static final Logger logger = LoggerFactory.getLogger(MessagingService.class);
 
--- a/src/java/org/apache/cassandra/net/Verb.java
+++ b/src/java/org/apache/cassandra/net/Verb.java
@@ -70,16 +70,11 @@
 import org.apache.cassandra.repair.messages.SyncRequest;
 import org.apache.cassandra.repair.messages.SyncResponse;
 import org.apache.cassandra.repair.messages.ValidationRequest;
-<<<<<<<
-=======
 import org.apache.cassandra.repair.messages.ValidationResponse;
->>>>>>>
 import org.apache.cassandra.schema.SchemaMutationsSerializer;
 import org.apache.cassandra.schema.SchemaPullVerbHandler;
 import org.apache.cassandra.schema.SchemaPushVerbHandler;
 import org.apache.cassandra.schema.SchemaVersionVerbHandler;
-<<<<<<<
-=======
 import org.apache.cassandra.service.paxos.PaxosCommit;
 import org.apache.cassandra.service.paxos.PaxosCommitAndPrepare;
 import org.apache.cassandra.service.paxos.PaxosPrepare;
@@ -93,7 +88,6 @@
 import org.apache.cassandra.service.paxos.cleanup.PaxosStartPrepareCleanup;
 import org.apache.cassandra.service.paxos.cleanup.PaxosFinishPrepareCleanup;
 import org.apache.cassandra.utils.BooleanSerializer;
->>>>>>>
 import org.apache.cassandra.service.EchoVerbHandler;
 import org.apache.cassandra.service.SnapshotVerbHandler;
 import org.apache.cassandra.service.paxos.Commit;
@@ -102,40 +96,6 @@
 import org.apache.cassandra.service.paxos.v1.PrepareVerbHandler;
 import org.apache.cassandra.service.paxos.v1.ProposeVerbHandler;
 import org.apache.cassandra.streaming.ReplicationDoneVerbHandler;
-<<<<<<<
-import org.apache.cassandra.utils.BooleanSerializer;
-import org.apache.cassandra.utils.UUIDSerializer;
-
-import static java.util.concurrent.TimeUnit.NANOSECONDS;
-import static org.apache.cassandra.concurrent.Stage.ANTI_ENTROPY;
-import static org.apache.cassandra.concurrent.Stage.COUNTER_MUTATION;
-import static org.apache.cassandra.concurrent.Stage.GOSSIP;
-import static org.apache.cassandra.concurrent.Stage.IMMEDIATE;
-import static org.apache.cassandra.concurrent.Stage.INTERNAL_RESPONSE;
-import static org.apache.cassandra.concurrent.Stage.MIGRATION;
-import static org.apache.cassandra.concurrent.Stage.MISC;
-import static org.apache.cassandra.concurrent.Stage.MUTATION;
-import static org.apache.cassandra.concurrent.Stage.READ;
-import static org.apache.cassandra.concurrent.Stage.REQUEST_RESPONSE;
-import static org.apache.cassandra.concurrent.Stage.TRACING;
-import static org.apache.cassandra.net.Verb.Kind.CUSTOM;
-import static org.apache.cassandra.net.Verb.Kind.NORMAL;
-import static org.apache.cassandra.net.Verb.Priority.P0;
-import static org.apache.cassandra.net.Verb.Priority.P1;
-import static org.apache.cassandra.net.Verb.Priority.P2;
-import static org.apache.cassandra.net.Verb.Priority.P3;
-import static org.apache.cassandra.net.Verb.Priority.P4;
-import static org.apache.cassandra.net.VerbTimeouts.counterTimeout;
-import static org.apache.cassandra.net.VerbTimeouts.longTimeout;
-import static org.apache.cassandra.net.VerbTimeouts.noTimeout;
-import static org.apache.cassandra.net.VerbTimeouts.pingTimeout;
-import static org.apache.cassandra.net.VerbTimeouts.rangeTimeout;
-import static org.apache.cassandra.net.VerbTimeouts.readTimeout;
-import static org.apache.cassandra.net.VerbTimeouts.repairMsgTimeout;
-import static org.apache.cassandra.net.VerbTimeouts.rpcTimeout;
-import static org.apache.cassandra.net.VerbTimeouts.truncateTimeout;
-import static org.apache.cassandra.net.VerbTimeouts.writeTimeout;
-=======
 import org.apache.cassandra.utils.ReflectionUtils;
 import org.apache.cassandra.utils.TimeUUID;
 import org.apache.cassandra.utils.UUIDSerializer;
@@ -145,7 +105,6 @@
 import static org.apache.cassandra.net.VerbTimeouts.*;
 import static org.apache.cassandra.net.Verb.Kind.*;
 import static org.apache.cassandra.net.Verb.Priority.*;
->>>>>>>
 
 /**
  * Note that priorities except P0 are presently unused.  P0 corresponds to urgent, i.e. what used to be the "Gossip" connection.
--- a/src/java/org/apache/cassandra/schema/DefaultSchemaUpdateHandler.java
+++ b/src/java/org/apache/cassandra/schema/DefaultSchemaUpdateHandler.java
@@ -24,10 +24,6 @@
 import java.util.Map;
 import java.util.Set;
 import java.util.UUID;
-<<<<<<<
-=======
-import java.util.concurrent.CompletableFuture;
->>>>>>>
 import java.util.function.BiConsumer;
 import java.util.stream.Collectors;
 
@@ -51,11 +47,8 @@
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.utils.FBUtilities;
 import org.apache.cassandra.utils.Pair;
-<<<<<<<
-=======
 import org.apache.cassandra.utils.concurrent.AsyncPromise;
 import org.apache.cassandra.utils.concurrent.Awaitable;
->>>>>>>
 
 import static org.apache.cassandra.schema.MigrationCoordinator.MAX_OUTSTANDING_VERSION_REQUESTS;
 
@@ -70,11 +63,7 @@
     private final BiConsumer<SchemaTransformationResult, Boolean> updateCallback;
     private volatile DistributedSchema schema = DistributedSchema.EMPTY;
 
-<<<<<<<
     private volatile AsyncPromise<Void> requestedReset;
-=======
-    private volatile CompletableFuture<Void> requestedReset;
->>>>>>>
 
     private MigrationCoordinator createMigrationCoordinator(MessagingService messagingService)
     {
@@ -140,21 +129,13 @@
             return true;
 
         logger.warn("There are nodes in the cluster with a different schema version than us, from which we did not merge schemas: " +
-<<<<<<<
                     "our version: ({}), outstanding versions -> endpoints: {}. Use -D{}=true to ignore this, " +
-=======
-                    "our version: ({}), outstanding versions -> endpoints: {}. Use -D{}}=true to ignore this, " +
->>>>>>>
                     "-D{}=<ep1[,epN]> to skip specific endpoints, or -D{}=<ver1[,verN]> to skip specific schema versions",
                     Schema.instance.getVersion(),
                     migrationCoordinator.outstandingVersions(),
                     CassandraRelevantProperties.BOOTSTRAP_SKIP_SCHEMA_CHECK.getKey(),
-<<<<<<<
                     CassandraRelevantProperties.IGNORED_SCHEMA_CHECK_ENDPOINTS.getKey(),
                     CassandraRelevantProperties.IGNORED_SCHEMA_CHECK_VERSIONS.getKey());
-=======
-                    CassandraRelevantProperties.IGNORED_SCHEMA_CHECK_ENDPOINTS.getKey(), CassandraRelevantProperties.IGNORED_SCHEMA_CHECK_VERSIONS.getKey());
->>>>>>>
 
         if (requireSchemas)
         {
@@ -237,11 +218,7 @@
         DistributedSchema after = new DistributedSchema(afterKeyspaces, version);
         SchemaTransformationResult update = new SchemaTransformationResult(before, after, diff);
 
-<<<<<<<
-        logger.debug("Applying schema change due to received mutations: {}", update);
-=======
         logger.info("Applying schema change due to received mutations: {}", update);
->>>>>>>
         updateSchema(update, false);
         return update;
     }
@@ -331,28 +308,13 @@
      * @return
      */
     @Override
-<<<<<<<
     public Awaitable clear()
-=======
-    public CompletableFuture<Void> clear()
->>>>>>>
     {
         synchronized (this)
         {
             if (requestedReset == null)
             {
-<<<<<<<
                 requestedReset = new AsyncPromise<>();
-=======
-                requestedReset = new CompletableFuture<Void>()
-                {
-                    @Override
-                    public boolean cancel(boolean mayInterruptIfRunning)
-                    {
-                        throw new UnsupportedOperationException();
-                    }
-                };
->>>>>>>
                 migrationCoordinator.reset();
             }
             return requestedReset;
@@ -373,11 +335,7 @@
         {
             schema = DistributedSchema.EMPTY;
             SchemaKeyspace.truncate();
-<<<<<<<
-            requestedReset.complete(null);
-=======
             requestedReset.setSuccess(null);
->>>>>>>
             requestedReset = null;
         }
         applyMutations(mutations);
--- a/src/java/org/apache/cassandra/schema/DistributedSchema.java
+++ b/src/java/org/apache/cassandra/schema/DistributedSchema.java
@@ -91,11 +91,7 @@
             ksm.tables.forEach(tm -> Preconditions.checkArgument(tm.keyspace.equals(ksm.name), "Table %s metadata points to keyspace %s while defined in keyspace %s", tm.name, tm.keyspace, ksm.name));
             ksm.views.forEach(vm -> Preconditions.checkArgument(vm.keyspace().equals(ksm.name), "View %s metadata points to keyspace %s while defined in keyspace %s", vm.name(), vm.keyspace(), ksm.name));
             ksm.types.forEach(ut -> Preconditions.checkArgument(ut.keyspace.equals(ksm.name), "Type %s points to keyspace %s while defined in keyspace %s", ut.name, ut.keyspace, ksm.name));
-<<<<<<<
-            ksm.functions.forEach(f -> Preconditions.checkArgument(f.name().keyspace.equals(ksm.name), "Function %s points to keyspace %s while defined in keyspace %s", f.name().name, f.name().keyspace, ksm.name));
-=======
             ksm.userFunctions.forEach(f -> Preconditions.checkArgument(f.name().keyspace.equals(ksm.name), "Function %s points to keyspace %s while defined in keyspace %s", f.name().name, f.name().keyspace, ksm.name));
->>>>>>>
         });
     }
 }
--- a/src/java/org/apache/cassandra/schema/KeyspaceMetadata.java
+++ b/src/java/org/apache/cassandra/schema/KeyspaceMetadata.java
@@ -20,11 +20,8 @@
 import java.util.HashSet;
 import java.util.Optional;
 import java.util.Set;
-<<<<<<<
-=======
 import java.util.stream.Stream;
 
->>>>>>>
 import javax.annotation.Nullable;
 
 import com.google.common.base.MoreObjects;
@@ -128,11 +125,6 @@
         return new KeyspaceMetadata(this.name, this.kind, this.params, Tables.none(), Views.none(), Types.none(), UserFunctions.none());
     }
 
-    public KeyspaceMetadata empty()
-    {
-        return new KeyspaceMetadata(this.name, this.kind, this.params, Tables.none(), Views.none(), Types.none(), Functions.none());
-    }
-
     public boolean isVirtual()
     {
         return kind == Kind.VIRTUAL;
--- a/src/java/org/apache/cassandra/schema/MigrationCoordinator.java
+++ b/src/java/org/apache/cassandra/schema/MigrationCoordinator.java
@@ -24,7 +24,6 @@
 import java.util.ArrayDeque;
 import java.util.ArrayList;
 import java.util.Collection;
-import java.util.Collections;
 import java.util.Deque;
 import java.util.HashMap;
 import java.util.HashSet;
@@ -32,29 +31,15 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Objects;
-<<<<<<<
-import java.util.Optional;
-import java.util.Set;
-import java.util.UUID;
-import java.util.WeakHashMap;
-import java.util.concurrent.CompletableFuture;
-import java.util.concurrent.Executor;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Future;
-=======
 import java.util.Set;
 import java.util.UUID;
 import java.util.concurrent.RejectedExecutionException;
->>>>>>>
 import java.util.concurrent.ScheduledExecutorService;
 import java.util.concurrent.ScheduledFuture;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicReference;
 import java.util.function.BiConsumer;
-<<<<<<<
-=======
 import java.util.function.LongSupplier;
->>>>>>>
 import java.util.function.Supplier;
 
 import com.google.common.annotations.VisibleForTesting;
@@ -84,25 +69,18 @@
 import org.apache.cassandra.utils.FBUtilities;
 import org.apache.cassandra.utils.NoSpamLogger;
 import org.apache.cassandra.utils.Pair;
-<<<<<<<
-=======
 import org.apache.cassandra.utils.Simulate;
 import org.apache.cassandra.utils.concurrent.Future;
 import org.apache.cassandra.utils.concurrent.ImmediateFuture;
->>>>>>>
 import org.apache.cassandra.utils.concurrent.WaitQueue;
 
 import static org.apache.cassandra.config.CassandraRelevantProperties.IGNORED_SCHEMA_CHECK_ENDPOINTS;
 import static org.apache.cassandra.config.CassandraRelevantProperties.IGNORED_SCHEMA_CHECK_VERSIONS;
-<<<<<<<
 import static org.apache.cassandra.config.CassandraRelevantProperties.SCHEMA_PULL_INTERVAL_MS;
 import static org.apache.cassandra.net.Verb.SCHEMA_PUSH_REQ;
 import static org.apache.cassandra.utils.Clock.Global.nanoTime;
 import static org.apache.cassandra.utils.Simulate.With.MONITORS;
 import static org.apache.cassandra.utils.concurrent.WaitQueue.newWaitQueue;
-=======
-import static org.apache.cassandra.net.Verb.SCHEMA_PUSH_REQ;
->>>>>>>
 
 /**
  * Migration coordinator is responsible for tracking schema versions on various nodes and, if needed, synchronize the
@@ -121,22 +99,6 @@
 {
     private static final Logger logger = LoggerFactory.getLogger(MigrationCoordinator.class);
     private static final NoSpamLogger noSpamLogger = NoSpamLogger.getLogger(MigrationCoordinator.logger, 1, TimeUnit.MINUTES);
-<<<<<<<
-    private static final CompletableFuture<Void> FINISHED_FUTURE = CompletableFuture.completedFuture(null);
-
-    private static final int MIGRATION_DELAY_IN_MS = CassandraRelevantProperties.MIGRATION_DELAY.getInt();
-    public static final int MAX_OUTSTANDING_VERSION_REQUESTS = 3;
-
-    /**
-     * @see CassandraRelevantProperties#SCHEMA_PULL_BACKOFF_DELAY_MS
-     */
-    private static final long BACKOFF_DELAY_MS = CassandraRelevantProperties.SCHEMA_PULL_BACKOFF_DELAY_MS.getInt();
-
-    /**
-     * Holds the timestamps in ms for last pull request attempts.
-     */
-    private final WeakHashMap<InetAddressAndPort, Long> lastPullAttemptTimestamps = new WeakHashMap<>();
-=======
     private static final Future<Void> FINISHED_FUTURE = ImmediateFuture.success(null);
 
     private static LongSupplier getUptimeFn = () -> ManagementFactory.getRuntimeMXBean().getUptime();
@@ -149,7 +111,6 @@
 
     private static final int MIGRATION_DELAY_IN_MS = CassandraRelevantProperties.MIGRATION_DELAY.getInt();
     public static final int MAX_OUTSTANDING_VERSION_REQUESTS = 3;
->>>>>>>
 
     private static ImmutableSet<UUID> getIgnoredVersions()
     {
@@ -266,11 +227,7 @@
     private final Supplier<UUID> schemaVersion;
     private final BiConsumer<InetAddressAndPort, Collection<Mutation>> schemaUpdateCallback;
 
-<<<<<<<
     final ExecutorPlus executor;
-=======
-    final ExecutorService executor;
->>>>>>>
 
     /**
      * Creates but does not start migration coordinator instance.
@@ -279,11 +236,7 @@
      * @param periodicCheckExecutor executor on which the periodic checks are scheduled
      */
     MigrationCoordinator(MessagingService messagingService,
-<<<<<<<
                          ExecutorPlus executor,
-=======
-                         ExecutorService executor,
->>>>>>>
                          ScheduledExecutorService periodicCheckExecutor,
                          int maxOutstandingVersionRequests,
                          Gossiper gossiper,
@@ -300,18 +253,6 @@
     }
 
     void start()
-<<<<<<<
-    {
-        announce(schemaVersion.get());
-        int interval = CassandraRelevantProperties.SCHEMA_PULL_INTERVAL_MS.getInt();
-        periodicPullTask.updateAndGet(curTask -> curTask == null
-                                                 ? periodicCheckExecutor.scheduleWithFixedDelay(this::pullUnreceivedSchemaVersions, interval, interval, TimeUnit.MILLISECONDS)
-                                                 : curTask);
-    }
-
-    private synchronized void pullUnreceivedSchemaVersions()
-    {
-=======
     {
         long interval = SCHEMA_PULL_INTERVAL_MS.getLong();
         logger.info("Starting migration coordinator and scheduling pulling schema versions every {}", Duration.ofMillis(interval));
@@ -324,7 +265,6 @@
     private synchronized void pullUnreceivedSchemaVersions()
     {
         logger.debug("Pulling unreceived schema versions...");
->>>>>>>
         for (VersionInfo info : versionInfo.values())
         {
             if (info.wasReceived() || info.outstandingRequests.size() > 0)
@@ -337,11 +277,7 @@
         }
     }
 
-<<<<<<<
-    private synchronized CompletableFuture<Void> maybePullSchema(VersionInfo info)
-=======
     private synchronized Future<Void> maybePullSchema(VersionInfo info)
->>>>>>>
     {
         if (info.endpoints.isEmpty() || info.wasReceived() || !shouldPullSchema(info.version))
         {
@@ -464,11 +400,7 @@
     private boolean shouldPullImmediately(InetAddressAndPort endpoint, UUID version)
     {
         UUID localSchemaVersion = schemaVersion.get();
-<<<<<<<
-        if (SchemaConstants.emptyVersion.equals(localSchemaVersion) || ManagementFactory.getRuntimeMXBean().getUptime() < MIGRATION_DELAY_IN_MS)
-=======
         if (SchemaConstants.emptyVersion.equals(localSchemaVersion) || getUptimeFn.getAsLong() < MIGRATION_DELAY_IN_MS)
->>>>>>>
         {
             // If we think we may be bootstrapping or have recently started, submit MigrationTask immediately
             logger.debug("Immediately submitting migration task for {}, " +
@@ -491,11 +423,7 @@
         return !Objects.equals(schemaVersion.get(), info.version);
     }
 
-<<<<<<<
-    synchronized CompletableFuture<Void> reportEndpointVersion(InetAddressAndPort endpoint, UUID version)
-=======
     synchronized Future<Void> reportEndpointVersion(InetAddressAndPort endpoint, UUID version)
->>>>>>>
     {
         logger.debug("Reported schema {} at endpoint {}", version, endpoint);
         if (ignoredEndpoints.contains(endpoint) || IGNORED_VERSIONS.contains(version))
@@ -615,26 +543,6 @@
         }
     }
 
-<<<<<<<
-    private CompletableFuture<Void> scheduleSchemaPull(InetAddressAndPort endpoint, VersionInfo info)
-    {
-        Executor submissionExecutor;
-        if (shouldPullImmediately(endpoint, info.version))
-        {
-            long nextAttempt = lastPullAttemptTimestamps.getOrDefault(endpoint, 0L) + BACKOFF_DELAY_MS;
-            long now = System.currentTimeMillis();
-            if (nextAttempt <= now)
-            {
-                logger.debug("Pulling {} immediately from {}", info, endpoint);
-                submissionExecutor = this::submitToMigrationIfNotShutdown;
-            }
-            else
-            {
-                long delay = nextAttempt - now;
-                logger.debug("Previous pull of {} from {} failed. Postponing next attempt for {}ms", info, endpoint, delay);
-                submissionExecutor = r -> ScheduledExecutors.nonPeriodicTasks.schedule(() -> submitToMigrationIfNotShutdown(r), delay, TimeUnit.MILLISECONDS);
-            }
-=======
     private Future<Void> scheduleSchemaPull(InetAddressAndPort endpoint, VersionInfo info)
     {
         FutureTask<Void> task = new FutureTask<>(() -> pullSchema(endpoint, new Callback(endpoint, info)));
@@ -643,20 +551,16 @@
         {
             logger.debug("Pulling {} immediately from {}", info, endpoint);
             submitToMigrationIfNotShutdown(task);
->>>>>>>
         }
         else
         {
             logger.debug("Postponing pull of {} from {} for {}ms", info, endpoint, MIGRATION_DELAY_IN_MS);
-            submissionExecutor = r -> ScheduledExecutors.nonPeriodicTasks.schedule(() -> submitToMigrationIfNotShutdown(r), MIGRATION_DELAY_IN_MS, TimeUnit.MILLISECONDS);
+            ScheduledExecutors.nonPeriodicTasks.schedule(() -> submitToMigrationIfNotShutdown(task), MIGRATION_DELAY_IN_MS, TimeUnit.MILLISECONDS);
         }
 
-        return CompletableFuture.runAsync(() -> pullSchema(endpoint, new Callback(endpoint, info)), submissionExecutor);
+        return task;
     }
 
-<<<<<<<
-    private CompletableFuture<Collection<Mutation>> pullSchemaFrom(InetAddressAndPort endpoint)
-=======
     void announce(UUID schemaVersion)
     {
         if (gossiper.isEnabled())
@@ -665,21 +569,10 @@
     }
 
     private Future<?> submitToMigrationIfNotShutdown(Runnable task)
->>>>>>>
     {
-        CompletableFuture<Collection<Mutation>> result = new CompletableFuture<>();
-        return submitToMigrationIfNotShutdown(() -> pullSchema(endpoint, new RequestCallback<Collection<Mutation>>()
+        boolean skipped = false;
+        try
         {
-<<<<<<<
-            @Override
-            public void onResponse(Message<Collection<Mutation>> msg)
-            {
-                result.complete(msg.payload);
-            }
-
-            @Override
-            public void onFailure(InetAddressAndPort from, RequestFailureReason failureReason)
-=======
             if (executor.isShutdown() || executor.isTerminated())
             {
                 skipped = true;
@@ -695,52 +588,12 @@
         finally
         {
             if (skipped)
->>>>>>>
-            {
-                result.completeExceptionally(new RuntimeException("Failed to get schema from " + from + ". The failure reason was: " + failureReason));
-            }
-
-            @Override
-            public boolean invokeOnFailure()
             {
-                return true;
+                logger.info("Skipped scheduled pulling schema from other nodes: the MIGRATION executor service has been shutdown.");
             }
-        })).thenCompose(ignored -> result);
-    }
-
-<<<<<<<
-=======
-    CompletableFuture<Collection<Mutation>> pullSchemaFromAnyNode()
-    {
-        Optional<InetAddressAndPort> endpoint = gossiper.getLiveMembers()
-                                                        .stream()
-                                                        .filter(this::shouldPullFromEndpoint)
-                                                        .findFirst();
-
-        return endpoint.map(this::pullSchemaFrom).orElse(CompletableFuture.completedFuture(Collections.emptyList()));
-    }
-
-    void announce(UUID schemaVersion)
-    {
-        if (gossiper.isEnabled())
-            gossiper.addLocalApplicationState(ApplicationState.SCHEMA, StorageService.instance.valueFactory.schema(schemaVersion));
-        SchemaDiagnostics.versionAnnounced(Schema.instance);
-    }
-
-    private CompletableFuture<Void> submitToMigrationIfNotShutdown(Runnable task)
-    {
-        if (executor.isShutdown() || executor.isTerminated())
-        {
-            logger.info("Skipped scheduled pulling schema from other nodes: the MIGRATION executor service has been shutdown.");
-            return CompletableFuture.completedFuture(null);
-        }
-        else
-        {
-            return CompletableFuture.runAsync(task, executor);
         }
     }
 
->>>>>>>
     private class Callback implements RequestCallback<Collection<Mutation>>
     {
         final InetAddressAndPort endpoint;
@@ -795,11 +648,6 @@
 
     private void pullSchema(InetAddressAndPort endpoint, RequestCallback<Collection<Mutation>> callback)
     {
-<<<<<<<
-=======
-        lastPullAttemptTimestamps.put(endpoint, System.currentTimeMillis());
-
->>>>>>>
         if (!gossiper.isAlive(endpoint))
         {
             noSpamLogger.warn("Can't send schema pull request: node {} is down.", endpoint);
@@ -910,8 +758,4 @@
                && messagingService.versions.getRaw(endpoint) == MessagingService.current_version;
     }
 
-<<<<<<<
-}
-=======
 }
->>>>>>>
--- a/src/java/org/apache/cassandra/schema/OfflineSchemaUpdateHandler.java
+++ b/src/java/org/apache/cassandra/schema/OfflineSchemaUpdateHandler.java
@@ -20,10 +20,6 @@
 
 import java.time.Duration;
 import java.util.UUID;
-<<<<<<<
-=======
-import java.util.concurrent.CompletableFuture;
->>>>>>>
 import java.util.function.BiConsumer;
 
 import org.slf4j.Logger;
@@ -31,11 +27,8 @@
 
 import org.apache.cassandra.schema.SchemaTransformation.SchemaTransformationResult;
 import org.apache.cassandra.utils.ByteArrayUtil;
-<<<<<<<
-=======
 import org.apache.cassandra.utils.concurrent.Awaitable;
 import org.apache.cassandra.utils.concurrent.ImmediateFuture;
->>>>>>>
 
 /**
  * Update handler which works only in memory. It does not load or save the schema anywhere. It is used in client mode
@@ -95,16 +88,9 @@
     }
 
     @Override
-<<<<<<<
     public synchronized Awaitable clear()
     {
         this.schema = DistributedSchema.EMPTY;
         return ImmediateFuture.success(true);
-=======
-    public synchronized CompletableFuture<Void> clear()
-    {
-        this.schema = DistributedSchema.EMPTY;
-        return CompletableFuture.completedFuture(null);
->>>>>>>
     }
 }
--- a/src/java/org/apache/cassandra/schema/Schema.java
+++ b/src/java/org/apache/cassandra/schema/Schema.java
@@ -26,15 +26,8 @@
 import java.util.Optional;
 import java.util.Set;
 import java.util.UUID;
-<<<<<<<
-import java.util.concurrent.CompletableFuture;
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.TimeoutException;
-=======
 import java.util.concurrent.TimeUnit;
 import java.util.function.Consumer;
->>>>>>>
 import java.util.function.Supplier;
 
 import com.google.common.annotations.VisibleForTesting;
@@ -45,15 +38,10 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-<<<<<<<
 import org.apache.cassandra.config.CassandraRelevantProperties;
 import org.apache.cassandra.cql3.functions.Function;
 import org.apache.cassandra.cql3.functions.FunctionName;
 import org.apache.cassandra.cql3.functions.UserFunction;
-=======
-import org.apache.cassandra.cql3.functions.Function;
-import org.apache.cassandra.cql3.functions.FunctionName;
->>>>>>>
 import org.apache.cassandra.db.ColumnFamilyStore;
 import org.apache.cassandra.db.Keyspace;
 import org.apache.cassandra.db.KeyspaceNotDefinedException;
@@ -62,10 +50,7 @@
 import org.apache.cassandra.db.virtual.VirtualKeyspaceRegistry;
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.exceptions.InvalidRequestException;
-<<<<<<<
-=======
 import org.apache.cassandra.gms.Gossiper;
->>>>>>>
 import org.apache.cassandra.io.sstable.Descriptor;
 import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.locator.LocalStrategy;
@@ -74,11 +59,8 @@
 import org.apache.cassandra.schema.SchemaTransformation.SchemaTransformationResult;
 import org.apache.cassandra.service.PendingRangeCalculatorService;
 import org.apache.cassandra.service.StorageService;
-<<<<<<<
-=======
 import org.apache.cassandra.utils.FBUtilities;
 import org.apache.cassandra.utils.concurrent.Awaitable;
->>>>>>>
 import org.apache.cassandra.utils.concurrent.LoadingMap;
 
 import static com.google.common.collect.Iterables.size;
@@ -104,19 +86,10 @@
 {
     private static final Logger logger = LoggerFactory.getLogger(Schema.class);
 
-<<<<<<<
     public static final Schema instance = new Schema();
 
     private volatile Keyspaces distributedKeyspaces = Keyspaces.none();
     private volatile Keyspaces distributedAndLocalKeyspaces;
-=======
-    public static final String FORCE_LOAD_LOCAL_KEYSPACES_PROP = "cassandra.schema.force_load_local_keyspaces";
-    private static final boolean FORCE_LOAD_LOCAL_KEYSPACES = Boolean.getBoolean(FORCE_LOAD_LOCAL_KEYSPACES_PROP);
-
-    public static final Schema instance = new Schema();
-
-    private volatile Keyspaces distributedKeyspaces = Keyspaces.none();
->>>>>>>
 
     private final Keyspaces localKeyspaces;
 
@@ -145,16 +118,10 @@
     private Schema()
     {
         this.online = isDaemonInitialized();
-<<<<<<<
         this.localKeyspaces = (CassandraRelevantProperties.FORCE_LOAD_LOCAL_KEYSPACES.getBoolean() || isDaemonInitialized() || isToolInitialized())
                               ? Keyspaces.of(SchemaKeyspace.metadata(), SystemKeyspace.metadata())
                               : Keyspaces.none();
         this.distributedAndLocalKeyspaces = this.localKeyspaces;
-=======
-        this.localKeyspaces = (FORCE_LOAD_LOCAL_KEYSPACES || isDaemonInitialized() || isToolInitialized())
-                              ? Keyspaces.of(SchemaKeyspace.metadata(), SystemKeyspace.metadata())
-                              : Keyspaces.none();
->>>>>>>
 
         this.localKeyspaces.forEach(this::loadNew);
         this.updateHandler = SchemaUpdateHandlerFactoryProvider.instance.get().getSchemaUpdateHandler(online, this::mergeAndUpdateVersion);
@@ -165,10 +132,7 @@
     {
         this.online = online;
         this.localKeyspaces = localKeyspaces;
-<<<<<<<
-=======
         this.distributedAndLocalKeyspaces = this.localKeyspaces;
->>>>>>>
         this.updateHandler = updateHandler;
     }
 
@@ -210,10 +174,7 @@
             reload(previous, ksm);
 
         distributedKeyspaces = distributedKeyspaces.withAddedOrUpdated(ksm);
-<<<<<<<
-=======
         distributedAndLocalKeyspaces = distributedAndLocalKeyspaces.withAddedOrUpdated(ksm);
->>>>>>>
     }
 
     private synchronized void loadNew(KeyspaceMetadata ksm)
@@ -290,19 +251,11 @@
         return keyspaceInstances.blockingLoadIfAbsent(keyspaceName, loadFunction);
     }
 
-<<<<<<<
     private Keyspace maybeRemoveKeyspaceInstance(String keyspaceName, Consumer<Keyspace> unloadFunction)
     {
         try
         {
             return keyspaceInstances.blockingUnloadIfPresent(keyspaceName, unloadFunction);
-=======
-    public Keyspace maybeRemoveKeyspaceInstance(String keyspaceName, boolean dropData)
-    {
-        try
-        {
-            return keyspaceInstances.blockingUnloadIfPresent(keyspaceName, keyspace -> keyspace.unload(dropData));
->>>>>>>
         }
         catch (LoadingMap.UnloadExecutionException e)
         {
@@ -310,24 +263,9 @@
         }
     }
 
-<<<<<<<
-    /**
-     * @deprecated use {@link #distributedAndLocalKeyspaces()}
-     */
-    @Deprecated
-    public Keyspaces snapshot()
-    {
-        return distributedAndLocalKeyspaces();
-    }
-
-    public Keyspaces distributedAndLocalKeyspaces()
-    {
-        return Keyspaces.builder().add(localKeyspaces).add(distributedKeyspaces).build();
-=======
     public Keyspaces distributedAndLocalKeyspaces()
     {
         return distributedAndLocalKeyspaces;
->>>>>>>
     }
 
     public Keyspaces distributedKeyspaces()
@@ -356,10 +294,7 @@
     private synchronized void unload(KeyspaceMetadata ksm)
     {
         distributedKeyspaces = distributedKeyspaces.without(ksm.name);
-<<<<<<<
-=======
         distributedAndLocalKeyspaces = distributedAndLocalKeyspaces.without(ksm.name);
->>>>>>>
 
         this.tableMetadataRefCache = tableMetadataRefCache.withRemovedRefs(ksm);
 
@@ -553,11 +488,7 @@
         KeyspaceMetadata ksm = getKeyspaceMetadata(name.keyspace);
         return ksm == null
                ? Collections.emptyList()
-<<<<<<<
-               : ksm.functions.get(name);
-=======
                : ksm.userFunctions.get(name);
->>>>>>>
     }
 
     /**
@@ -573,15 +504,8 @@
         if (!name.hasKeyspace())
             throw new IllegalArgumentException(String.format("Function name must be fully quallified: got %s", name));
 
-<<<<<<<
-        KeyspaceMetadata ksm = getKeyspaceMetadata(name.keyspace);
-        return ksm == null
-               ? Optional.empty()
-               : ksm.functions.find(name, argTypes);
-=======
         return Optional.ofNullable(getKeyspaceMetadata(name.keyspace))
                        .flatMap(ksm -> ksm.userFunctions.find(name, argTypes));
->>>>>>>
     }
 
     /* Version control */
@@ -623,19 +547,6 @@
     }
 
     /**
-<<<<<<<
-=======
-     * Clear all KS/CF metadata and reset version.
-     */
-    public synchronized void clear()
-    {
-        distributedKeyspaces.forEach(this::unload);
-        updateVersion(SchemaConstants.emptyVersion);
-        SchemaDiagnostics.schemaCleared(this);
-    }
-
-    /**
->>>>>>>
      * When we receive {@link SchemaTransformationResult} in a callback invocation, the transformation result includes
      * pre-transformation and post-transformation schema metadata and versions, and a diff between them. Basically
      * we expect that the local image of the schema metadata ({@link #distributedKeyspaces}) and version ({@link #version})
@@ -691,20 +602,12 @@
     @VisibleForTesting
     public synchronized void mergeAndUpdateVersion(SchemaTransformationResult result, boolean dropData)
     {
-<<<<<<<
-=======
-        if (online)
-            SystemKeyspace.updateSchemaVersion(result.after.getVersion());
->>>>>>>
         result = localDiff(result);
         schemaChangeNotifier.notifyPreChanges(result);
         merge(result.diff, dropData);
         updateVersion(result.after.getVersion());
-<<<<<<<
-=======
         if (online)
             SystemKeyspace.updateSchemaVersion(result.after.getVersion());
->>>>>>>
     }
 
     public SchemaTransformationResult transform(SchemaTransformation transformation)
@@ -725,22 +628,6 @@
     {
         logger.debug("Clearing local schema...");
 
-<<<<<<<
-        CompletableFuture<Void> clearCompletion = updateHandler.clear();
-        try
-        {
-            clearCompletion.get(StorageService.SCHEMA_DELAY_MILLIS, TimeUnit.MILLISECONDS);
-        }
-        catch (TimeoutException | ExecutionException e)
-        {
-            throw new RuntimeException("Schema reset failed - no schema received from other nodes");
-        }
-        catch (InterruptedException e)
-        {
-            Thread.currentThread().interrupt();
-            throw new RuntimeException("Failed to reset schema - the thread has been interrupted");
-        }
-=======
         if (Gossiper.instance.getLiveMembers().stream().allMatch(ep -> FBUtilities.getBroadcastAddressAndPort().equals(ep)))
             throw new InvalidRequestException("Cannot reset local schema when there are no other live nodes");
 
@@ -757,7 +644,6 @@
             Thread.currentThread().interrupt();
             throw new RuntimeException("Failed to reset schema - the thread has been interrupted");
         }
->>>>>>>
         SchemaDiagnostics.schemaCleared(this);
         logger.info("Local schema reset completed");
     }
@@ -802,11 +688,7 @@
             Keyspace.open(delta.after.name, this, true).viewManager.reload(true);
         }
 
-<<<<<<<
-        schemaChangeNotifier.notifyKeyspaceAltered(delta);
-=======
         schemaChangeNotifier.notifyKeyspaceAltered(delta, dropData);
->>>>>>>
         SchemaDiagnostics.keyspaceAltered(this, delta);
     }
 
@@ -830,35 +712,6 @@
         }
     }
 
-<<<<<<<
-    private void dropKeyspace(KeyspaceMetadata keyspace, boolean dropData)
-    {
-        SchemaDiagnostics.keyspaceDropping(this, keyspace);
-
-        boolean initialized = Keyspace.isInitialized();
-        Keyspace ks = initialized ? getKeyspaceInstance(keyspace.name) : null;
-        if (initialized)
-        {
-            if (ks == null)
-                return;
-
-            keyspace.views.forEach(v -> dropView(ks, v, dropData));
-            keyspace.tables.forEach(t -> dropTable(ks, t, dropData));
-
-            // remove the keyspace from the static instances
-            maybeRemoveKeyspaceInstance(keyspace.name, dropData);
-        }
-
-        unload(keyspace);
-
-        if (initialized)
-        {
-            Keyspace.writeOrder.awaitNewBarrier();
-        }
-
-        schemaChangeNotifier.notifyKeyspaceDropped(keyspace);
-        SchemaDiagnostics.keyspaceDropped(this, keyspace);
-=======
     private void dropKeyspace(KeyspaceMetadata keyspaceMetadata, boolean dropData)
     {
         SchemaDiagnostics.keyspaceDropping(this, keyspaceMetadata);
@@ -889,7 +742,6 @@
 
         schemaChangeNotifier.notifyKeyspaceDropped(keyspaceMetadata, dropData);
         SchemaDiagnostics.keyspaceDropped(this, keyspaceMetadata);
->>>>>>>
     }
 
     private void dropView(Keyspace keyspace, ViewMetadata metadata, boolean dropData)
@@ -940,8 +792,4 @@
                : Collections.emptyMap();
     }
 
-<<<<<<<
-}
-=======
 }
->>>>>>>
--- a/src/java/org/apache/cassandra/schema/SchemaChangeListener.java
+++ b/src/java/org/apache/cassandra/schema/SchemaChangeListener.java
@@ -83,19 +83,6 @@
     {
     }
 
-<<<<<<<
-    default void onDropKeyspace(KeyspaceMetadata keyspace)
-    {
-    }
-
-    default void onDropTable(TableMetadata table)
-    {
-    }
-
-    default void onDropView(ViewMetadata view)
-    {
-        onDropTable(view.metadata);
-=======
     default void onDropKeyspace(KeyspaceMetadata keyspace, boolean dropData)
     {
     }
@@ -107,7 +94,6 @@
     default void onDropView(ViewMetadata view, boolean dropData)
     {
         onDropTable(view.metadata, dropData);
->>>>>>>
     }
 
     default void onDropType(UserType type)
--- a/src/java/org/apache/cassandra/schema/SchemaChangeNotifier.java
+++ b/src/java/org/apache/cassandra/schema/SchemaChangeNotifier.java
@@ -52,30 +52,17 @@
         keyspace.types.forEach(this::notifyCreateType);
         keyspace.tables.forEach(this::notifyCreateTable);
         keyspace.views.forEach(this::notifyCreateView);
-<<<<<<<
-        keyspace.functions.udfs().forEach(this::notifyCreateFunction);
-        keyspace.functions.udas().forEach(this::notifyCreateAggregate);
-    }
-
-    public void notifyKeyspaceAltered(KeyspaceMetadata.KeyspaceDiff delta)
-=======
         keyspace.userFunctions.udfs().forEach(this::notifyCreateFunction);
         keyspace.userFunctions.udas().forEach(this::notifyCreateAggregate);
     }
 
     public void notifyKeyspaceAltered(KeyspaceMetadata.KeyspaceDiff delta, boolean dropData)
->>>>>>>
     {
         // notify on everything dropped
         delta.udas.dropped.forEach(uda -> notifyDropAggregate((UDAggregate) uda));
         delta.udfs.dropped.forEach(udf -> notifyDropFunction((UDFunction) udf));
-<<<<<<<
-        delta.views.dropped.forEach(this::notifyDropView);
-        delta.tables.dropped.forEach(this::notifyDropTable);
-=======
         delta.views.dropped.forEach(view -> notifyDropView(view, dropData));
         delta.tables.dropped.forEach(metadata -> notifyDropTable(metadata, dropData));
->>>>>>>
         delta.types.dropped.forEach(this::notifyDropType);
 
         // notify on everything created
@@ -95,16 +82,6 @@
         delta.udas.altered.forEach(diff -> notifyAlterAggregate(diff.before, diff.after));
     }
 
-<<<<<<<
-    public void notifyKeyspaceDropped(KeyspaceMetadata keyspace)
-    {
-        keyspace.functions.udas().forEach(this::notifyDropAggregate);
-        keyspace.functions.udfs().forEach(this::notifyDropFunction);
-        keyspace.views.forEach(this::notifyDropView);
-        keyspace.tables.forEach(this::notifyDropTable);
-        keyspace.types.forEach(this::notifyDropType);
-        notifyDropKeyspace(keyspace);
-=======
     public void notifyKeyspaceDropped(KeyspaceMetadata keyspace, boolean dropData)
     {
         keyspace.userFunctions.udas().forEach(this::notifyDropAggregate);
@@ -113,7 +90,6 @@
         keyspace.tables.forEach(metadata -> notifyDropTable(metadata, dropData));
         keyspace.types.forEach(this::notifyDropType);
         notifyDropKeyspace(keyspace, dropData);
->>>>>>>
     }
 
     public void notifyPreChanges(SchemaTransformationResult transformationResult)
@@ -199,21 +175,6 @@
         changeListeners.forEach(l -> l.onAlterAggregate(before, after));
     }
 
-<<<<<<<
-    private void notifyDropKeyspace(KeyspaceMetadata ksm)
-    {
-        changeListeners.forEach(l -> l.onDropKeyspace(ksm));
-    }
-
-    private void notifyDropTable(TableMetadata metadata)
-    {
-        changeListeners.forEach(l -> l.onDropTable(metadata));
-    }
-
-    private void notifyDropView(ViewMetadata view)
-    {
-        changeListeners.forEach(l -> l.onDropView(view));
-=======
     private void notifyDropKeyspace(KeyspaceMetadata ksm, boolean dropData)
     {
         changeListeners.forEach(l -> l.onDropKeyspace(ksm, dropData));
@@ -227,7 +188,6 @@
     private void notifyDropView(ViewMetadata view, boolean dropData)
     {
         changeListeners.forEach(l -> l.onDropView(view, dropData));
->>>>>>>
     }
 
     private void notifyDropType(UserType ut)
--- a/src/java/org/apache/cassandra/schema/SchemaKeyspace.java
+++ b/src/java/org/apache/cassandra/schema/SchemaKeyspace.java
@@ -41,24 +41,10 @@
 import org.slf4j.LoggerFactory;
 
 import org.antlr.runtime.RecognitionException;
-<<<<<<<
 import org.apache.cassandra.config.*;
 import org.apache.cassandra.cql3.*;
 import org.apache.cassandra.cql3.functions.*;
 import org.apache.cassandra.cql3.functions.masking.ColumnMask;
-=======
-import org.apache.cassandra.config.CassandraRelevantProperties;
-import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.cql3.CQL3Type;
-import org.apache.cassandra.cql3.ColumnIdentifier;
-import org.apache.cassandra.cql3.FieldIdentifier;
-import org.apache.cassandra.cql3.Terms;
-import org.apache.cassandra.cql3.UntypedResultSet;
-import org.apache.cassandra.cql3.WhereClause;
-import org.apache.cassandra.cql3.functions.FunctionName;
-import org.apache.cassandra.cql3.functions.UDAggregate;
-import org.apache.cassandra.cql3.functions.UDFunction;
->>>>>>>
 import org.apache.cassandra.cql3.statements.schema.CreateTableStatement;
 import org.apache.cassandra.db.ColumnFamilyStore;
 import org.apache.cassandra.db.DecoratedKey;
@@ -70,6 +56,7 @@
 import org.apache.cassandra.db.ReadExecutionController;
 import org.apache.cassandra.db.filter.ColumnFilter;
 import org.apache.cassandra.db.marshal.AbstractType;
+import org.apache.cassandra.db.marshal.BooleanType;
 import org.apache.cassandra.db.marshal.BytesType;
 import org.apache.cassandra.db.marshal.ReversedType;
 import org.apache.cassandra.db.marshal.UTF8Type;
@@ -93,7 +80,6 @@
 import static java.lang.String.format;
 import static java.util.stream.Collectors.toList;
 import static java.util.stream.Collectors.toSet;
-<<<<<<<
 
 import static org.apache.cassandra.config.CassandraRelevantProperties.IGNORE_CORRUPTED_SCHEMA_TABLES;
 import static org.apache.cassandra.config.CassandraRelevantProperties.TEST_FLUSH_LOCAL_SCHEMA_CHANGES;
@@ -105,25 +91,6 @@
 /**
  * system_schema.* tables and methods for manipulating them.
  *
-=======
-import static org.apache.cassandra.cql3.QueryProcessor.executeInternal;
-import static org.apache.cassandra.cql3.QueryProcessor.executeOnceInternal;
-import static org.apache.cassandra.schema.SchemaKeyspaceTables.AGGREGATES;
-import static org.apache.cassandra.schema.SchemaKeyspaceTables.ALL;
-import static org.apache.cassandra.schema.SchemaKeyspaceTables.COLUMNS;
-import static org.apache.cassandra.schema.SchemaKeyspaceTables.DROPPED_COLUMNS;
-import static org.apache.cassandra.schema.SchemaKeyspaceTables.FUNCTIONS;
-import static org.apache.cassandra.schema.SchemaKeyspaceTables.INDEXES;
-import static org.apache.cassandra.schema.SchemaKeyspaceTables.KEYSPACES;
-import static org.apache.cassandra.schema.SchemaKeyspaceTables.TABLES;
-import static org.apache.cassandra.schema.SchemaKeyspaceTables.TRIGGERS;
-import static org.apache.cassandra.schema.SchemaKeyspaceTables.TYPES;
-import static org.apache.cassandra.schema.SchemaKeyspaceTables.VIEWS;
-
-/**
- * system_schema.* tables and methods for manipulating them.
- * 
->>>>>>>
  * Please notice this class is _not_ thread safe and all methods which reads or updates the data in schema keyspace
  * should be accessed only from the implementation of {@link SchemaUpdateHandler} in synchronized blocks.
  */
@@ -1148,11 +1115,7 @@
     }
 
     @VisibleForTesting
-<<<<<<<
     public static ColumnMetadata createColumnFromRow(UntypedResultSet.Row row, Types types, UserFunctions functions)
-=======
-    static ColumnMetadata createColumnFromRow(UntypedResultSet.Row row, Types types)
->>>>>>>
     {
         String keyspace = row.getString("keyspace_name");
         String table = row.getString("table_name");
--- a/src/java/org/apache/cassandra/schema/SchemaUpdateHandler.java
+++ b/src/java/org/apache/cassandra/schema/SchemaUpdateHandler.java
@@ -19,15 +19,9 @@
 package org.apache.cassandra.schema;
 
 import java.time.Duration;
-<<<<<<<
 
 import org.apache.cassandra.schema.SchemaTransformation.SchemaTransformationResult;
 import org.apache.cassandra.utils.concurrent.Awaitable;
-=======
-import java.util.concurrent.CompletableFuture;
-
-import org.apache.cassandra.schema.SchemaTransformation.SchemaTransformationResult;
->>>>>>>
 
 /**
  * Schema update handler is responsible for maintaining the shared schema and synchronizing it with other nodes in
@@ -80,9 +74,5 @@
      * <p/>
      * The returned awaitable is fulfilled when the schema is received and applied.
      */
-<<<<<<<
     Awaitable clear();
-=======
-    CompletableFuture<Void> clear();
->>>>>>>
 }
--- a/src/java/org/apache/cassandra/schema/SchemaUpdateHandlerFactoryProvider.java
+++ b/src/java/org/apache/cassandra/schema/SchemaUpdateHandlerFactoryProvider.java
@@ -25,38 +25,25 @@
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.utils.FBUtilities;
 
-<<<<<<<
-/**
- * Provides the instance of SchemaUpdateHandler factory pointed by {@link #SUH_FACTORY_CLASS_PROPERTY} system property.
-=======
 import static org.apache.cassandra.config.CassandraRelevantProperties.SCHEMA_UPDATE_HANDLER_FACTORY_CLASS;
 
 /**
  * Provides the instance of SchemaUpdateHandler factory pointed by
  * {@link org.apache.cassandra.config.CassandraRelevantProperties#SCHEMA_UPDATE_HANDLER_FACTORY_CLASS} system property.
->>>>>>>
  * If the property is not defined, the default factory {@link DefaultSchemaUpdateHandler} instance is returned.
  */
 public class SchemaUpdateHandlerFactoryProvider implements Provider<SchemaUpdateHandlerFactory>
 {
-<<<<<<<
     /** @deprecated Use CassandraRelevantProperties.SCHEMA_UPDATE_HANDLER_FACTORY_CLASS instead. */
     @Deprecated
     public static final String SUH_FACTORY_CLASS_PROPERTY = "cassandra.schema.update_handler_factory.class";
-=======
-    private static final String SUH_FACTORY_CLASS_PROPERTY = "cassandra.schema.update_handler_factory.class";
->>>>>>>
 
     public final static SchemaUpdateHandlerFactoryProvider instance = new SchemaUpdateHandlerFactoryProvider();
 
     @Override
     public SchemaUpdateHandlerFactory get()
     {
-<<<<<<<
         String suhFactoryClassName = StringUtils.trimToNull(SCHEMA_UPDATE_HANDLER_FACTORY_CLASS.getString());
-=======
-        String suhFactoryClassName = StringUtils.trimToNull(System.getProperty(SUH_FACTORY_CLASS_PROPERTY));
->>>>>>>
         if (suhFactoryClassName == null)
         {
             return DefaultSchemaUpdateHandlerFactory.instance;
@@ -71,11 +58,7 @@
             catch (InstantiationException | IllegalAccessException ex)
             {
                 throw new ConfigurationException(String.format("Failed to initialize schema update handler factory class %s defined in %s system property.",
-<<<<<<<
                                                                suhFactoryClassName, SCHEMA_UPDATE_HANDLER_FACTORY_CLASS.getKey()), ex);
-=======
-                                                               suhFactoryClassName, SUH_FACTORY_CLASS_PROPERTY), ex);
->>>>>>>
             }
         }
     }
--- a/src/java/org/apache/cassandra/schema/TableId.java
+++ b/src/java/org/apache/cassandra/schema/TableId.java
@@ -34,8 +34,6 @@
 
 import static java.nio.charset.StandardCharsets.UTF_8;
 
-import static java.nio.charset.StandardCharsets.UTF_8;
-
 /**
  * The unique identifier of a table.
  * <p>
@@ -99,16 +97,12 @@
      */
     public static TableId forSystemTable(String keyspace, String table)
     {
-<<<<<<<
-        assert SchemaConstants.isLocalSystemKeyspace(keyspace) || SchemaConstants.isReplicatedSystemKeyspace(keyspace);
-=======
         assert SchemaConstants.isSystemKeyspace(keyspace) : String.format("Table %s.%s is not a system table; only keyspaces allowed are %s", keyspace, table, SchemaConstants.getSystemKeyspaces());
         return unsafeDeterministic(keyspace, table);
     }
 
     public static TableId unsafeDeterministic(String keyspace, String table)
     {
->>>>>>>
         return new TableId(UUID.nameUUIDFromBytes(ArrayUtils.addAll(keyspace.getBytes(UTF_8), table.getBytes(UTF_8))));
     }
 
--- a/src/java/org/apache/cassandra/service/CassandraDaemon.java
+++ b/src/java/org/apache/cassandra/service/CassandraDaemon.java
@@ -41,14 +41,7 @@
 import com.codahale.metrics.Meter;
 import com.codahale.metrics.MetricRegistryListener;
 import com.codahale.metrics.SharedMetricRegistries;
-<<<<<<<
-
-=======
-import com.codahale.metrics.jvm.BufferPoolMetricSet;
-import com.codahale.metrics.jvm.FileDescriptorRatioGauge;
-import com.codahale.metrics.jvm.GarbageCollectorMetricSet;
-import com.codahale.metrics.jvm.MemoryUsageGaugeSet;
->>>>>>>
+
 import org.apache.cassandra.audit.AuditLogManager;
 import org.apache.cassandra.auth.AuthCacheService;
 import org.apache.cassandra.concurrent.ScheduledExecutors;
@@ -355,8 +348,6 @@
         // Re-populate token metadata after commit log recover (new peers might be loaded onto system keyspace #10293)
         StorageService.instance.populateTokenMetadata();
 
-<<<<<<<
-=======
         try
         {
             PaxosState.maybeRebuildUncommittedState();
@@ -366,7 +357,6 @@
             throw new RuntimeException(e);
         }
 
->>>>>>>
         // Clean up system.size_estimates entries left lying around from missed keyspace drops (CASSANDRA-14905)
         StorageService.instance.cleanupSizeEstimates();
 
--- a/src/java/org/apache/cassandra/service/PendingRangeCalculatorService.java
+++ b/src/java/org/apache/cassandra/service/PendingRangeCalculatorService.java
@@ -19,23 +19,6 @@
 package org.apache.cassandra.service;
 
 import java.util.Collection;
-<<<<<<<
-import java.util.concurrent.LinkedBlockingQueue;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.TimeoutException;
-import java.util.concurrent.atomic.AtomicInteger;
-
-import com.google.common.annotations.VisibleForTesting;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import org.apache.cassandra.concurrent.JMXEnabledThreadPoolExecutor;
-import org.apache.cassandra.concurrent.NamedThreadFactory;
-import org.apache.cassandra.db.Keyspace;
-import org.apache.cassandra.locator.AbstractReplicationStrategy;
-import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.utils.ExecutorUtils;
-=======
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
 
@@ -52,7 +35,6 @@
 
 import static org.apache.cassandra.concurrent.ExecutorFactory.Global.executorFactory;
 import static org.apache.cassandra.utils.Clock.Global.currentTimeMillis;
->>>>>>>
 
 public class PendingRangeCalculatorService
 {
@@ -81,50 +63,6 @@
 
     public PendingRangeCalculatorService()
     {
-<<<<<<<
-=======
-        executor.setRejectedExecutionHandler((r, e) ->
-            {
-                PendingRangeCalculatorServiceDiagnostics.taskRejected(instance, updateJobs);
-                PendingRangeCalculatorService.instance.finishUpdate();
-            }
-        );
-    }
-
-    private static class PendingRangeTask implements Runnable
-    {
-        private final AtomicInteger updateJobs;
-
-        PendingRangeTask(AtomicInteger updateJobs)
-        {
-            this.updateJobs = updateJobs;
-        }
-
-        public void run()
-        {
-            try
-            {
-                PendingRangeCalculatorServiceDiagnostics.taskStarted(instance, updateJobs);
-                long start = System.currentTimeMillis();
-                Collection<String> keyspaces = Schema.instance.getNonLocalStrategyKeyspaces().names();
-                for (String keyspaceName : keyspaces)
-                    calculatePendingRanges(Keyspace.open(keyspaceName).getReplicationStrategy(), keyspaceName);
-                if (logger.isTraceEnabled())
-                    logger.trace("Finished PendingRangeTask for {} keyspaces in {}ms", keyspaces.size(), System.currentTimeMillis() - start);
-                PendingRangeCalculatorServiceDiagnostics.taskFinished(instance, updateJobs);
-            }
-            finally
-            {
-                PendingRangeCalculatorService.instance.finishUpdate();
-            }
-        }
-    }
-
-    private void finishUpdate()
-    {
-        int jobs = updateJobs.decrementAndGet();
-        PendingRangeCalculatorServiceDiagnostics.taskCountChanged(instance, jobs);
->>>>>>>
     }
 
     public void update()
--- a/src/java/org/apache/cassandra/service/StorageService.java
+++ b/src/java/org/apache/cassandra/service/StorageService.java
@@ -25,14 +25,8 @@
 import java.net.InetSocketAddress;
 import java.net.UnknownHostException;
 import java.nio.ByteBuffer;
-<<<<<<<
-import java.nio.file.Paths;
-import java.time.Duration;
-import java.time.Instant;
-=======
 import java.time.Instant;
 import java.time.format.DateTimeParseException;
->>>>>>>
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
@@ -56,12 +50,6 @@
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.ExecutionException;
-<<<<<<<
-=======
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Future;
-import java.util.concurrent.FutureTask;
->>>>>>>
 import java.util.concurrent.ThreadLocalRandom;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
@@ -195,19 +183,13 @@
 import org.apache.cassandra.repair.messages.RepairOption;
 import org.apache.cassandra.schema.CompactionParams.TombstoneOption;
 import org.apache.cassandra.schema.KeyspaceMetadata;
-<<<<<<<
-=======
 import org.apache.cassandra.schema.Keyspaces;
->>>>>>>
 import org.apache.cassandra.schema.ReplicationParams;
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.SchemaConstants;
 import org.apache.cassandra.schema.SchemaTransformations;
-<<<<<<<
-=======
 import org.apache.cassandra.schema.SystemDistributedKeyspace;
 import org.apache.cassandra.schema.TableId;
->>>>>>>
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.TableMetadataRef;
 import org.apache.cassandra.schema.ViewMetadata;
@@ -282,8 +264,6 @@
 import static org.apache.cassandra.index.SecondaryIndexManager.isIndexColumnFamily;
 import static org.apache.cassandra.net.NoPayload.noPayload;
 import static org.apache.cassandra.net.Verb.REPLICATION_DONE_REQ;
-<<<<<<<
-=======
 import static org.apache.cassandra.service.ActiveRepairService.ParentRepairStatus;
 import static org.apache.cassandra.service.ActiveRepairService.repairCommandExecutor;
 import static org.apache.cassandra.service.StorageService.Mode.DECOMMISSIONED;
@@ -291,7 +271,6 @@
 import static org.apache.cassandra.service.StorageService.Mode.JOINING_FAILED;
 import static org.apache.cassandra.utils.Clock.Global.currentTimeMillis;
 import static org.apache.cassandra.utils.Clock.Global.nanoTime;
->>>>>>>
 import static org.apache.cassandra.utils.FBUtilities.getBroadcastAddressAndPort;
 import static org.apache.cassandra.utils.FBUtilities.now;
 
@@ -445,11 +424,7 @@
     /* the probability for tracing any particular request, 0 disables tracing and 1 enables for all */
     private double traceProbability = 0.0;
 
-<<<<<<<
-    private enum Mode { STARTING, NORMAL, JOINING, LEAVING, DECOMMISSIONED, MOVING, DRAINING, DRAINED }
-=======
     public enum Mode { STARTING, NORMAL, JOINING, JOINING_FAILED, LEAVING, DECOMMISSIONED, DECOMMISSION_FAILED, MOVING, DRAINING, DRAINED }
->>>>>>>
     private volatile Mode operationMode = Mode.STARTING;
 
     /* Used for tracking drain progress */
@@ -1069,11 +1044,7 @@
         if (replacing)
             return true;
 
-<<<<<<<
         if (REPLACE_ADDRESS_FIRST_BOOT.getString() != null && SystemKeyspace.bootstrapComplete())
-=======
-        if (System.getProperty("cassandra.replace_address_first_boot", null) != null && SystemKeyspace.bootstrapComplete())
->>>>>>>
         {
             logger.info("Replace address on the first boot requested; this node is already bootstrapped");
             return false;
@@ -1206,7 +1177,6 @@
         }
     }
 
-<<<<<<<
     @VisibleForTesting
     public void startSnapshotManager()
     {
@@ -1222,17 +1192,6 @@
 
         if (!Schema.instance.waitUntilReady(java.time.Duration.ofMillis(schemaTimeoutMillis)))
             throw new IllegalStateException("Could not achieve schema readiness in " + java.time.Duration.ofMillis(schemaTimeoutMillis));
-=======
-    public void waitForSchema(long schemaTimeoutMillis, long ringTimeoutMillis)
-    {
-        Instant deadline = Instant.now().plus(Duration.ofMillis(ringTimeoutMillis));
-
-        while (Schema.instance.isEmpty() && Instant.now().isBefore(deadline))
-            Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS);
-
-        if (!Schema.instance.waitUntilReady(Duration.ofMillis(schemaTimeoutMillis)))
-            throw new IllegalStateException("Could not achieve schema readiness in " + Duration.ofMillis(schemaTimeoutMillis));
->>>>>>>
     }
 
     private void joinTokenRing(long schemaTimeoutMillis, long ringTimeoutMillis) throws ConfigurationException
@@ -1390,11 +1349,7 @@
     private void executePreJoinTasks(boolean bootstrap)
     {
         StreamSupport.stream(ColumnFamilyStore.all().spliterator(), false)
-<<<<<<<
                 .filter(cfs -> Schema.instance.getUserKeyspaces().names().contains(cfs.getKeyspaceName()))
-=======
-                .filter(cfs -> Schema.instance.getUserKeyspaces().names().contains(cfs.keyspace.getName()))
->>>>>>>
                 .forEach(cfs -> cfs.indexManager.executePreJoinTasksBlocking(bootstrap));
     }
 
@@ -2071,7 +2026,6 @@
                     InetAddressAndPort existing = tokenMetadata.getEndpoint(token);
                     if (existing != null)
                     {
-<<<<<<<
                         EndpointState endpointStateForExisting = Gossiper.instance.getEndpointStateForEndpoint(existing);
                         long updateTimestamp = endpointStateForExisting.getUpdateTimestamp();
                         long allowedDelay = nanoTime() - nanoDelay;
@@ -2081,10 +2035,6 @@
                         {
                             logger.error("Unable to replace node for token={}. The node is reporting as {}alive with updateTimestamp={}, allowedDelay={}",
                                          token, endpointStateForExisting.isAlive() ? "" : "not ", updateTimestamp, allowedDelay);
-=======
-                        long nanoDelay = ringTimeoutMillis * 1000000L;
-                        if (Gossiper.instance.getEndpointStateForEndpoint(existing).getUpdateTimestamp() > (System.nanoTime() - nanoDelay))
->>>>>>>
                             throw new UnsupportedOperationException("Cannot replace a live node... ");
                         }
                         collisions.add(existing);
@@ -2210,12 +2160,8 @@
     /**
      * All MVs have been created during bootstrap, so mark them as built
      */
-<<<<<<<
     private void markViewsAsBuilt()
     {
-=======
-    private void markViewsAsBuilt() {
->>>>>>>
         for (String keyspace : Schema.instance.getUserKeyspaces().names())
         {
             for (ViewMetadata view: Schema.instance.getKeyspaceMetadata(keyspace).views)
@@ -5286,11 +5232,7 @@
             }
 
             startLeaving();
-<<<<<<<
             long timeout = Math.max(RING_DELAY_MILLIS, BatchlogManager.getBatchlogTimeout());
-=======
-            long timeout = Math.max(RING_DELAY_MILLIS, BatchlogManager.instance.getBatchlogTimeout());
->>>>>>>
             setMode(Mode.LEAVING, "sleeping " + timeout + " ms for batch processing and pending range setup", true);
             Thread.sleep(timeout);
 
--- a/src/java/org/apache/cassandra/tools/SSTableExpiredBlockers.java
+++ b/src/java/org/apache/cassandra/tools/SSTableExpiredBlockers.java
@@ -35,11 +35,8 @@
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.TableMetadata;
-<<<<<<<
-=======
 
 import static org.apache.cassandra.utils.Clock.Global.currentTimeMillis;
->>>>>>>
 
 /**
  * During compaction we can drop entire sstables if they only contain expired tombstones and if it is guaranteed
--- a/src/java/org/apache/cassandra/tools/SSTableOfflineRelevel.java
+++ b/src/java/org/apache/cassandra/tools/SSTableOfflineRelevel.java
@@ -42,10 +42,7 @@
 import org.apache.cassandra.io.sstable.Descriptor;
 import org.apache.cassandra.io.sstable.format.SSTableFormat.Components;
 import org.apache.cassandra.io.sstable.format.SSTableReader;
-<<<<<<<
-=======
 import org.apache.cassandra.io.util.File;
->>>>>>>
 import org.apache.cassandra.schema.Schema;
 
 /**
--- a/src/java/org/apache/cassandra/tools/StandaloneSSTableUtil.java
+++ b/src/java/org/apache/cassandra/tools/StandaloneSSTableUtil.java
@@ -18,24 +18,6 @@
  */
 package org.apache.cassandra.tools;
 
-<<<<<<<
-import java.io.File;
-import java.io.IOException;
-import java.util.function.BiPredicate;
-
-import org.apache.commons.cli.CommandLine;
-import org.apache.commons.cli.CommandLineParser;
-import org.apache.commons.cli.GnuParser;
-import org.apache.commons.cli.HelpFormatter;
-import org.apache.commons.cli.ParseException;
-
-import org.apache.cassandra.db.Directories;
-import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
-import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.schema.TableMetadata;
-import org.apache.cassandra.utils.OutputHandler;
-
-=======
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.db.Directories;
@@ -47,7 +29,6 @@
 import java.util.function.BiPredicate;
 
 import org.apache.cassandra.io.util.File;
->>>>>>>
 import static org.apache.cassandra.tools.BulkLoader.CmdLineOptions;
 
 public class StandaloneSSTableUtil
--- a/src/java/org/apache/cassandra/tools/StandaloneSplitter.java
+++ b/src/java/org/apache/cassandra/tools/StandaloneSplitter.java
@@ -18,19 +18,10 @@
  */
 package org.apache.cassandra.tools;
 
-<<<<<<<
-import java.io.File;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-=======
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
->>>>>>>
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -54,10 +45,7 @@
 import org.apache.cassandra.io.sstable.Descriptor;
 import org.apache.cassandra.io.sstable.SSTable;
 import org.apache.cassandra.io.sstable.format.SSTableReader;
-<<<<<<<
-=======
 import org.apache.cassandra.io.util.File;
->>>>>>>
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.utils.JVMStabilityInspector;
 
--- a/src/java/org/apache/cassandra/tools/StandaloneUpgrader.java
+++ b/src/java/org/apache/cassandra/tools/StandaloneUpgrader.java
@@ -39,10 +39,6 @@
 import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
 import org.apache.cassandra.io.sstable.Component;
 import org.apache.cassandra.io.sstable.Descriptor;
-<<<<<<<
-=======
-import org.apache.cassandra.io.sstable.format.SSTableFormat;
->>>>>>>
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.utils.JVMStabilityInspector;
--- a/src/java/org/apache/cassandra/tools/nodetool/stats/TableStatsHolder.java
+++ b/src/java/org/apache/cassandra/tools/nodetool/stats/TableStatsHolder.java
@@ -18,7 +18,6 @@
 
 package org.apache.cassandra.tools.nodetool.stats;
 
-<<<<<<<
 import java.text.DateFormat;
 import java.text.SimpleDateFormat;
 import java.util.*;
@@ -35,23 +34,6 @@
 import org.apache.cassandra.io.util.*;
 import org.apache.cassandra.metrics.*;
 import org.apache.cassandra.tools.*;
-=======
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import javax.management.InstanceNotFoundException;
-
-import com.google.common.collect.ArrayListMultimap;
-
-import org.apache.cassandra.db.ColumnFamilyStoreMBean;
-import org.apache.cassandra.io.util.FileUtils;
-import org.apache.cassandra.metrics.CassandraMetricsRegistry;
-import org.apache.cassandra.tools.NodeProbe;
->>>>>>>
 
 public class TableStatsHolder implements StatsHolder
 {
--- a/src/java/org/apache/cassandra/transport/Server.java
+++ b/src/java/org/apache/cassandra/transport/Server.java
@@ -55,14 +55,7 @@
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.SchemaChangeListener;
 import org.apache.cassandra.schema.TableMetadata;
-<<<<<<<
 import org.apache.cassandra.service.*;
-=======
-import org.apache.cassandra.service.CassandraDaemon;
-import org.apache.cassandra.service.IEndpointLifecycleSubscriber;
-import org.apache.cassandra.service.NativeTransportService;
-import org.apache.cassandra.service.StorageService;
->>>>>>>
 import org.apache.cassandra.transport.messages.EventMessage;
 import org.apache.cassandra.utils.FBUtilities;
 
@@ -553,21 +546,13 @@
         }
 
         @Override
-<<<<<<<
-        public void onDropKeyspace(KeyspaceMetadata keyspace)
-=======
         public void onDropKeyspace(KeyspaceMetadata keyspace, boolean dropData)
->>>>>>>
         {
             send(new Event.SchemaChange(Event.SchemaChange.Change.DROPPED, keyspace.name));
         }
 
         @Override
-<<<<<<<
-        public void onDropTable(TableMetadata table)
-=======
         public void onDropTable(TableMetadata table, boolean dropData)
->>>>>>>
         {
             send(new Event.SchemaChange(Event.SchemaChange.Change.DROPPED, Event.SchemaChange.Target.TABLE, table.keyspace, table.name));
         }
--- a/src/java/org/apache/cassandra/utils/FBUtilities.java
+++ b/src/java/org/apache/cassandra/utils/FBUtilities.java
@@ -20,10 +20,6 @@
 import java.io.BufferedReader;
 import java.io.ByteArrayOutputStream;
 import java.io.DataOutputStream;
-<<<<<<<
-=======
-import java.io.File;
->>>>>>>
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
@@ -38,19 +34,11 @@
 import java.nio.ByteBuffer;
 import java.security.MessageDigest;
 import java.security.NoSuchAlgorithmException;
-<<<<<<<
-import java.time.Duration;
-=======
 import java.time.Instant;
->>>>>>>
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Comparator;
-<<<<<<<
-=======
-import java.util.EnumSet;
->>>>>>>
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
@@ -58,19 +46,12 @@
 import java.util.Optional;
 import java.util.Properties;
 import java.util.TreeSet;
-<<<<<<<
-=======
-import java.util.concurrent.CompletableFuture;
->>>>>>>
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
-<<<<<<<
-=======
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
->>>>>>>
 import java.util.zip.CRC32;
 import java.util.zip.Checksum;
 import javax.annotation.Nonnull;
@@ -78,22 +59,11 @@
 
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.base.Joiner;
-<<<<<<<
-import com.google.common.base.Preconditions;
-import com.google.common.base.Strings;
-import com.google.common.util.concurrent.Uninterruptibles;
-=======
 import com.google.common.collect.ImmutableList;
->>>>>>>
 import org.apache.commons.lang3.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-<<<<<<<
-=======
-import com.fasterxml.jackson.core.JsonFactory;
-import com.fasterxml.jackson.databind.ObjectMapper;
->>>>>>>
 import org.apache.cassandra.audit.IAuditLogger;
 import org.apache.cassandra.auth.AllowAllNetworkAuthorizer;
 import org.apache.cassandra.auth.IAuthenticator;
@@ -582,56 +552,7 @@
         }
     }
 
-<<<<<<<
     public static <T, F extends Future<? extends T>> F waitOnFirstFuture(Iterable<? extends F> futures)
-=======
-    public static <T> T waitOnFuture(Future<T> future, Duration timeout)
-    {
-        Preconditions.checkArgument(!timeout.isNegative(), "Timeout must not be negative, provided %s", timeout);
-        try
-        {
-            return future.get(timeout.toNanos(), TimeUnit.NANOSECONDS);
-        }
-        catch (ExecutionException ee)
-        {
-            logger.info("Exception occurred in async code", ee);
-            throw Throwables.cleaned(ee);
-        }
-        catch (InterruptedException ie)
-        {
-            throw new AssertionError(ie);
-        }
-        catch (TimeoutException e)
-        {
-            throw new RuntimeException("Timeout - task did not finish in " + timeout, e);
-        }
-    }
-
-    public static boolean await(Future<?> future, Duration timeout)
-    {
-        Preconditions.checkArgument(!timeout.isNegative(), "Timeout must not be negative, provided %s", timeout);
-        try
-        {
-            future.get(timeout.toNanos(), TimeUnit.NANOSECONDS);
-            return true;
-        }
-        catch (ExecutionException ee)
-        {
-            logger.info("Exception occurred in async code", ee);
-            throw Throwables.cleaned(ee);
-        }
-        catch (InterruptedException ie)
-        {
-            throw new AssertionError(ie);
-        }
-        catch (TimeoutException e)
-        {
-            return false;
-        }
-    }
-
-    public static <T> Future<? extends T> waitOnFirstFuture(Iterable<? extends Future<? extends T>> futures)
->>>>>>>
     {
         return waitOnFirstFuture(futures, 100);
     }
--- a/test/distributed/org/apache/cassandra/distributed/action/GossipHelper.java
+++ b/test/distributed/org/apache/cassandra/distributed/action/GossipHelper.java
@@ -29,11 +29,8 @@
 import java.util.List;
 import java.util.Map;
 import java.util.UUID;
-<<<<<<<
-=======
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
->>>>>>>
 
 import org.apache.cassandra.config.CassandraRelevantProperties;
 import org.apache.cassandra.dht.IPartitioner;
@@ -246,11 +243,7 @@
                 InetAddressAndPort endpoint = toCassandraInetAddressAndPort(pullFrom);
                 EndpointState state = Gossiper.instance.getEndpointStateForEndpoint(endpoint);
                 Gossiper.instance.doOnChangeNotifications(endpoint, ApplicationState.SCHEMA, state.getApplicationState(ApplicationState.SCHEMA));
-<<<<<<<
-                Schema.instance.waitUntilReady(Duration.ofSeconds(10));
-=======
                 assertTrue("schema is ready", Schema.instance.waitUntilReady(Duration.ofSeconds(10)));
->>>>>>>
             }).accept(pullFrom);
         }
     }
--- a/test/distributed/org/apache/cassandra/distributed/impl/Instance.java
+++ b/test/distributed/org/apache/cassandra/distributed/impl/Instance.java
@@ -695,7 +695,6 @@
                 StorageService.instance.registerDaemon(CassandraDaemon.getInstanceForTesting());
                 if (config.has(GOSSIP))
                 {
-<<<<<<<
                     MigrationCoordinator.setUptimeFn(() -> TimeUnit.NANOSECONDS.toMillis(nanoTime() - startedAt.get()));
                     try
                     {
@@ -709,9 +708,6 @@
                             throw new RuntimeException("Unable to bind, run the following in a termanl and try again:\nfor subnet in $(seq 0 5); do for id in $(seq 0 5); do sudo ifconfig lo0 alias \"127.0.$subnet.$id\"; done; done;", e);
                         throw e;
                     }
-=======
-                    StorageService.instance.initServer();
->>>>>>>
                     StorageService.instance.removeShutdownHook();
 
                     Gossiper.waitToSettle();
@@ -719,7 +715,6 @@
                 else
                 {
                     Schema.instance.startSync();
-<<<<<<<
                     Stream peers = cluster.stream().filter(instance -> ((IInstance) instance).isValid());
                     SystemKeyspace.setLocalHostId(config.hostId());
                     if (config.has(BLANK_GOSSIP))
@@ -728,14 +723,6 @@
                         peers.forEach(peer -> GossipHelper.statusToNormal((IInvokableInstance) peer).accept(this));
                     else
                         peers.forEach(peer -> GossipHelper.unsafeStatusToNormal(this, (IInstance) peer));
-=======
-                    cluster.stream().forEach(peer -> {
-                        if (cluster instanceof Cluster)
-                            GossipHelper.statusToNormal((IInvokableInstance) peer).accept(this);
-                        else
-                            GossipHelper.unsafeStatusToNormal(this, (IInstance) peer);
-                    });
->>>>>>>
 
                     StorageService.instance.setUpDistributedSystemKeyspaces();
                     StorageService.instance.setNormalModeUnsafe();
@@ -748,10 +735,6 @@
                 // see org.apache.cassandra.service.CassandraDaemon.setup
                 StorageService.instance.populateTokenMetadata();
 
-<<<<<<<
-=======
-                StorageService.instance.doAuthSetup(false);
->>>>>>>
                 CassandraDaemon.getInstanceForTesting().completeSetup();
 
                 if (config.has(NATIVE_PROTOCOL))
--- a/test/distributed/org/apache/cassandra/distributed/test/SchemaTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/SchemaTest.java
@@ -18,18 +18,9 @@
 
 package org.apache.cassandra.distributed.test;
 
-<<<<<<<
-import java.time.Duration;
 import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
-import com.google.common.util.concurrent.Futures;
-import com.google.common.util.concurrent.Uninterruptibles;
-=======
-import java.util.concurrent.Future;
-import java.util.concurrent.TimeUnit;
-
->>>>>>>
 import org.junit.Test;
 
 import org.apache.cassandra.config.CassandraRelevantProperties;
@@ -38,19 +29,10 @@
 import org.apache.cassandra.distributed.api.ConsistencyLevel;
 import org.apache.cassandra.distributed.api.Feature;
 import org.apache.cassandra.distributed.api.IInvokableInstance;
-<<<<<<<
-=======
-import org.apache.cassandra.distributed.api.IIsolatedExecutor;
->>>>>>>
 import org.apache.cassandra.distributed.api.IIsolatedExecutor.SerializableCallable;
 import org.apache.cassandra.gms.Gossiper;
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.SchemaConstants;
-<<<<<<<
-=======
-import org.apache.cassandra.service.StorageService;
-import org.apache.cassandra.utils.FBUtilities;
->>>>>>>
 import org.assertj.core.api.Assertions;
 import org.awaitility.Awaitility;
 import org.awaitility.core.ConditionFactory;
@@ -143,10 +125,6 @@
      * In the second phase of the test we simply break the schema on the 1st node and call reset to fetch the schema
      * definition it from the 2nd node.
      */
-<<<<<<<
-=======
-    @SuppressWarnings("Convert2MethodRef")
->>>>>>>
     @Test
     public void schemaReset() throws Throwable
     {
@@ -167,21 +145,6 @@
                                         .allMatch(e -> e.equals(getBroadcastAddressAndPort()));
             }));
 
-<<<<<<<
-            // now, let's make a disagreement, the shutdown node 2 has a definition of TABLE_ONE, while the running
-            // node 1 will have a definition of TABLE_TWO
-            cluster.coordinator(1).execute(String.format("DROP TABLE %s.%s", KEYSPACE, TABLE_ONE), ConsistencyLevel.ONE);
-            cluster.coordinator(1).execute(String.format("CREATE TABLE %s.%s (pk INT PRIMARY KEY, v TEXT)", KEYSPACE, TABLE_TWO), ConsistencyLevel.ONE);
-            await(30).until(() -> checkTablesPropagated(cluster.get(1), false, true));
-
-            // Schema.resetLocalSchema is guarded by some conditions which would not let us reset schema if there is no
-            // live node in the cluster, therefore we simply call SchemaUpdateHandler.clear (this is the only real thing
-            // being done by Schema.resetLocalSchema under the hood)
-            SerializableCallable<Boolean> clear = () -> FBUtilities.await(Schema.instance.updateHandler.clear(), Duration.ofMinutes(1));
-            Future<Boolean> clear1 = cluster.get(1).asyncCallsOnInstance(clear).call();
-            assertFalse(clear1.isDone());
-
-=======
             // when there is no node to fetch the schema from, reset local schema should immediately fail
             Assertions.assertThatExceptionOfType(RuntimeException.class).isThrownBy(() -> {
                 cluster.get(1).runOnInstance(() -> Schema.instance.resetLocalSchema());
@@ -200,7 +163,6 @@
             Future<Boolean> clear1 = cluster.get(1).asyncCallsOnInstance(clear).call();
             assertFalse(clear1.isDone());
 
->>>>>>>
             // when the 2nd node is started, schema should be back in sync
             cluster.get(2).startup();
             await(30).until(() -> clear1.isDone() && clear1.get());
--- a/test/distributed/org/apache/cassandra/distributed/test/ring/BootstrapTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/ring/BootstrapTest.java
@@ -19,11 +19,8 @@
 package org.apache.cassandra.distributed.test.ring;
 
 import java.lang.management.ManagementFactory;
-<<<<<<<
-=======
 import java.util.HashSet;
 import java.util.List;
->>>>>>>
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.Callable;
@@ -32,7 +29,6 @@
 
 import org.junit.After;
 import org.junit.Assert;
-<<<<<<<
 import org.junit.AssumptionViolatedException;
 import org.junit.Before;
 import org.junit.Test;
@@ -46,12 +42,6 @@
 import org.apache.cassandra.db.SystemKeyspace;
 import org.apache.cassandra.dht.Range;
 import org.apache.cassandra.dht.Token;
-=======
-import org.junit.Before;
-import org.junit.Test;
-
-import org.apache.cassandra.config.CassandraRelevantProperties;
->>>>>>>
 import org.apache.cassandra.distributed.Cluster;
 import org.apache.cassandra.distributed.api.ConsistencyLevel;
 import org.apache.cassandra.distributed.api.ICluster;
@@ -84,11 +74,8 @@
 {
     private long savedMigrationDelay;
 
-<<<<<<<
-=======
     static WithProperties properties;
 
->>>>>>>
     @Before
     public void beforeTest()
     {
@@ -98,22 +85,13 @@
         // When we are running multiple test cases in the class, where each starts a node but in the same JVM, the
         // up-time will be more or less relevant only for the first test. In order to enforce the startup-like behaviour
         // for each test case, the MIGRATION_DELAY time is adjusted accordingly
-<<<<<<<
         properties = new WithProperties().set(MIGRATION_DELAY, ManagementFactory.getRuntimeMXBean().getUptime() + savedMigrationDelay);
-=======
-        savedMigrationDelay = CassandraRelevantProperties.MIGRATION_DELAY.getLong();
-        CassandraRelevantProperties.MIGRATION_DELAY.setLong(ManagementFactory.getRuntimeMXBean().getUptime() + savedMigrationDelay);
->>>>>>>
     }
 
     @After
     public void afterTest()
     {
-<<<<<<<
-        CassandraRelevantProperties.MIGRATION_DELAY.setLong(savedMigrationDelay);
-=======
         properties.close();
->>>>>>>
     }
 
     @Test
--- a/test/microbench/org/apache/cassandra/test/microbench/BatchStatementBench.java
+++ b/test/microbench/org/apache/cassandra/test/microbench/BatchStatementBench.java
@@ -42,10 +42,7 @@
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.SchemaTestUtil;
 import org.apache.cassandra.schema.TableMetadata;
-<<<<<<<
-=======
 import org.apache.cassandra.service.ClientState;
->>>>>>>
 import org.apache.cassandra.utils.FBUtilities;
 import org.openjdk.jmh.annotations.Benchmark;
 import org.openjdk.jmh.annotations.BenchmarkMode;
--- a/test/microbench/org/apache/cassandra/test/microbench/MutationBench.java
+++ b/test/microbench/org/apache/cassandra/test/microbench/MutationBench.java
@@ -26,12 +26,9 @@
 
 import org.apache.cassandra.UpdateBuilder;
 import org.apache.cassandra.config.DatabaseDescriptor;
-<<<<<<<
 import org.apache.cassandra.cql3.statements.schema.CreateTableStatement;
-=======
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.SchemaTestUtil;
->>>>>>>
 import org.apache.cassandra.db.Mutation;
 import org.apache.cassandra.dht.Murmur3Partitioner;
 import org.apache.cassandra.io.util.DataInputBuffer;
@@ -40,8 +37,6 @@
 import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.KeyspaceParams;
-import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.schema.SchemaTestUtil;
 import org.apache.cassandra.schema.TableMetadata;
 import org.openjdk.jmh.annotations.Benchmark;
 import org.openjdk.jmh.annotations.BenchmarkMode;
--- a/test/unit/org/apache/cassandra/SchemaLoader.java
+++ b/test/unit/org/apache/cassandra/SchemaLoader.java
@@ -24,12 +24,6 @@
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
-<<<<<<<
-=======
-
-import org.junit.After;
-import org.junit.BeforeClass;
->>>>>>>
 
 import org.apache.cassandra.auth.AuthKeyspace;
 import org.apache.cassandra.auth.AuthSchemaChangeListener;
@@ -63,7 +57,6 @@
 import org.apache.cassandra.index.StubIndex;
 import org.apache.cassandra.index.sasi.SASIIndex;
 import org.apache.cassandra.index.sasi.disk.OnDiskIndexBuilder;
-<<<<<<<
 import org.apache.cassandra.schema.*;
 import org.apache.cassandra.utils.ByteBufferUtil;
 import org.apache.cassandra.utils.FBUtilities;
@@ -76,26 +69,6 @@
 import static org.apache.cassandra.config.CassandraRelevantProperties.TEST_COMPRESSION_ALGO;
 import static org.apache.cassandra.utils.Clock.Global.currentTimeMillis;
 
-=======
-import org.apache.cassandra.schema.CachingParams;
-import org.apache.cassandra.schema.ColumnMetadata;
-import org.apache.cassandra.schema.CompactionParams;
-import org.apache.cassandra.schema.CompressionParams;
-import org.apache.cassandra.schema.Functions;
-import org.apache.cassandra.schema.IndexMetadata;
-import org.apache.cassandra.schema.Indexes;
-import org.apache.cassandra.schema.KeyspaceMetadata;
-import org.apache.cassandra.schema.KeyspaceParams;
-import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.schema.SchemaTestUtil;
-import org.apache.cassandra.schema.TableMetadata;
-import org.apache.cassandra.schema.Tables;
-import org.apache.cassandra.schema.Types;
-import org.apache.cassandra.schema.Views;
-import org.apache.cassandra.utils.ByteBufferUtil;
-import org.apache.cassandra.utils.FBUtilities;
-
->>>>>>>
 public class SchemaLoader
 {
     @BeforeClass
@@ -318,11 +291,7 @@
 
     public static void createKeyspace(String name, KeyspaceParams params, Tables tables, Types types)
     {
-<<<<<<<
-        SchemaTestUtil.announceNewKeyspace(KeyspaceMetadata.create(name, params, tables, Views.none(), types, Functions.none()));
-=======
         SchemaTestUtil.announceNewKeyspace(KeyspaceMetadata.create(name, params, tables, Views.none(), types, UserFunctions.none()));
->>>>>>>
     }
 
     public static void setupAuth(IRoleManager roleManager, IAuthenticator authenticator, IAuthorizer authorizer, INetworkAuthorizer networkAuthorizer,
@@ -332,10 +301,7 @@
         DatabaseDescriptor.setAuthenticator(authenticator);
         DatabaseDescriptor.setAuthorizer(authorizer);
         DatabaseDescriptor.setNetworkAuthorizer(networkAuthorizer);
-<<<<<<<
-=======
         DatabaseDescriptor.setCIDRAuthorizer(cidrAuthorizer);
->>>>>>>
         SchemaTestUtil.announceNewKeyspace(AuthKeyspace.metadata());
         DatabaseDescriptor.getRoleManager().setup();
         DatabaseDescriptor.getAuthenticator().setup();
--- a/test/unit/org/apache/cassandra/cql3/CQLTester.java
+++ b/test/unit/org/apache/cassandra/cql3/CQLTester.java
@@ -26,10 +26,7 @@
 import java.net.ServerSocket;
 import java.nio.ByteBuffer;
 import java.rmi.server.RMISocketFactory;
-<<<<<<<
-=======
 import java.util.AbstractList;
->>>>>>>
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
@@ -53,11 +50,8 @@
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 import java.util.stream.Collectors;
-<<<<<<<
-=======
 import java.util.stream.Stream;
 import javax.annotation.Nullable;
->>>>>>>
 import javax.management.MBeanServerConnection;
 import javax.management.remote.JMXConnector;
 import javax.management.remote.JMXConnectorFactory;
@@ -69,11 +63,7 @@
 import com.google.common.base.Strings;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Iterables;
-<<<<<<<
-
-=======
 import org.apache.commons.lang3.ArrayUtils;
->>>>>>>
 import org.junit.After;
 import org.junit.AfterClass;
 import org.junit.Assert;
@@ -82,10 +72,7 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-<<<<<<<
-=======
 import com.codahale.metrics.Gauge;
->>>>>>>
 import com.datastax.driver.core.CloseFuture;
 import com.datastax.driver.core.Cluster;
 import com.datastax.driver.core.ColumnDefinitions;
@@ -101,11 +88,6 @@
 import com.datastax.driver.core.UserType;
 import com.datastax.driver.core.exceptions.UnauthorizedException;
 import com.datastax.shaded.netty.channel.EventLoopGroup;
-import com.datastax.driver.core.Row;
-import com.datastax.driver.core.Session;
-import com.datastax.driver.core.SimpleStatement;
-import com.datastax.driver.core.SocketOptions;
-import com.datastax.driver.core.Statement;
 import org.apache.cassandra.SchemaLoader;
 import org.apache.cassandra.ServerTestUtils;
 import org.apache.cassandra.Util;
@@ -115,7 +97,6 @@
 import org.apache.cassandra.auth.AuthTestUtils;
 import org.apache.cassandra.auth.IRoleManager;
 import org.apache.cassandra.concurrent.ScheduledExecutors;
-<<<<<<<
 import org.apache.cassandra.concurrent.Stage;
 import org.apache.cassandra.config.CassandraRelevantProperties;
 import org.apache.cassandra.config.DataStorageSpec;
@@ -130,16 +111,6 @@
 import org.apache.cassandra.db.marshal.AbstractType;
 import org.apache.cassandra.db.marshal.BooleanType;
 import org.apache.cassandra.db.marshal.ByteBufferAccessor;
-=======
-import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.config.EncryptionOptions;
-import org.apache.cassandra.cql3.functions.FunctionName;
-import org.apache.cassandra.db.ColumnFamilyStore;
-import org.apache.cassandra.db.Directories;
-import org.apache.cassandra.db.Keyspace;
-import org.apache.cassandra.db.marshal.AbstractType;
-import org.apache.cassandra.db.marshal.BooleanType;
->>>>>>>
 import org.apache.cassandra.db.marshal.ByteType;
 import org.apache.cassandra.db.marshal.BytesType;
 import org.apache.cassandra.db.marshal.CollectionType;
@@ -155,25 +126,18 @@
 import org.apache.cassandra.db.marshal.MapType;
 import org.apache.cassandra.db.marshal.SetType;
 import org.apache.cassandra.db.marshal.ShortType;
-<<<<<<<
-=======
 import org.apache.cassandra.db.marshal.TimeUUIDType;
->>>>>>>
 import org.apache.cassandra.db.marshal.TimestampType;
 import org.apache.cassandra.db.marshal.TupleType;
 import org.apache.cassandra.db.marshal.UTF8Type;
 import org.apache.cassandra.db.marshal.UUIDType;
-<<<<<<<
-=======
 import org.apache.cassandra.db.marshal.VectorType;
->>>>>>>
 import org.apache.cassandra.db.virtual.VirtualKeyspaceRegistry;
 import org.apache.cassandra.db.virtual.VirtualSchemaKeyspace;
 import org.apache.cassandra.dht.Murmur3Partitioner;
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.exceptions.InvalidRequestException;
 import org.apache.cassandra.exceptions.SyntaxException;
-<<<<<<<
 import org.apache.cassandra.index.Index;
 import org.apache.cassandra.index.SecondaryIndexManager;
 import org.apache.cassandra.io.filesystem.ListenableFileSystem;
@@ -183,32 +147,20 @@
 import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.locator.TokenMetadata;
 import org.apache.cassandra.metrics.CassandraMetricsRegistry;
-=======
-import org.apache.cassandra.index.SecondaryIndexManager;
-import org.apache.cassandra.io.util.FileUtils;
-import org.apache.cassandra.locator.InetAddressAndPort;
-import org.apache.cassandra.locator.TokenMetadata;
->>>>>>>
 import org.apache.cassandra.metrics.ClientMetrics;
 import org.apache.cassandra.schema.IndexMetadata;
 import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.SchemaConstants;
-<<<<<<<
-=======
 import org.apache.cassandra.schema.SchemaKeyspace;
 import org.apache.cassandra.schema.SchemaTestUtil;
->>>>>>>
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.serializers.TypeSerializer;
 import org.apache.cassandra.service.ClientState;
 import org.apache.cassandra.service.QueryState;
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.transport.Event;
-<<<<<<<
-=======
 import org.apache.cassandra.transport.Message;
->>>>>>>
 import org.apache.cassandra.transport.ProtocolVersion;
 import org.apache.cassandra.transport.Server;
 import org.apache.cassandra.transport.SimpleClient;
--- a/test/unit/org/apache/cassandra/cql3/KeyCacheCqlTest.java
+++ b/test/unit/org/apache/cassandra/cql3/KeyCacheCqlTest.java
@@ -30,10 +30,7 @@
 
 import org.apache.cassandra.cache.KeyCacheKey;
 import org.apache.cassandra.config.DatabaseDescriptor;
-<<<<<<<
-=======
 import org.apache.cassandra.db.ColumnFamilyStore;
->>>>>>>
 import org.apache.cassandra.db.Keyspace;
 import org.apache.cassandra.index.Index;
 import org.apache.cassandra.io.sstable.filter.BloomFilterMetrics;
--- a/test/unit/org/apache/cassandra/cql3/ViewSchemaTest.java
+++ b/test/unit/org/apache/cassandra/cql3/ViewSchemaTest.java
@@ -27,42 +27,21 @@
 import java.util.HashSet;
 import java.util.UUID;
 
-import org.junit.After;
 import org.junit.Assert;
-<<<<<<<
-import org.junit.Before;
-import org.junit.BeforeClass;
 import org.junit.Test;
 
 import com.datastax.driver.core.exceptions.InvalidQueryException;
-import com.datastax.driver.core.exceptions.OperationTimedOutException;
-import org.apache.cassandra.concurrent.SEPExecutor;
-import org.apache.cassandra.concurrent.Stage;
 import org.apache.cassandra.db.ColumnFamilyStore;
 import org.apache.cassandra.db.Keyspace;
 import org.apache.cassandra.db.SchemaCQLHelper;
-import org.apache.cassandra.db.SystemKeyspace;
-=======
-import org.junit.Test;
-
-import com.datastax.driver.core.exceptions.InvalidQueryException;
-import org.apache.cassandra.db.ColumnFamilyStore;
-import org.apache.cassandra.db.Keyspace;
-import org.apache.cassandra.db.SchemaCQLHelper;
->>>>>>>
 import org.apache.cassandra.exceptions.InvalidRequestException;
 import org.apache.cassandra.schema.ColumnMetadata;
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.serializers.SimpleDateSerializer;
 import org.apache.cassandra.serializers.TimeSerializer;
-<<<<<<<
-import org.apache.cassandra.transport.ProtocolVersion;
-import org.apache.cassandra.utils.ByteBufferUtil;
-=======
 import org.apache.cassandra.utils.ByteBufferUtil;
 import org.assertj.core.api.Assertions;
->>>>>>>
 
 import static org.junit.Assert.assertTrue;
 
@@ -878,11 +857,7 @@
 
         Keyspace keyspace = Keyspace.open(keyspace());
         ColumnFamilyStore mv = keyspace.getColumnFamilyStore(view);
-<<<<<<<
         assertTrue(SchemaCQLHelper.getTableMetadataAsCQL(mv.metadata(), keyspace.getMetadata())
-=======
-        assertTrue(SchemaCQLHelper.getTableMetadataAsCQL(mv.metadata(), true, true, true, keyspace.getMetadata())
->>>>>>>
                                   .startsWith(String.format(viewSnapshotSchema,
                                                             keyspace(),
                                                             view,
--- a/test/unit/org/apache/cassandra/cql3/validation/entities/TupleTypeTest.java
+++ b/test/unit/org/apache/cassandra/cql3/validation/entities/TupleTypeTest.java
@@ -33,13 +33,10 @@
 
 import org.apache.cassandra.cql3.CQLTester;
 import org.apache.cassandra.cql3.UntypedResultSet;
-<<<<<<<
-=======
 import org.apache.cassandra.db.marshal.AbstractType;
 import org.apache.cassandra.db.marshal.ByteBufferAccessor;
 import org.apache.cassandra.db.marshal.DecimalType;
 import org.apache.cassandra.db.marshal.DurationType;
->>>>>>>
 import org.apache.cassandra.db.marshal.TupleType;
 import org.apache.cassandra.utils.AbstractTypeGenerators;
 import org.apache.cassandra.utils.AbstractTypeGenerators.TypeSupport;
--- a/test/unit/org/apache/cassandra/cql3/validation/entities/UFTest.java
+++ b/test/unit/org/apache/cassandra/cql3/validation/entities/UFTest.java
@@ -851,11 +851,7 @@
                                                             "java",
                                                             f.body(),
                                                             new InvalidRequestException("foo bar is broken"));
-<<<<<<<
-        SchemaTestUtil.addOrUpdateKeyspace(ksm.withSwapped(ksm.functions.without(f.name(), f.argTypes()).with(broken)), false);
-=======
         SchemaTestUtil.addOrUpdateKeyspace(ksm.withSwapped(ksm.userFunctions.without(f.name(), f.argTypes()).with(broken)), false);
->>>>>>>
 
         assertInvalidThrowMessage("foo bar is broken", InvalidRequestException.class,
                                   "SELECT key, " + fName + "(dval) FROM %s");
--- a/test/unit/org/apache/cassandra/cql3/validation/operations/CompactStorageSplit2Test.java
+++ b/test/unit/org/apache/cassandra/cql3/validation/operations/CompactStorageSplit2Test.java
@@ -2269,11 +2269,7 @@
 
         ColumnFamilyStore cfs = Keyspace.open(keyspace).getColumnFamilyStore(table);
 
-<<<<<<<
         String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), cfs.keyspace.getMetadata());
-=======
-        String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), true, true, true, cfs.keyspace.getMetadata());
->>>>>>>
         String expected = "CREATE TABLE IF NOT EXISTS cql_test_keyspace_compact.test_table_compact (\n" +
                           "    pk1 varint,\n" +
                           "    pk2 ascii,\n" +
@@ -2309,11 +2305,7 @@
 
         ColumnFamilyStore cfs = Keyspace.open(keyspace).getColumnFamilyStore(table);
 
-<<<<<<<
         String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), cfs.keyspace.getMetadata());
-=======
-        String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), true, true, true, cfs.keyspace.getMetadata());
->>>>>>>
         String expected = "CREATE TABLE IF NOT EXISTS cql_test_keyspace_counter.test_table_counter (\n" +
                           "    pk1 varint,\n" +
                           "    pk2 ascii,\n" +
@@ -2338,11 +2330,7 @@
 
         ColumnFamilyStore cfs = Keyspace.open(keyspace()).getColumnFamilyStore(tableName);
 
-<<<<<<<
         String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), cfs.keyspace.getMetadata());
-=======
-        String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), true, true, true, cfs.keyspace.getMetadata());
->>>>>>>
         String expected = "CREATE TABLE IF NOT EXISTS " + keyspace() + "." + tableName + " (\n" +
                         "    pk1 varint,\n" +
                         "    reg1 int,\n" +
@@ -2364,11 +2352,7 @@
                                        " WITH COMPACT STORAGE");
 
         ColumnFamilyStore cfs = Keyspace.open(keyspace()).getColumnFamilyStore(tableName);
-<<<<<<<
         assertTrue(SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), cfs.keyspace.getMetadata()).contains(
-=======
-        assertTrue(SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), true, true, true, cfs.keyspace.getMetadata()).contains(
->>>>>>>
         "CREATE TABLE IF NOT EXISTS " + keyspace() + "." + tableName + " (\n" +
         "    pk1 varint,\n" +
         "    reg1 int,\n" +
@@ -2390,11 +2374,7 @@
 
         ColumnFamilyStore cfs = Keyspace.open(keyspace()).getColumnFamilyStore(tableName);
 
-<<<<<<<
         String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), cfs.keyspace.getMetadata());
-=======
-        String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), true, true, true, cfs.keyspace.getMetadata());
->>>>>>>
         String expected = "CREATE TABLE IF NOT EXISTS " + keyspace() + "." + tableName + " (\n" +
                           "    pk1 varint,\n" +
                           "    reg1 counter,\n" +
@@ -2417,11 +2397,7 @@
 
         ColumnFamilyStore cfs = Keyspace.open(keyspace()).getColumnFamilyStore(tableName);
 
-<<<<<<<
         String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), cfs.keyspace.getMetadata());
-=======
-        String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), true, true, true, cfs.keyspace.getMetadata());
->>>>>>>
         String expected = "CREATE TABLE IF NOT EXISTS " + keyspace() + "." + tableName + " (\n" +
                           "    pk1 varint,\n" +
                           "    ck1 int,\n" +
@@ -2444,11 +2420,7 @@
 
         ColumnFamilyStore cfs = Keyspace.open(keyspace()).getColumnFamilyStore(tableName);
 
-<<<<<<<
         String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), cfs.keyspace.getMetadata());
-=======
-        String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), true, true, true, cfs.keyspace.getMetadata());
->>>>>>>
         String expected = "CREATE TABLE IF NOT EXISTS " + keyspace() + "." + tableName + " (\n" +
                           "    pk1 varint,\n" +
                           "    ck1 int,\n" +
--- a/test/unit/org/apache/cassandra/db/CounterCacheTest.java
+++ b/test/unit/org/apache/cassandra/db/CounterCacheTest.java
@@ -20,8 +20,6 @@
 import java.util.Collections;
 import java.util.concurrent.ExecutionException;
 
-<<<<<<<
-=======
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.ColumnMetadata;
 import org.apache.cassandra.schema.KeyspaceMetadata;
@@ -30,7 +28,6 @@
 import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.schema.KeyspaceParams;
 import org.apache.cassandra.utils.ByteBufferUtil;
->>>>>>>
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -38,18 +35,10 @@
 import org.apache.cassandra.SchemaLoader;
 import org.apache.cassandra.db.marshal.CounterColumnType;
 import org.apache.cassandra.db.marshal.Int32Type;
-import org.apache.cassandra.dht.Bounds;
-import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.exceptions.WriteTimeoutException;
-import org.apache.cassandra.schema.ColumnMetadata;
-import org.apache.cassandra.schema.KeyspaceMetadata;
-import org.apache.cassandra.schema.KeyspaceParams;
 import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.schema.SchemaTestUtil;
-import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.service.CacheService;
-import org.apache.cassandra.utils.ByteBufferUtil;
 
 import static org.apache.cassandra.utils.ByteBufferUtil.bytes;
 import static org.junit.Assert.assertEquals;
--- a/test/unit/org/apache/cassandra/db/KeyspaceTest.java
+++ b/test/unit/org/apache/cassandra/db/KeyspaceTest.java
@@ -36,10 +36,7 @@
 import org.apache.cassandra.db.rows.Cell;
 import org.apache.cassandra.db.rows.Row;
 import org.apache.cassandra.db.rows.RowIterator;
-<<<<<<<
-=======
 import org.apache.cassandra.io.sstable.AbstractRowIndexEntry;
->>>>>>>
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.io.sstable.format.big.BigTableReader;
 import org.apache.cassandra.metrics.ClearableHistogram;
@@ -50,10 +47,7 @@
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
-<<<<<<<
-=======
 import static org.junit.Assert.assertTrue;
->>>>>>>
 import static org.junit.Assert.fail;
 
 public class KeyspaceTest extends CQLTester
--- a/test/unit/org/apache/cassandra/db/RowCacheTest.java
+++ b/test/unit/org/apache/cassandra/db/RowCacheTest.java
@@ -32,20 +32,14 @@
 import org.apache.cassandra.SchemaLoader;
 import org.apache.cassandra.Util;
 import org.apache.cassandra.cache.RowCacheKey;
-<<<<<<<
-=======
 import org.apache.cassandra.db.marshal.ValueAccessors;
 import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.db.marshal.AsciiType;
-import org.apache.cassandra.db.rows.*;
->>>>>>>
 import org.apache.cassandra.db.compaction.CompactionManager;
 import org.apache.cassandra.db.filter.ColumnFilter;
-import org.apache.cassandra.db.marshal.AsciiType;
 import org.apache.cassandra.db.marshal.IntegerType;
-import org.apache.cassandra.db.marshal.ValueAccessors;
 import org.apache.cassandra.db.partitions.CachedPartition;
 import org.apache.cassandra.db.rows.Cell;
 import org.apache.cassandra.db.rows.ColumnData;
@@ -56,29 +50,17 @@
 import org.apache.cassandra.dht.ByteOrderedPartitioner.BytesToken;
 import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.exceptions.ConfigurationException;
-import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.locator.TokenMetadata;
 import org.apache.cassandra.metrics.ClearableHistogram;
 import org.apache.cassandra.schema.CachingParams;
-import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.KeyspaceParams;
-<<<<<<<
-=======
-import org.apache.cassandra.schema.Schema;
->>>>>>>
 import org.apache.cassandra.schema.SchemaTestUtil;
 import org.apache.cassandra.service.CacheService;
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.utils.ByteBufferUtil;
 
-<<<<<<<
 import static org.apache.cassandra.config.CassandraRelevantProperties.TEST_ORG_CAFFINITAS_OHC_SEGMENTCOUNT;
 import static org.junit.Assert.*;
-=======
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertTrue;
->>>>>>>
 
 public class RowCacheTest
 {
--- a/test/unit/org/apache/cassandra/db/SchemaCQLHelperTest.java
+++ b/test/unit/org/apache/cassandra/db/SchemaCQLHelperTest.java
@@ -18,7 +18,6 @@
 
 package org.apache.cassandra.db;
 
-<<<<<<<
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
 import com.google.common.io.Files;
@@ -28,47 +27,30 @@
 import org.junit.Test;
 
 import com.fasterxml.jackson.databind.JsonNode;
-import org.apache.cassandra.*;
-import org.apache.cassandra.cql3.*;
 import org.apache.cassandra.cql3.statements.schema.IndexTarget;
-import org.apache.cassandra.db.marshal.*;
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.index.sasi.SASIIndex;
-import org.apache.cassandra.schema.*;
 import org.apache.cassandra.service.reads.SpeculativeRetryPolicy;
 import org.apache.cassandra.utils.ByteBufferUtil;
 import org.apache.cassandra.utils.FBUtilities;
 import org.apache.cassandra.utils.JsonUtils;
 
-=======
-import java.io.FileReader;
->>>>>>>
 import java.nio.ByteBuffer;
 import java.nio.charset.Charset;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.stream.Collectors;
 
-import com.google.common.collect.ImmutableList;
-import com.google.common.collect.ImmutableMap;
-import com.google.common.io.Files;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Test;
-
 import org.apache.cassandra.SchemaLoader;
 import org.apache.cassandra.cql3.CQLTester;
 import org.apache.cassandra.cql3.ColumnIdentifier;
 import org.apache.cassandra.cql3.FieldIdentifier;
-import org.apache.cassandra.cql3.statements.schema.IndexTarget;
 import org.apache.cassandra.db.marshal.AsciiType;
 import org.apache.cassandra.db.marshal.IntegerType;
 import org.apache.cassandra.db.marshal.ListType;
 import org.apache.cassandra.db.marshal.MapType;
 import org.apache.cassandra.db.marshal.ReversedType;
 import org.apache.cassandra.db.marshal.UserType;
-import org.apache.cassandra.exceptions.ConfigurationException;
-import org.apache.cassandra.index.sasi.SASIIndex;
 import org.apache.cassandra.schema.ColumnMetadata;
 import org.apache.cassandra.schema.CompactionParams;
 import org.apache.cassandra.schema.CompressionParams;
@@ -78,12 +60,6 @@
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.Tables;
 import org.apache.cassandra.schema.Types;
-import org.apache.cassandra.service.reads.SpeculativeRetryPolicy;
-import org.apache.cassandra.utils.ByteBufferUtil;
-import org.apache.cassandra.utils.FBUtilities;
-import org.json.simple.JSONArray;
-import org.json.simple.JSONObject;
-import org.json.simple.parser.JSONParser;
 
 import static org.hamcrest.CoreMatchers.allOf;
 import static org.hamcrest.CoreMatchers.containsString;
@@ -205,11 +181,7 @@
                           "    reg2 varint,\n" +
                           "    st1 varint static,\n" +
                           "    PRIMARY KEY (pk1, ck1)\n) WITH ID =";
-<<<<<<<
         String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), cfs.keyspace.getMetadata());
-=======
-        String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), true, true, true, cfs.keyspace.getMetadata());
->>>>>>>
 
         assertThat(actual,
                    allOf(startsWith(expected),
@@ -250,11 +222,7 @@
         ColumnFamilyStore cfs = Keyspace.open(keyspace).getColumnFamilyStore(table);
 
         // when re-adding, column is present as both column and as dropped column record.
-<<<<<<<
         String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), cfs.keyspace.getMetadata());
-=======
-        String actual = SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), true, true, true, cfs.keyspace.getMetadata());
->>>>>>>
         String expected = "CREATE TABLE IF NOT EXISTS cql_test_keyspace_readded_columns.test_table_readded_columns (\n" +
                           "    pk1 varint,\n" +
                           "    ck1 varint,\n" +
@@ -293,11 +261,7 @@
 
         ColumnFamilyStore cfs = Keyspace.open(keyspace).getColumnFamilyStore(table);
 
-<<<<<<<
         assertThat(SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), cfs.keyspace.getMetadata()),
-=======
-        assertThat(SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), true, true, true, cfs.keyspace.getMetadata()),
->>>>>>>
                    startsWith(
                    "CREATE TABLE IF NOT EXISTS cql_test_keyspace_create_table.test_table_create_table (\n" +
                    "    pk1 varint,\n" +
@@ -344,11 +308,7 @@
 
         ColumnFamilyStore cfs = Keyspace.open(keyspace).getColumnFamilyStore(table);
 
-<<<<<<<
         assertThat(SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), cfs.keyspace.getMetadata()),
-=======
-        assertThat(SchemaCQLHelper.getTableMetadataAsCQL(cfs.metadata(), true, true, true, cfs.keyspace.getMetadata()),
->>>>>>>
                    containsString("CLUSTERING ORDER BY (cl1 ASC)\n" +
                             "    AND additional_write_policy = 'ALWAYS'\n" +
                             "    AND allow_auto_snapshot = true\n" +
--- a/test/unit/org/apache/cassandra/db/SystemKeyspaceTest.java
+++ b/test/unit/org/apache/cassandra/db/SystemKeyspaceTest.java
@@ -23,7 +23,6 @@
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashSet;
-import java.util.LinkedHashSet;
 import java.util.List;
 import java.util.Set;
 import java.util.UUID;
@@ -40,11 +39,8 @@
 import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.schema.SchemaConstants;
 import org.apache.cassandra.schema.SchemaKeyspace;
-<<<<<<<
-=======
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.transport.ProtocolVersion;
->>>>>>>
 import org.apache.cassandra.utils.ByteBufferUtil;
 import org.apache.cassandra.utils.CassandraVersion;
 import org.apache.cassandra.utils.FBUtilities;
--- a/test/unit/org/apache/cassandra/db/commitlog/CommitLogTest.java
+++ b/test/unit/org/apache/cassandra/db/commitlog/CommitLogTest.java
@@ -18,21 +18,14 @@
  */
 package org.apache.cassandra.db.commitlog;
 
-<<<<<<<
-import java.io.ByteArrayOutputStream;
-import java.io.Closeable;
-import java.io.DataOutputStream;
-import java.io.File;
-import java.io.FileOutputStream;
-=======
 import org.apache.cassandra.config.CassandraRelevantProperties;
+import org.apache.cassandra.config.Config.DiskFailurePolicy;
 import org.apache.cassandra.distributed.shared.WithProperties;
 import org.apache.cassandra.io.util.File;
 
 import java.io.ByteArrayOutputStream;
 import java.io.Closeable;
 import java.io.DataOutputStream;
->>>>>>>
 import java.io.IOException;
 import java.io.OutputStream;
 import java.math.BigInteger;
@@ -41,8 +34,10 @@
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
+import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
+import java.util.Objects;
 import java.util.Random;
 import java.util.UUID;
 import java.util.concurrent.Callable;
@@ -56,28 +51,16 @@
 
 import com.google.common.collect.Iterables;
 import com.google.common.io.Files;
-<<<<<<<
 
 import org.apache.cassandra.io.util.FileOutputStreamPlus;
 
 import org.junit.*;
-=======
-import org.junit.After;
-import org.junit.AfterClass;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Ignore;
-import org.junit.Test;
->>>>>>>
 import org.junit.runner.RunWith;
 import org.junit.runners.Parameterized;
 import org.junit.runners.Parameterized.Parameters;
 
 import org.apache.cassandra.SchemaLoader;
 import org.apache.cassandra.Util;
-<<<<<<<
-import org.apache.cassandra.config.Config.DiskFailurePolicy;
-=======
 import org.apache.cassandra.db.memtable.Memtable;
 import org.apache.cassandra.db.memtable.SkipListMemtable;
 import org.apache.cassandra.io.compress.ZstdCompressor;
@@ -87,12 +70,10 @@
 import org.apache.cassandra.schema.SchemaTestUtil;
 import org.apache.cassandra.schema.TableId;
 import org.apache.cassandra.schema.TableMetadata;
->>>>>>>
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.config.ParameterizedClass;
 import org.apache.cassandra.db.ColumnFamilyStore;
 import org.apache.cassandra.db.Keyspace;
-import org.apache.cassandra.db.Memtable;
 import org.apache.cassandra.db.Mutation;
 import org.apache.cassandra.db.MutationExceededMaxSizeException;
 import org.apache.cassandra.db.RowUpdateBuilder;
@@ -111,17 +92,10 @@
 import org.apache.cassandra.io.compress.DeflateCompressor;
 import org.apache.cassandra.io.compress.LZ4Compressor;
 import org.apache.cassandra.io.compress.SnappyCompressor;
-import org.apache.cassandra.io.compress.ZstdCompressor;
 import org.apache.cassandra.io.sstable.format.SSTableReader;
-import org.apache.cassandra.io.util.FileUtils;
 import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.schema.KeyspaceParams;
-<<<<<<<
-import org.apache.cassandra.schema.TableId;
-import org.apache.cassandra.schema.TableMetadata;
-=======
 import org.apache.cassandra.security.CipherFactory;
->>>>>>>
 import org.apache.cassandra.security.EncryptionContext;
 import org.apache.cassandra.security.EncryptionContextGenerator;
 import org.apache.cassandra.service.StorageService;
@@ -132,12 +106,9 @@
 import org.apache.cassandra.utils.Pair;
 import org.apache.cassandra.utils.vint.VIntCoding;
 
-<<<<<<<
-=======
 import static java.lang.String.format;
 import static org.apache.cassandra.config.CassandraRelevantProperties.COMMITLOG_IGNORE_REPLAY_ERRORS;
 import static org.apache.cassandra.config.CassandraRelevantProperties.COMMIT_LOG_REPLAY_LIST;
->>>>>>>
 import static org.apache.cassandra.db.commitlog.CommitLogSegment.ENTRY_OVERHEAD_SIZE;
 import static org.apache.cassandra.utils.ByteBufferUtil.bytes;
 import static org.junit.Assert.assertEquals;
@@ -218,10 +189,6 @@
                                     custom);
         SchemaLoader.createKeyspace(KEYSPACE2,
                                     KeyspaceParams.simpleTransient(1),
-<<<<<<<
-                                    SchemaLoader.standardCFMD(KEYSPACE2, STANDARD1, 0, AsciiType.instance, BytesType.instance),
-                                    SchemaLoader.standardCFMD(KEYSPACE2, STANDARD2, 0, AsciiType.instance, BytesType.instance));
-=======
                                     SchemaLoader.standardCFMD(KEYSPACE2, STANDARD1, 0, AsciiType.instance, BytesType.instance).memtable(skipListMemtable),
                                     SchemaLoader.standardCFMD(KEYSPACE2, STANDARD2, 0, AsciiType.instance, BytesType.instance).memtable(skipListMemtable));
         SchemaLoader.createKeyspace(KEYSPACE1_REPLAY,
@@ -232,7 +199,6 @@
                                     KeyspaceParams.simple(1),
                                     SchemaLoader.standardCFMD(KEYSPACE2_REPLAY, KEYSPACE2_REPLAY_TABLE2, 0, AsciiType.instance, BytesType.instance).memtable(skipListMemtable));
 
->>>>>>>
         CompactionManager.instance.disableAutoCompaction();
 
         testKiller = new KillerForTests();
--- a/test/unit/org/apache/cassandra/db/commitlog/CommitLogUpgradeTest.java
+++ b/test/unit/org/apache/cassandra/db/commitlog/CommitLogUpgradeTest.java
@@ -21,36 +21,24 @@
  *
  */
 
-<<<<<<<
-=======
-import java.io.File;
-import java.io.FileInputStream;
->>>>>>>
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.util.Properties;
 
-<<<<<<<
-=======
 import org.apache.cassandra.io.util.File;
 import org.apache.cassandra.io.util.FileInputStreamPlus;
 import org.junit.Assert;
 
->>>>>>>
 import com.google.common.base.Predicate;
 import org.junit.After;
-import org.junit.Assert;
 import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
 import org.apache.cassandra.SchemaLoader;
 import org.apache.cassandra.config.DatabaseDescriptor;
-<<<<<<<
-=======
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.SchemaTestUtil;
->>>>>>>
 import org.apache.cassandra.db.Mutation;
 import org.apache.cassandra.db.marshal.AsciiType;
 import org.apache.cassandra.db.marshal.BytesType;
@@ -59,8 +47,6 @@
 import org.apache.cassandra.db.rows.Row;
 import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.KeyspaceParams;
-import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.schema.SchemaTestUtil;
 import org.apache.cassandra.schema.TableId;
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.Tables;
--- a/test/unit/org/apache/cassandra/db/compaction/TTLExpiryTest.java
+++ b/test/unit/org/apache/cassandra/db/compaction/TTLExpiryTest.java
@@ -29,10 +29,7 @@
 
 import org.apache.cassandra.SchemaLoader;
 import org.apache.cassandra.Util;
-<<<<<<<
-=======
 import org.apache.cassandra.config.CassandraRelevantProperties;
->>>>>>>
 import org.apache.cassandra.db.ColumnFamilyStore;
 import org.apache.cassandra.db.DataRange;
 import org.apache.cassandra.db.Keyspace;
@@ -41,19 +38,11 @@
 import org.apache.cassandra.db.lifecycle.SSTableSet;
 import org.apache.cassandra.db.marshal.AsciiType;
 import org.apache.cassandra.db.marshal.MapType;
-<<<<<<<
 import org.apache.cassandra.db.partitions.UnfilteredPartitionIterator;
 import org.apache.cassandra.db.rows.UnfilteredRowIterator;
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.io.sstable.SSTableReadsListener;
 import org.apache.cassandra.io.sstable.format.SSTableReader;
-=======
-import org.apache.cassandra.db.rows.UnfilteredRowIterator;
-import org.apache.cassandra.exceptions.ConfigurationException;
-import org.apache.cassandra.io.sstable.ISSTableScanner;
-import org.apache.cassandra.io.sstable.format.SSTableReader;
-import org.apache.cassandra.io.sstable.format.SSTableReadsListener;
->>>>>>>
 import org.apache.cassandra.schema.KeyspaceParams;
 import org.apache.cassandra.schema.SchemaTestUtil;
 import org.apache.cassandra.schema.TableMetadata;
--- a/test/unit/org/apache/cassandra/hints/HintTest.java
+++ b/test/unit/org/apache/cassandra/hints/HintTest.java
@@ -56,14 +56,9 @@
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.utils.FBUtilities;
 
-<<<<<<<
-import static junit.framework.Assert.assertEquals;
-import static junit.framework.Assert.assertFalse;
-=======
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 
->>>>>>>
 import static org.apache.cassandra.Util.dk;
 import static org.apache.cassandra.hints.HintsTestUtil.assertHintsEqual;
 import static org.apache.cassandra.hints.HintsTestUtil.assertPartitionsEqual;
--- a/test/unit/org/apache/cassandra/index/sasi/disk/PerSSTableIndexWriterTest.java
+++ b/test/unit/org/apache/cassandra/index/sasi/disk/PerSSTableIndexWriterTest.java
@@ -41,10 +41,7 @@
 import org.apache.cassandra.db.DecoratedKey;
 import org.apache.cassandra.db.Keyspace;
 import org.apache.cassandra.db.compaction.OperationType;
-<<<<<<<
-=======
 import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
->>>>>>>
 import org.apache.cassandra.db.marshal.Int32Type;
 import org.apache.cassandra.db.marshal.LongType;
 import org.apache.cassandra.db.marshal.UTF8Type;
@@ -66,11 +63,8 @@
 import org.apache.cassandra.schema.Tables;
 import org.apache.cassandra.utils.ByteBufferUtil;
 
-<<<<<<<
-=======
 import static org.apache.cassandra.config.CassandraRelevantProperties.CASSANDRA_CONFIG;
 
->>>>>>>
 public class PerSSTableIndexWriterTest extends SchemaLoader
 {
     private static final String KS_NAME = "sasi";
--- a/test/unit/org/apache/cassandra/io/sstable/CQLSSTableWriterClientTest.java
+++ b/test/unit/org/apache/cassandra/io/sstable/CQLSSTableWriterClientTest.java
@@ -40,11 +40,7 @@
     @Before
     public void setUp()
     {
-<<<<<<<
-        this.testDirectory = Files.createTempDir();
-=======
         this.testDirectory = new File(Files.createTempDir());
->>>>>>>
         DatabaseDescriptor.clientInitialization();
     }
 
--- a/test/unit/org/apache/cassandra/io/sstable/indexsummary/IndexSummaryManagerTest.java
+++ b/test/unit/org/apache/cassandra/io/sstable/indexsummary/IndexSummaryManagerTest.java
@@ -26,10 +26,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
-<<<<<<<
-=======
-import java.util.UUID;
->>>>>>>
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.Future;
@@ -261,15 +257,9 @@
         // halve the min_index_interval, but constrain the available space to exactly what we have now; as a result,
         // the summary shouldn't change
         SchemaTestUtil.announceTableUpdate(cfs.metadata().unbuild().minIndexInterval(originalMinIndexInterval / 2).build());
-<<<<<<<
         R sstable = ServerTestUtils.<R>getLiveIndexSummarySupportingReaders(cfs).iterator().next();
         long summarySpace = sstable.getIndexSummary().getOffHeapSize();
         try (LifecycleTransaction txn = cfs.getTracker().tryModify(sstable, OperationType.UNKNOWN))
-=======
-        SSTableReader sstable = cfs.getLiveSSTables().iterator().next();
-        long summarySpace = sstable.getIndexSummaryOffHeapSize();
-        try (LifecycleTransaction txn = cfs.getTracker().tryModify(asList(sstable), OperationType.UNKNOWN))
->>>>>>>
         {
             redistributeSummaries(Collections.emptyList(), of(cfs.metadata.id, txn), summarySpace);
         }
@@ -292,11 +282,7 @@
         // return min_index_interval to it's original value (double it), but only give the summary enough space
         // to have an effective index interval of twice the new min
         SchemaTestUtil.announceTableUpdate(cfs.metadata().unbuild().minIndexInterval(originalMinIndexInterval).build());
-<<<<<<<
-        try (LifecycleTransaction txn = cfs.getTracker().tryModify(asList(sstable), OperationType.UNKNOWN))
-=======
         try (LifecycleTransaction txn = cfs.getTracker().tryModify(sstable, OperationType.UNKNOWN))
->>>>>>>
         {
             redistributeSummaries(Collections.emptyList(), of(cfs.metadata.id, txn), (long) Math.ceil(summarySpace / 2.0));
         }
@@ -309,11 +295,7 @@
         // result in an effective interval above the new max)
         SchemaTestUtil.announceTableUpdate(cfs.metadata().unbuild().minIndexInterval(originalMinIndexInterval * 4).build());
         SchemaTestUtil.announceTableUpdate(cfs.metadata().unbuild().maxIndexInterval(originalMinIndexInterval * 4).build());
-<<<<<<<
-        try (LifecycleTransaction txn = cfs.getTracker().tryModify(asList(sstable), OperationType.UNKNOWN))
-=======
         try (LifecycleTransaction txn = cfs.getTracker().tryModify(sstable, OperationType.UNKNOWN))
->>>>>>>
         {
             redistributeSummaries(Collections.emptyList(), of(cfs.metadata.id, txn), 10);
         }
--- a/test/unit/org/apache/cassandra/schema/MigrationCoordinatorTest.java
+++ b/test/unit/org/apache/cassandra/schema/MigrationCoordinatorTest.java
@@ -34,20 +34,12 @@
 
 import com.google.common.collect.Iterables;
 import com.google.common.collect.Sets;
-<<<<<<<
-=======
-import com.google.common.util.concurrent.MoreExecutors;
->>>>>>>
 import org.junit.Assert;
 import org.junit.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-<<<<<<<
 import org.apache.cassandra.concurrent.ImmediateExecutor;
-=======
-import org.apache.cassandra.config.CassandraRelevantProperties;
->>>>>>>
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.Mutation;
 import org.apache.cassandra.gms.ApplicationState;
@@ -104,7 +96,6 @@
             throw new AssertionError(e);
         }
 
-        CassandraRelevantProperties.SCHEMA_PULL_BACKOFF_DELAY_MS.setInt(0);
         DatabaseDescriptor.daemonInitialization();
 
         when(validEndpointState.getApplicationState(ApplicationState.RELEASE_VERSION)).thenReturn(VersionedValue.unsafeMakeVersionedValue(FBUtilities.getReleaseVersionString(), 0));
@@ -145,11 +136,7 @@
             when(versions.knows(any())).thenReturn(true);
             when(versions.getRaw(any())).thenReturn(MessagingService.current_version);
             this.coordinator = new MigrationCoordinator(messagingService,
-<<<<<<<
                                                         ImmediateExecutor.INSTANCE,
-=======
-                                                        MoreExecutors.newDirectExecutorService(),
->>>>>>>
                                                         oneTimeExecutor,
                                                         maxOutstandingRequests,
                                                         gossiper,
@@ -341,11 +328,7 @@
 
             Pair<InetAddressAndPort, RequestCallback<Collection<Mutation>>> next = wrapper.requests.remove();
 
-<<<<<<<
             // we should be contacting endpoints in a round robin fashion
-=======
-            // we should be contacting endpoints in a round-robin fashion
->>>>>>>
             Assert.assertTrue(EPs.contains(next.left));
             if (prev != null && prev.left.equals(next.left))
                 Assert.fail(String.format("Not expecting prev %s to be equal to next %s", prev.left, next.left));
--- a/test/unit/org/apache/cassandra/schema/SchemaKeyspaceTest.java
+++ b/test/unit/org/apache/cassandra/schema/SchemaKeyspaceTest.java
@@ -24,7 +24,6 @@
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Set;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.CyclicBarrier;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
@@ -130,20 +129,12 @@
 
     private Collection<Mutation> getSchemaMutations()
     {
-<<<<<<<
         AsyncPromise<Collection<Mutation>> p = new AsyncPromise<>();
         MessagingService.instance().sendWithCallback(Message.out(Verb.SCHEMA_PULL_REQ, NoPayload.noPayload),
                                                      FBUtilities.getBroadcastAddressAndPort(),
                                                      (RequestCallback<Collection<Mutation>>) msg -> p.setSuccess(msg.payload));
         p.syncUninterruptibly();
         return p.getNow();
-=======
-        CompletableFuture<Collection<Mutation>> p = new CompletableFuture<>();
-        MessagingService.instance().sendWithCallback(Message.out(Verb.SCHEMA_PULL_REQ, NoPayload.noPayload),
-                                                     FBUtilities.getBroadcastAddressAndPort(),
-                                                     (RequestCallback<Collection<Mutation>>) msg -> p.complete(msg.payload));
-        return p.join();
->>>>>>>
     }
 
     @Test
--- a/test/unit/org/apache/cassandra/schema/SchemaTest.java
+++ b/test/unit/org/apache/cassandra/schema/SchemaTest.java
@@ -29,10 +29,6 @@
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.Keyspace;
 import org.apache.cassandra.db.Mutation;
-<<<<<<<
-=======
-import org.apache.cassandra.db.commitlog.CommitLog;
->>>>>>>
 import org.apache.cassandra.gms.Gossiper;
 import org.apache.cassandra.utils.FBUtilities;
 
@@ -56,11 +52,6 @@
         assertEquals(0, Schema.instance.getNonSystemKeyspaces().size());
 
         Gossiper.instance.start((int) (System.currentTimeMillis() / 1000));
-<<<<<<<
-=======
-        Keyspace.setInitialized();
-
->>>>>>>
         try
         {
             // add a few.
@@ -87,8 +78,6 @@
         }
     }
 
-<<<<<<<
-=======
     @Test
     public void testKeyspaceCreationWhenNotInitialized() {
         Keyspace.unsetInitialized();
@@ -116,7 +105,6 @@
         assertNull(Schema.instance.getKeyspaceInstance("test"));
     }
 
->>>>>>>
     private void saveKeyspaces()
     {
         Collection<Mutation> mutations = Arrays.asList(SchemaKeyspace.makeCreateKeyspaceMutation(KeyspaceMetadata.create("ks0", KeyspaceParams.simple(3)), FBUtilities.timestampMicros()).build(),
--- a/test/unit/org/apache/cassandra/schema/SchemaTestUtil.java
+++ b/test/unit/org/apache/cassandra/schema/SchemaTestUtil.java
@@ -18,18 +18,11 @@
 
 package org.apache.cassandra.schema;
 
-<<<<<<<
-import java.time.Duration;
-import java.util.Collection;
-import java.util.Collections;
-
-=======
 import java.util.Collection;
 import java.util.Collections;
 import java.util.concurrent.TimeUnit;
 
 import org.junit.Assert;
->>>>>>>
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -38,11 +31,7 @@
 import org.apache.cassandra.exceptions.AlreadyExistsException;
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.net.Message;
-<<<<<<<
-import org.apache.cassandra.utils.FBUtilities;
-=======
 import org.apache.cassandra.utils.concurrent.Future;
->>>>>>>
 
 import static org.apache.cassandra.net.Verb.SCHEMA_PUSH_REQ;
 
@@ -149,14 +138,9 @@
     public static void mergeAndAnnounceLocally(Collection<Mutation> schemaMutations)
     {
         SchemaPushVerbHandler.instance.doVerb(Message.out(SCHEMA_PUSH_REQ, schemaMutations));
-<<<<<<<
-        FBUtilities.waitOnFuture(Stage.MIGRATION.submit(() -> {
-        }), Duration.ofSeconds(10)); // simply wait for stage executor to complete previously scheduled tasks
-=======
         Future<?> f = Stage.MIGRATION.submit(() -> {});
         Assert.assertTrue(f.awaitThrowUncheckedOnInterrupt(10, TimeUnit.SECONDS));
         f.rethrowIfFailed();
->>>>>>>
     }
 
 }
--- a/test/unit/org/apache/cassandra/service/MoveTest.java
+++ b/test/unit/org/apache/cassandra/service/MoveTest.java
@@ -37,8 +37,6 @@
 import com.google.common.collect.HashMultimap;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Multimap;
-<<<<<<<
-=======
 
 import org.apache.cassandra.diag.DiagnosticEventService;
 import org.apache.cassandra.gms.GossiperEvent;
@@ -46,14 +44,11 @@
 import org.apache.cassandra.locator.EndpointsForToken;
 import org.apache.cassandra.locator.RangesAtEndpoint;
 import org.apache.cassandra.locator.RangesByEndpoint;
->>>>>>>
 import org.junit.AfterClass;
 import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
-<<<<<<<
-=======
 import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.locator.Replica;
 import org.apache.cassandra.locator.ReplicaCollection;
@@ -61,40 +56,26 @@
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.marshal.BytesType;
->>>>>>>
 import org.apache.cassandra.SchemaLoader;
 import org.apache.cassandra.Util;
-import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.db.marshal.BytesType;
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.RandomPartitioner;
 import org.apache.cassandra.dht.RandomPartitioner.BigIntegerToken;
 import org.apache.cassandra.dht.Range;
 import org.apache.cassandra.dht.Token;
-import org.apache.cassandra.diag.DiagnosticEventService;
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.gms.ApplicationState;
 import org.apache.cassandra.gms.Gossiper;
-import org.apache.cassandra.gms.GossiperEvent;
 import org.apache.cassandra.gms.VersionedValue;
 import org.apache.cassandra.locator.AbstractNetworkTopologySnitch;
 import org.apache.cassandra.locator.AbstractReplicationStrategy;
-import org.apache.cassandra.locator.EndpointsForRange;
-import org.apache.cassandra.locator.EndpointsForToken;
-import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.locator.NetworkTopologyStrategy;
 import org.apache.cassandra.locator.PendingRangeMaps;
-import org.apache.cassandra.locator.RangesAtEndpoint;
-import org.apache.cassandra.locator.RangesByEndpoint;
-import org.apache.cassandra.locator.Replica;
-import org.apache.cassandra.locator.ReplicaCollection;
 import org.apache.cassandra.locator.SimpleSnitch;
 import org.apache.cassandra.locator.TokenMetadata;
 import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.KeyspaceParams;
 import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.schema.SchemaTestUtil;
-import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.Tables;
 
 import static org.junit.Assert.assertEquals;
--- a/test/unit/org/apache/cassandra/service/OptionalTasksTest.java
+++ b/test/unit/org/apache/cassandra/service/OptionalTasksTest.java
@@ -86,19 +86,11 @@
         ColumnFamilyStore cfs = Schema.instance.getColumnFamilyStoreInstance(Objects.requireNonNull(metadata).id);
         Objects.requireNonNull(cfs).metric.coordinatorReadLatency.update(100, TimeUnit.NANOSECONDS);
 
-<<<<<<<
         long originalValue = cfs.sampleReadLatencyMicros;
-=======
-        long originalValue = cfs.sampleReadLatencyNanos;
->>>>>>>
 
         // ...and ensure that the speculation threshold updater runs.
         SPECULATION_THRESHOLD_UPDATER.run();
 
-<<<<<<<
         assertNotEquals(originalValue, cfs.sampleReadLatencyMicros);
-=======
-        assertNotEquals(originalValue, cfs.sampleReadLatencyNanos);
->>>>>>>
     }
 }
--- a/test/unit/org/apache/cassandra/service/StorageServiceServerTest.java
+++ b/test/unit/org/apache/cassandra/service/StorageServiceServerTest.java
@@ -27,7 +27,6 @@
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
-import java.util.Random;
 import java.util.UUID;
 
 import com.google.common.collect.HashMultimap;
@@ -39,11 +38,7 @@
 import org.apache.cassandra.audit.AuditLogManager;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.Keyspace;
-<<<<<<<
-=======
 import org.apache.cassandra.db.SystemKeyspace;
-import org.apache.cassandra.db.WindowsFailedSnapshotTracker;
->>>>>>>
 import org.apache.cassandra.db.commitlog.CommitLog;
 import org.apache.cassandra.dht.Murmur3Partitioner;
 import org.apache.cassandra.dht.Murmur3Partitioner.LongToken;
@@ -70,11 +65,8 @@
 
 import static org.apache.cassandra.ServerTestUtils.cleanup;
 import static org.apache.cassandra.ServerTestUtils.mkdirs;
-<<<<<<<
-=======
 import static org.apache.cassandra.config.CassandraRelevantProperties.GOSSIP_DISABLE_THREAD_VALIDATION;
 import static org.apache.cassandra.config.CassandraRelevantProperties.REPLACE_ADDRESS;
->>>>>>>
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 
--- a/test/unit/org/apache/cassandra/transport/ClientNotificiationsTest.java
+++ b/test/unit/org/apache/cassandra/transport/ClientNotificiationsTest.java
@@ -88,11 +88,7 @@
             notifier.onLeaveCluster(broadcastAddress);
             notifier.onCreateKeyspace(ks);
             notifier.onAlterKeyspace(ks, ks);
-<<<<<<<
-            notifier.onDropKeyspace(ks);
-=======
             notifier.onDropKeyspace(ks, true);
->>>>>>>
 
             handler.assertNextEvent(Event.StatusChange.nodeUp(nativeAddress));
             handler.assertNextEvent(Event.StatusChange.nodeDown(nativeAddress));
--- a/test/unit/org/apache/cassandra/triggers/TriggersSchemaTest.java
+++ b/test/unit/org/apache/cassandra/triggers/TriggersSchemaTest.java
@@ -28,21 +28,12 @@
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.KeyspaceParams;
-import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.schema.SchemaTestUtil;
-import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.Tables;
 import org.apache.cassandra.schema.TriggerMetadata;
 import org.apache.cassandra.schema.Triggers;
 
-<<<<<<<
 import static org.apache.cassandra.utils.Clock.Global.nanoTime;
 import static org.junit.Assert.*;
-=======
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertTrue;
->>>>>>>
 
 public class TriggersSchemaTest
 {
--- a/test/unit/org/apache/cassandra/utils/CassandraGenerators.java
+++ b/test/unit/org/apache/cassandra/utils/CassandraGenerators.java
@@ -511,11 +511,7 @@
                 {
                     // to make sure the correct indents are taken, convert to CQL, then replace newlines with the indents
                     // then prefix with the indents.
-<<<<<<<
                     String cql = SchemaCQLHelper.getTableMetadataAsCQL((TableMetadata) value, null);
-=======
-                    String cql = SchemaCQLHelper.getTableMetadataAsCQL((TableMetadata) value, true, true, false, null);
->>>>>>>
                     cql = NEWLINE_PATTERN.matcher(cql).replaceAll(Matcher.quoteReplacement("\n  " + spacer));
                     cql = "\n  " + spacer + cql;
                     value = cql;
--- a/tools/stress/src/org/apache/cassandra/stress/CompactionStress.java
+++ b/tools/stress/src/org/apache/cassandra/stress/CompactionStress.java
@@ -30,10 +30,6 @@
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
-<<<<<<<
-=======
-import java.util.concurrent.Future;
->>>>>>>
 import java.util.concurrent.TimeUnit;
 import javax.inject.Inject;
 
@@ -57,10 +53,7 @@
 import org.apache.cassandra.io.sstable.Component;
 import org.apache.cassandra.io.sstable.Descriptor;
 import org.apache.cassandra.io.sstable.StressCQLSSTableWriter;
-<<<<<<<
-=======
 import org.apache.cassandra.io.sstable.format.SSTableFormat.Components;
->>>>>>>
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.io.util.FileUtils;
 import org.apache.cassandra.locator.InetAddressAndPort;
diff --git a/src/java/org/apache/cassandra/cache/AutoSavingCache.java b/src/java/org/apache/cassandra/cache/AutoSavingCache.java
index 5e649c062f..5b1442bb32 100644
--- a/src/java/org/apache/cassandra/cache/AutoSavingCache.java
+++ b/src/java/org/apache/cassandra/cache/AutoSavingCache.java
@@ -29,9 +29,6 @@ import java.util.concurrent.ScheduledFuture;
 import java.util.concurrent.TimeUnit;
 import javax.annotation.concurrent.NotThreadSafe;
 
-import com.google.common.util.concurrent.ListenableFuture;
-import com.google.common.util.concurrent.ListeningExecutorService;
-import com.google.common.util.concurrent.MoreExecutors;
 import org.cliffc.high_scale_lib.NonBlockingHashSet;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
diff --git a/src/java/org/apache/cassandra/cql3/QueryProcessor.java b/src/java/org/apache/cassandra/cql3/QueryProcessor.java
index 88865c5906..7b744d039e 100644
--- a/src/java/org/apache/cassandra/cql3/QueryProcessor.java
+++ b/src/java/org/apache/cassandra/cql3/QueryProcessor.java
@@ -30,6 +30,8 @@ import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.stream.Collectors;
 
+import com.github.benmanes.caffeine.cache.Cache;
+import com.github.benmanes.caffeine.cache.Caffeine;
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.base.Predicate;
 import com.google.common.collect.Iterables;
diff --git a/src/java/org/apache/cassandra/cql3/statements/schema/AlterSchemaStatement.java b/src/java/org/apache/cassandra/cql3/statements/schema/AlterSchemaStatement.java
index f9db9ebee5..3d0bf6ec07 100644
--- a/src/java/org/apache/cassandra/cql3/statements/schema/AlterSchemaStatement.java
+++ b/src/java/org/apache/cassandra/cql3/statements/schema/AlterSchemaStatement.java
@@ -34,6 +34,7 @@ import org.apache.cassandra.schema.Keyspaces.KeyspacesDiff;
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.SchemaConstants;
 import org.apache.cassandra.schema.SchemaTransformation;
+import org.apache.cassandra.schema.TableParams;
 import org.apache.cassandra.service.ClientState;
 import org.apache.cassandra.service.ClientWarn;
 import org.apache.cassandra.service.QueryState;
diff --git a/src/java/org/apache/cassandra/db/Keyspace.java b/src/java/org/apache/cassandra/db/Keyspace.java
index 1347496ccf..b49eb3162a 100644
--- a/src/java/org/apache/cassandra/db/Keyspace.java
+++ b/src/java/org/apache/cassandra/db/Keyspace.java
@@ -145,17 +145,6 @@ public class Keyspace
         }
     }
 
-    /**
-     * Never use it in production code.
-     *
-     * Useful when creating a fake Schema so that it does not manage Keyspace instances (and CFS)
-     */
-    @VisibleForTesting
-    public static void unsetInitialized()
-    {
-        initialized = false;
-    }
-
     public static Keyspace open(String keyspaceName)
     {
         assert initialized || SchemaConstants.isLocalSystemKeyspace(keyspaceName) : "Initialized: " + initialized;
diff --git a/src/java/org/apache/cassandra/db/commitlog/CommitLog.java b/src/java/org/apache/cassandra/db/commitlog/CommitLog.java
index 62d638e10b..ca5077edd6 100644
--- a/src/java/org/apache/cassandra/db/commitlog/CommitLog.java
+++ b/src/java/org/apache/cassandra/db/commitlog/CommitLog.java
@@ -27,7 +27,6 @@ import java.util.Collections;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
-import java.util.Optional;
 import java.util.TreeMap;
 import java.util.UUID;
 import java.util.concurrent.TimeUnit;
@@ -44,7 +43,6 @@ import org.slf4j.LoggerFactory;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.config.ParameterizedClass;
 import org.apache.cassandra.db.Mutation;
-import org.apache.cassandra.db.SystemKeyspace;
 import org.apache.cassandra.exceptions.CDCWriteException;
 import org.apache.cassandra.io.FSWriteError;
 import org.apache.cassandra.io.compress.ICompressor;
diff --git a/src/java/org/apache/cassandra/schema/KeyspaceMetadata.java b/src/java/org/apache/cassandra/schema/KeyspaceMetadata.java
index 481ce9caef..3444aa5ed5 100644
--- a/src/java/org/apache/cassandra/schema/KeyspaceMetadata.java
+++ b/src/java/org/apache/cassandra/schema/KeyspaceMetadata.java
@@ -125,11 +125,6 @@ public final class KeyspaceMetadata implements SchemaElement
         return new KeyspaceMetadata(this.name, this.kind, this.params, Tables.none(), Views.none(), Types.none(), UserFunctions.none());
     }
 
-    public KeyspaceMetadata empty()
-    {
-        return new KeyspaceMetadata(this.name, this.kind, this.params, Tables.none(), Views.none(), Types.none(), Functions.none());
-    }
-
     public boolean isVirtual()
     {
         return kind == Kind.VIRTUAL;
diff --git a/src/java/org/apache/cassandra/schema/MigrationCoordinator.java b/src/java/org/apache/cassandra/schema/MigrationCoordinator.java
index 8d9173e208..2ffe35cd32 100644
--- a/src/java/org/apache/cassandra/schema/MigrationCoordinator.java
+++ b/src/java/org/apache/cassandra/schema/MigrationCoordinator.java
@@ -24,7 +24,6 @@ import java.time.Duration;
 import java.util.ArrayDeque;
 import java.util.ArrayList;
 import java.util.Collection;
-import java.util.Collections;
 import java.util.Deque;
 import java.util.HashMap;
 import java.util.HashSet;
@@ -556,10 +555,10 @@ public class MigrationCoordinator
         else
         {
             logger.debug("Postponing pull of {} from {} for {}ms", info, endpoint, MIGRATION_DELAY_IN_MS);
-            submissionExecutor = r -> ScheduledExecutors.nonPeriodicTasks.schedule(() -> submitToMigrationIfNotShutdown(r), MIGRATION_DELAY_IN_MS, TimeUnit.MILLISECONDS);
+            ScheduledExecutors.nonPeriodicTasks.schedule(() -> submitToMigrationIfNotShutdown(task), MIGRATION_DELAY_IN_MS, TimeUnit.MILLISECONDS);
         }
 
-        return CompletableFuture.runAsync(() -> pullSchema(endpoint, new Callback(endpoint, info)), submissionExecutor);
+        return task;
     }
 
     void announce(UUID schemaVersion)
@@ -571,8 +570,8 @@ public class MigrationCoordinator
 
     private Future<?> submitToMigrationIfNotShutdown(Runnable task)
     {
-        CompletableFuture<Collection<Mutation>> result = new CompletableFuture<>();
-        return submitToMigrationIfNotShutdown(() -> pullSchema(endpoint, new RequestCallback<Collection<Mutation>>()
+        boolean skipped = false;
+        try
         {
             if (executor.isShutdown() || executor.isTerminated())
             {
@@ -590,15 +589,9 @@ public class MigrationCoordinator
         {
             if (skipped)
             {
-                result.completeExceptionally(new RuntimeException("Failed to get schema from " + from + ". The failure reason was: " + failureReason));
+                logger.info("Skipped scheduled pulling schema from other nodes: the MIGRATION executor service has been shutdown.");
             }
-
-            @Override
-            public boolean invokeOnFailure()
-            {
-                return true;
-            }
-        })).thenCompose(ignored -> result);
+        }
     }
 
     private class Callback implements RequestCallback<Collection<Mutation>>
diff --git a/src/java/org/apache/cassandra/schema/SchemaKeyspace.java b/src/java/org/apache/cassandra/schema/SchemaKeyspace.java
index 98f7806055..0e576d79a3 100644
--- a/src/java/org/apache/cassandra/schema/SchemaKeyspace.java
+++ b/src/java/org/apache/cassandra/schema/SchemaKeyspace.java
@@ -56,6 +56,7 @@ import org.apache.cassandra.db.ReadCommand;
 import org.apache.cassandra.db.ReadExecutionController;
 import org.apache.cassandra.db.filter.ColumnFilter;
 import org.apache.cassandra.db.marshal.AbstractType;
+import org.apache.cassandra.db.marshal.BooleanType;
 import org.apache.cassandra.db.marshal.BytesType;
 import org.apache.cassandra.db.marshal.ReversedType;
 import org.apache.cassandra.db.marshal.UTF8Type;
diff --git a/src/java/org/apache/cassandra/schema/TableId.java b/src/java/org/apache/cassandra/schema/TableId.java
index e70f84f13d..ceeeec315a 100644
--- a/src/java/org/apache/cassandra/schema/TableId.java
+++ b/src/java/org/apache/cassandra/schema/TableId.java
@@ -34,8 +34,6 @@ import static org.apache.cassandra.utils.TimeUUID.Generator.nextTimeUUID;
 
 import static java.nio.charset.StandardCharsets.UTF_8;
 
-import static java.nio.charset.StandardCharsets.UTF_8;
-
 /**
  * The unique identifier of a table.
  * <p>
diff --git a/test/microbench/org/apache/cassandra/test/microbench/MutationBench.java b/test/microbench/org/apache/cassandra/test/microbench/MutationBench.java
index 0be175c642..3470577f68 100644
--- a/test/microbench/org/apache/cassandra/test/microbench/MutationBench.java
+++ b/test/microbench/org/apache/cassandra/test/microbench/MutationBench.java
@@ -26,6 +26,7 @@ import java.util.concurrent.TimeUnit;
 
 import org.apache.cassandra.UpdateBuilder;
 import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.cql3.statements.schema.CreateTableStatement;
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.SchemaTestUtil;
 import org.apache.cassandra.db.Mutation;
@@ -36,8 +37,6 @@ import org.apache.cassandra.io.util.DataOutputBufferFixed;
 import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.KeyspaceParams;
-import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.schema.SchemaTestUtil;
 import org.apache.cassandra.schema.TableMetadata;
 import org.openjdk.jmh.annotations.Benchmark;
 import org.openjdk.jmh.annotations.BenchmarkMode;
diff --git a/test/unit/org/apache/cassandra/cql3/CQLTester.java b/test/unit/org/apache/cassandra/cql3/CQLTester.java
index 3bff653e37..246d658f16 100644
--- a/test/unit/org/apache/cassandra/cql3/CQLTester.java
+++ b/test/unit/org/apache/cassandra/cql3/CQLTester.java
@@ -88,11 +88,6 @@ import com.datastax.driver.core.UDTValue;
 import com.datastax.driver.core.UserType;
 import com.datastax.driver.core.exceptions.UnauthorizedException;
 import com.datastax.shaded.netty.channel.EventLoopGroup;
-import com.datastax.driver.core.Row;
-import com.datastax.driver.core.Session;
-import com.datastax.driver.core.SimpleStatement;
-import com.datastax.driver.core.SocketOptions;
-import com.datastax.driver.core.Statement;
 import org.apache.cassandra.SchemaLoader;
 import org.apache.cassandra.ServerTestUtils;
 import org.apache.cassandra.Util;
diff --git a/test/unit/org/apache/cassandra/cql3/ViewSchemaTest.java b/test/unit/org/apache/cassandra/cql3/ViewSchemaTest.java
index 7dd5a4f101..b58777e5a9 100644
--- a/test/unit/org/apache/cassandra/cql3/ViewSchemaTest.java
+++ b/test/unit/org/apache/cassandra/cql3/ViewSchemaTest.java
@@ -27,7 +27,6 @@ import java.util.Date;
 import java.util.HashSet;
 import java.util.UUID;
 
-import org.junit.After;
 import org.junit.Assert;
 import org.junit.Test;
 
diff --git a/test/unit/org/apache/cassandra/db/CounterCacheTest.java b/test/unit/org/apache/cassandra/db/CounterCacheTest.java
index 780727a4c7..bcf8b676ea 100644
--- a/test/unit/org/apache/cassandra/db/CounterCacheTest.java
+++ b/test/unit/org/apache/cassandra/db/CounterCacheTest.java
@@ -35,18 +35,10 @@ import org.junit.Test;
 import org.apache.cassandra.SchemaLoader;
 import org.apache.cassandra.db.marshal.CounterColumnType;
 import org.apache.cassandra.db.marshal.Int32Type;
-import org.apache.cassandra.dht.Bounds;
-import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.exceptions.WriteTimeoutException;
-import org.apache.cassandra.schema.ColumnMetadata;
-import org.apache.cassandra.schema.KeyspaceMetadata;
-import org.apache.cassandra.schema.KeyspaceParams;
 import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.schema.SchemaTestUtil;
-import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.service.CacheService;
-import org.apache.cassandra.utils.ByteBufferUtil;
 
 import static org.apache.cassandra.utils.ByteBufferUtil.bytes;
 import static org.junit.Assert.assertEquals;
diff --git a/test/unit/org/apache/cassandra/db/ReadCommandTest.java b/test/unit/org/apache/cassandra/db/ReadCommandTest.java
index 179a584dca..a96a0707f7 100644
--- a/test/unit/org/apache/cassandra/db/ReadCommandTest.java
+++ b/test/unit/org/apache/cassandra/db/ReadCommandTest.java
@@ -30,7 +30,6 @@ import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
-import java.util.UUID;
 import java.util.function.Supplier;
 import java.util.stream.IntStream;
 
diff --git a/test/unit/org/apache/cassandra/db/RowCacheTest.java b/test/unit/org/apache/cassandra/db/RowCacheTest.java
index 474b3a5ce8..7dfd354c8c 100644
--- a/test/unit/org/apache/cassandra/db/RowCacheTest.java
+++ b/test/unit/org/apache/cassandra/db/RowCacheTest.java
@@ -37,12 +37,9 @@ import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.db.marshal.AsciiType;
-import org.apache.cassandra.db.rows.*;
 import org.apache.cassandra.db.compaction.CompactionManager;
 import org.apache.cassandra.db.filter.ColumnFilter;
-import org.apache.cassandra.db.marshal.AsciiType;
 import org.apache.cassandra.db.marshal.IntegerType;
-import org.apache.cassandra.db.marshal.ValueAccessors;
 import org.apache.cassandra.db.partitions.CachedPartition;
 import org.apache.cassandra.db.rows.Cell;
 import org.apache.cassandra.db.rows.ColumnData;
@@ -53,11 +50,9 @@ import org.apache.cassandra.dht.Bounds;
 import org.apache.cassandra.dht.ByteOrderedPartitioner.BytesToken;
 import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.exceptions.ConfigurationException;
-import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.locator.TokenMetadata;
 import org.apache.cassandra.metrics.ClearableHistogram;
 import org.apache.cassandra.schema.CachingParams;
-import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.KeyspaceParams;
 import org.apache.cassandra.schema.SchemaTestUtil;
 import org.apache.cassandra.service.CacheService;
diff --git a/test/unit/org/apache/cassandra/db/SchemaCQLHelperTest.java b/test/unit/org/apache/cassandra/db/SchemaCQLHelperTest.java
index f28862351c..53bfe12b76 100644
--- a/test/unit/org/apache/cassandra/db/SchemaCQLHelperTest.java
+++ b/test/unit/org/apache/cassandra/db/SchemaCQLHelperTest.java
@@ -27,13 +27,9 @@ import org.junit.Before;
 import org.junit.Test;
 
 import com.fasterxml.jackson.databind.JsonNode;
-import org.apache.cassandra.*;
-import org.apache.cassandra.cql3.*;
 import org.apache.cassandra.cql3.statements.schema.IndexTarget;
-import org.apache.cassandra.db.marshal.*;
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.index.sasi.SASIIndex;
-import org.apache.cassandra.schema.*;
 import org.apache.cassandra.service.reads.SpeculativeRetryPolicy;
 import org.apache.cassandra.utils.ByteBufferUtil;
 import org.apache.cassandra.utils.FBUtilities;
@@ -45,26 +41,16 @@ import java.util.Arrays;
 import java.util.Collections;
 import java.util.stream.Collectors;
 
-import com.google.common.collect.ImmutableList;
-import com.google.common.collect.ImmutableMap;
-import com.google.common.io.Files;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Test;
-
 import org.apache.cassandra.SchemaLoader;
 import org.apache.cassandra.cql3.CQLTester;
 import org.apache.cassandra.cql3.ColumnIdentifier;
 import org.apache.cassandra.cql3.FieldIdentifier;
-import org.apache.cassandra.cql3.statements.schema.IndexTarget;
 import org.apache.cassandra.db.marshal.AsciiType;
 import org.apache.cassandra.db.marshal.IntegerType;
 import org.apache.cassandra.db.marshal.ListType;
 import org.apache.cassandra.db.marshal.MapType;
 import org.apache.cassandra.db.marshal.ReversedType;
 import org.apache.cassandra.db.marshal.UserType;
-import org.apache.cassandra.exceptions.ConfigurationException;
-import org.apache.cassandra.index.sasi.SASIIndex;
 import org.apache.cassandra.schema.ColumnMetadata;
 import org.apache.cassandra.schema.CompactionParams;
 import org.apache.cassandra.schema.CompressionParams;
@@ -74,12 +60,6 @@ import org.apache.cassandra.schema.KeyspaceParams;
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.Tables;
 import org.apache.cassandra.schema.Types;
-import org.apache.cassandra.service.reads.SpeculativeRetryPolicy;
-import org.apache.cassandra.utils.ByteBufferUtil;
-import org.apache.cassandra.utils.FBUtilities;
-import org.json.simple.JSONArray;
-import org.json.simple.JSONObject;
-import org.json.simple.parser.JSONParser;
 
 import static org.hamcrest.CoreMatchers.allOf;
 import static org.hamcrest.CoreMatchers.containsString;
diff --git a/test/unit/org/apache/cassandra/db/SystemKeyspaceTest.java b/test/unit/org/apache/cassandra/db/SystemKeyspaceTest.java
index e0600e4b4c..25ea6bb37c 100644
--- a/test/unit/org/apache/cassandra/db/SystemKeyspaceTest.java
+++ b/test/unit/org/apache/cassandra/db/SystemKeyspaceTest.java
@@ -23,7 +23,6 @@ import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashSet;
-import java.util.LinkedHashSet;
 import java.util.List;
 import java.util.Set;
 import java.util.UUID;
diff --git a/test/unit/org/apache/cassandra/db/commitlog/CommitLogTest.java b/test/unit/org/apache/cassandra/db/commitlog/CommitLogTest.java
index 48b78fff66..f078cb8ca9 100644
--- a/test/unit/org/apache/cassandra/db/commitlog/CommitLogTest.java
+++ b/test/unit/org/apache/cassandra/db/commitlog/CommitLogTest.java
@@ -19,6 +19,7 @@
 package org.apache.cassandra.db.commitlog;
 
 import org.apache.cassandra.config.CassandraRelevantProperties;
+import org.apache.cassandra.config.Config.DiskFailurePolicy;
 import org.apache.cassandra.distributed.shared.WithProperties;
 import org.apache.cassandra.io.util.File;
 
@@ -33,8 +34,10 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
+import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
+import java.util.Objects;
 import java.util.Random;
 import java.util.UUID;
 import java.util.concurrent.Callable;
@@ -71,7 +74,6 @@ import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.config.ParameterizedClass;
 import org.apache.cassandra.db.ColumnFamilyStore;
 import org.apache.cassandra.db.Keyspace;
-import org.apache.cassandra.db.Memtable;
 import org.apache.cassandra.db.Mutation;
 import org.apache.cassandra.db.MutationExceededMaxSizeException;
 import org.apache.cassandra.db.RowUpdateBuilder;
@@ -90,9 +92,7 @@ import org.apache.cassandra.io.FSWriteError;
 import org.apache.cassandra.io.compress.DeflateCompressor;
 import org.apache.cassandra.io.compress.LZ4Compressor;
 import org.apache.cassandra.io.compress.SnappyCompressor;
-import org.apache.cassandra.io.compress.ZstdCompressor;
 import org.apache.cassandra.io.sstable.format.SSTableReader;
-import org.apache.cassandra.io.util.FileUtils;
 import org.apache.cassandra.net.MessagingService;
 import org.apache.cassandra.schema.KeyspaceParams;
 import org.apache.cassandra.security.CipherFactory;
diff --git a/test/unit/org/apache/cassandra/db/commitlog/CommitLogUpgradeTest.java b/test/unit/org/apache/cassandra/db/commitlog/CommitLogUpgradeTest.java
index 0c8ae0f35a..31b082ff2a 100644
--- a/test/unit/org/apache/cassandra/db/commitlog/CommitLogUpgradeTest.java
+++ b/test/unit/org/apache/cassandra/db/commitlog/CommitLogUpgradeTest.java
@@ -31,7 +31,6 @@ import org.junit.Assert;
 
 import com.google.common.base.Predicate;
 import org.junit.After;
-import org.junit.Assert;
 import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -48,8 +47,6 @@ import org.apache.cassandra.db.rows.Cell;
 import org.apache.cassandra.db.rows.Row;
 import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.KeyspaceParams;
-import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.schema.SchemaTestUtil;
 import org.apache.cassandra.schema.TableId;
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.Tables;
diff --git a/test/unit/org/apache/cassandra/schema/MigrationCoordinatorTest.java b/test/unit/org/apache/cassandra/schema/MigrationCoordinatorTest.java
index 0d1516856f..3783320566 100644
--- a/test/unit/org/apache/cassandra/schema/MigrationCoordinatorTest.java
+++ b/test/unit/org/apache/cassandra/schema/MigrationCoordinatorTest.java
@@ -41,7 +41,6 @@ import org.slf4j.LoggerFactory;
 
 import org.apache.cassandra.concurrent.ImmediateExecutor;
 import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.Mutation;
 import org.apache.cassandra.gms.ApplicationState;
 import org.apache.cassandra.gms.EndpointState;
@@ -97,7 +96,6 @@ public class MigrationCoordinatorTest
             throw new AssertionError(e);
         }
 
-        CassandraRelevantProperties.SCHEMA_PULL_BACKOFF_DELAY_MS.setInt(0);
         DatabaseDescriptor.daemonInitialization();
 
         when(validEndpointState.getApplicationState(ApplicationState.RELEASE_VERSION)).thenReturn(VersionedValue.unsafeMakeVersionedValue(FBUtilities.getReleaseVersionString(), 0));
diff --git a/test/unit/org/apache/cassandra/schema/SchemaKeyspaceTest.java b/test/unit/org/apache/cassandra/schema/SchemaKeyspaceTest.java
index 16275a5c8f..4a5db336c6 100644
--- a/test/unit/org/apache/cassandra/schema/SchemaKeyspaceTest.java
+++ b/test/unit/org/apache/cassandra/schema/SchemaKeyspaceTest.java
@@ -24,7 +24,6 @@ import java.util.Collection;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Set;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.CyclicBarrier;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
diff --git a/test/unit/org/apache/cassandra/service/MoveTest.java b/test/unit/org/apache/cassandra/service/MoveTest.java
index 81b452fc05..65668c29b2 100644
--- a/test/unit/org/apache/cassandra/service/MoveTest.java
+++ b/test/unit/org/apache/cassandra/service/MoveTest.java
@@ -58,37 +58,24 @@ import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.marshal.BytesType;
 import org.apache.cassandra.SchemaLoader;
 import org.apache.cassandra.Util;
-import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.db.marshal.BytesType;
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.RandomPartitioner;
 import org.apache.cassandra.dht.RandomPartitioner.BigIntegerToken;
 import org.apache.cassandra.dht.Range;
 import org.apache.cassandra.dht.Token;
-import org.apache.cassandra.diag.DiagnosticEventService;
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.gms.ApplicationState;
 import org.apache.cassandra.gms.Gossiper;
-import org.apache.cassandra.gms.GossiperEvent;
 import org.apache.cassandra.gms.VersionedValue;
 import org.apache.cassandra.locator.AbstractNetworkTopologySnitch;
 import org.apache.cassandra.locator.AbstractReplicationStrategy;
-import org.apache.cassandra.locator.EndpointsForRange;
-import org.apache.cassandra.locator.EndpointsForToken;
-import org.apache.cassandra.locator.InetAddressAndPort;
 import org.apache.cassandra.locator.NetworkTopologyStrategy;
 import org.apache.cassandra.locator.PendingRangeMaps;
-import org.apache.cassandra.locator.RangesAtEndpoint;
-import org.apache.cassandra.locator.RangesByEndpoint;
-import org.apache.cassandra.locator.Replica;
-import org.apache.cassandra.locator.ReplicaCollection;
 import org.apache.cassandra.locator.SimpleSnitch;
 import org.apache.cassandra.locator.TokenMetadata;
 import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.KeyspaceParams;
 import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.schema.SchemaTestUtil;
-import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.Tables;
 
 import static org.junit.Assert.assertEquals;
diff --git a/test/unit/org/apache/cassandra/service/StorageServiceServerTest.java b/test/unit/org/apache/cassandra/service/StorageServiceServerTest.java
index 47cb3e4956..3e8b804e50 100644
--- a/test/unit/org/apache/cassandra/service/StorageServiceServerTest.java
+++ b/test/unit/org/apache/cassandra/service/StorageServiceServerTest.java
@@ -27,7 +27,6 @@ import java.util.Collections;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
-import java.util.Random;
 import java.util.UUID;
 
 import com.google.common.collect.HashMultimap;
@@ -39,6 +38,7 @@ import org.junit.Test;
 import org.apache.cassandra.audit.AuditLogManager;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.Keyspace;
+import org.apache.cassandra.db.SystemKeyspace;
 import org.apache.cassandra.db.commitlog.CommitLog;
 import org.apache.cassandra.dht.Murmur3Partitioner;
 import org.apache.cassandra.dht.Murmur3Partitioner.LongToken;
diff --git a/test/unit/org/apache/cassandra/triggers/TriggersSchemaTest.java b/test/unit/org/apache/cassandra/triggers/TriggersSchemaTest.java
index 1b253e2158..6b875a37f1 100644
--- a/test/unit/org/apache/cassandra/triggers/TriggersSchemaTest.java
+++ b/test/unit/org/apache/cassandra/triggers/TriggersSchemaTest.java
@@ -28,9 +28,6 @@ import org.apache.cassandra.schema.SchemaTestUtil;
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.KeyspaceMetadata;
 import org.apache.cassandra.schema.KeyspaceParams;
-import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.schema.SchemaTestUtil;
-import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.Tables;
 import org.apache.cassandra.schema.TriggerMetadata;
 import org.apache.cassandra.schema.Triggers;
