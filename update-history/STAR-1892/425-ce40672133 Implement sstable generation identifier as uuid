--- a/.build/build-rat.xml
+++ b/.build/build-rat.xml
@@ -41,31 +41,6 @@
         <rat:report reportFile="${build.dir}/rat.txt">
             <fileset dir="." includesfile="${build.dir}/.ratinclude">
                  <!-- Config files with not much creativity -->
-<<<<<<<
-                 <exclude name="**/ide/**/*"/>
-                 <exclude name="**/metrics-reporter-config-sample.yaml"/>
-                 <exclude name="**/cassandra.yaml"/>
-                 <exclude name="**/cassandra-murmur.yaml"/>
-                 <exclude name="**/cassandra-seeds.yaml"/>
-                 <exclude NAME="**/doc/antora.yml"/>
-                 <exclude name="**/test/conf/cassandra.yaml"/>
-                 <exclude name="**/test/conf/cassandra_deprecated_parameters_names.yaml"/>
-                 <exclude name="**/test/conf/cassandra_encryption.yaml"/>
-                 <exclude name="**/test/conf/cdc.yaml"/>
-                 <exclude name="**/test/conf/commitlog_compression_LZ4.yaml"/>
-                 <exclude name="**/test/conf/commitlog_compression_Zstd.yaml"/>
-                 <exclude name="**/test/conf/system_keyspaces_directory.yaml"/>
-                 <exclude name="**/test/conf/sstableloader_with_encryption.yaml"/>
-                 <exclude name="**/test/conf/unit-test-conf/test-native-port.yaml"/>
-                 <exclude name="**/test/data/jmxdump/cassandra-3.0-jmx.yaml"/>
-                 <exclude name="**/test/data/jmxdump/cassandra-3.11-jmx.yaml"/>
-                 <exclude name="**/test/data/jmxdump/cassandra-4.0-jmx.yaml"/>
-                 <exclude name="**/test/data/jmxdump/cassandra-4.0-cc-jmx.yaml"/>
-                 <exclude name="**/tools/cqlstress-counter-example.yaml"/>
-                 <exclude name="**/tools/cqlstress-example.yaml"/>
-                 <exclude name="**/tools/cqlstress-insanity-example.yaml"/>
-                 <exclude name="**/tools/cqlstress-lwt-example.yaml"/>
-=======
                  <exclude name=".asf.yaml"/>
                  <exclude name="**/cassandra*.yaml"/>
                  <exclude NAME="doc/antora.yml"/>
@@ -94,7 +69,6 @@
                  <exclude name="test/data/**/*.sha1"/>
                  <exclude name="test/data/CASSANDRA-15313/lz4-jvm-crash-failure.txt"/>
                  <exclude name="test/data/jmxdump/cassandra-*-jmx.yaml"/>
->>>>>>>
                  <!-- Documentation files -->
                  <exclude name=".github/pull_request_template.md"/>
                  <exclude NAME="doc/modules/**/*"/>
--- a/NEWS.txt
+++ b/NEWS.txt
@@ -366,12 +366,9 @@
       When the node is restarted with UUID based generation identifiers enabled, each newly created sstable will have
       a UUID based generation identifier and such files are not readable by previous Cassandra versions. In the future
       those new identifiers will become enabled by default.
-<<<<<<<
-=======
     - Resetting schema behavior has changed in 4.1 so that: 1) resetting schema is prohibited when there is no live node
       where the schema could be fetched from, and 2) truncating local schema keyspace is postponed to the moment when
       the node receives schema from some other node.
->>>>>>>
 
 Upgrading
 ---------
--- a/conf/cassandra.yaml
+++ b/conf/cassandra.yaml
@@ -559,12 +559,8 @@
 
 # When in periodic commitlog mode, the number of milliseconds to block writes
 # while waiting for a slow disk flush to complete.
-<<<<<<<
 # Min unit: ms
 # periodic_commitlog_sync_lag_block:
-=======
-# periodic_commitlog_sync_lag_block_in_ms:
->>>>>>>
 
 # The size of the individual commitlog file segments.  A commitlog
 # segment may be archived, deleted, or recycled once all the data
@@ -611,17 +607,6 @@
 # any class that implements the SeedProvider interface and has a
 # constructor that takes a Map<String, String> of parameters will do.
 seed_provider:
-<<<<<<<
-    # Addresses of hosts that are deemed contact points.
-    # Cassandra nodes use this list of hosts to find each other and learn
-    # the topology of the ring.  You must change this if you are running
-    # multiple nodes!
-    - class_name: org.apache.cassandra.locator.SimpleSeedProvider
-      parameters:
-          # seeds is actually a comma-delimited list of addresses.
-          # Ex: "<ip1>,<ip2>,<ip3>"
-          - seeds: "127.0.0.1:7000"
-=======
   # Addresses of hosts that are deemed contact points.
   # Cassandra nodes use this list of hosts to find each other and learn
   # the topology of the ring.  You must change this if you are running
@@ -634,7 +619,6 @@
       # If set to "true", SimpleSeedProvider will return all IP addresses for a DNS name,
       # based on the configured name service on the system. Defaults to "false".
       #  resolve_multiple_ip_addresses_per_dns_record: "false"
->>>>>>>
 
 # For workloads with more data than can fit in memory, Cassandra's
 # bottleneck will be reads that need to fetch data from
@@ -1139,14 +1123,6 @@
 # and eventually get removed from the configuration.
 uuid_sstable_identifiers_enabled: false
 
-# Starting from 4.1 sstables support UUID based generation identifiers. They are disabled by default
-# because once enabled, there is no easy way to downgrade. When the node is restarted with this option
-# set to true, each newly created sstable will have a UUID based generation identifier and such files are
-# not readable by previous Cassandra versions. At some point, this option will become true by default
-# and eventually get removed from the configuration.
-# In Converged Cassandra, we enable this option by default
-enable_uuid_sstable_identifiers: true
-
 # When enabled, permits Cassandra to zero-copy stream entire eligible
 # SSTables between nodes, including every component.
 # This speeds up the network transfer significantly subject to
@@ -1438,12 +1414,8 @@
 
 # controls how often to perform the more expensive part of host score
 # calculation
-<<<<<<<
 # Min unit: ms
 dynamic_snitch_update_interval: 100ms
-=======
-dynamic_snitch_update_interval_in_ms: 100
->>>>>>>
 # controls how often to reset all host scores, allowing a bad host to
 # possibly recover
 # Min unit: ms
--- a/src/java/org/apache/cassandra/config/Config.java
+++ b/src/java/org/apache/cassandra/config/Config.java
@@ -813,11 +813,7 @@
     public volatile boolean auto_optimise_preview_repair_streams = false;
 
     // see CASSANDRA-17048 and the comment in cassandra.yaml
-<<<<<<<
-    public boolean enable_uuid_sstable_identifiers = false;
-=======
     public boolean uuid_sstable_identifiers_enabled = false;
->>>>>>>
 
     /**
      * Client mode means that the process is a pure client, that uses C* code base but does
--- a/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
+++ b/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
@@ -4629,7 +4629,6 @@
         }
     }
 
-<<<<<<<
     public static DurationSpec.LongNanosecondsBound getStreamingStateExpires()
     {
         return conf.streaming_state_expires;
@@ -4917,10 +4916,5 @@
     public static RepairRetrySpec getRepairRetrySpec()
     {
         return conf == null ? new RepairRetrySpec() : conf.repair.retries;
-=======
-    public static boolean isUUIDSSTableIdentifiersEnabled()
-    {
-        return conf.enable_uuid_sstable_identifiers;
->>>>>>>
     }
 }
--- a/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
+++ b/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
@@ -44,10 +44,7 @@
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
 import java.util.concurrent.atomic.AtomicReference;
-<<<<<<<
-=======
 import java.util.function.Consumer;
->>>>>>>
 import java.util.function.Supplier;
 import java.util.regex.Pattern;
 import java.util.stream.Collectors;
@@ -122,12 +119,9 @@
 import org.apache.cassandra.io.FSWriteError;
 import org.apache.cassandra.io.sstable.Component;
 import org.apache.cassandra.io.sstable.Descriptor;
-<<<<<<<
-=======
 import org.apache.cassandra.io.sstable.IScrubber;
 import org.apache.cassandra.io.sstable.IVerifier;
 import org.apache.cassandra.io.sstable.SSTable;
->>>>>>>
 import org.apache.cassandra.io.sstable.SSTableId;
 import org.apache.cassandra.io.sstable.SSTableIdFactory;
 import org.apache.cassandra.io.sstable.SSTableMultiWriter;
@@ -492,14 +486,9 @@
         crcCheckChance = new DefaultValue<>(metadata.get().params.crcCheckChance);
         viewManager = keyspace.viewManager.forTable(metadata.id);
         this.sstableIdGenerator = sstableIdGenerator;
-<<<<<<<
         sampleReadLatencyMicros = DatabaseDescriptor.getReadRpcTimeout(TimeUnit.MICROSECONDS) / 2;
         additionalWriteLatencyMicros = DatabaseDescriptor.getWriteRpcTimeout(TimeUnit.MICROSECONDS) / 2;
         memtableFactory = metadata.get().params.memtable.factory();
-=======
-        sampleReadLatencyNanos = DatabaseDescriptor.getReadRpcTimeout(NANOSECONDS) / 2;
-        additionalWriteLatencyNanos = DatabaseDescriptor.getWriteRpcTimeout(NANOSECONDS) / 2;
->>>>>>>
 
         logger.info("Initializing {}.{}", getKeyspaceName(), name);
 
@@ -896,16 +885,9 @@
                                            descriptor.cfname,
                                            // Increment the generation until we find a filename that doesn't exist. This is needed because the new
                                            // SSTables that are being loaded might already use these generation numbers.
-<<<<<<<
                                            sstableIdGenerator.get());
         }
         while (newDescriptor.fileFor(Components.DATA).exists());
-=======
-                                           sstableIdGenerator.get(),
-                                           descriptor.formatType);
-        }
-        while (newDescriptor.fileFor(Component.DATA).exists());
->>>>>>>
         return newDescriptor;
     }
 
@@ -966,7 +948,6 @@
     {
         Descriptor newDescriptor = new Descriptor(version,
                                                   directory,
-<<<<<<<
                                                   getKeyspaceName(),
                                                   name,
                                                   sstableIdGenerator.get());
@@ -985,14 +966,6 @@
             switchMemtableIfCurrent(currentMemtable, reason);
         else
             elseNotify.accept(currentMemtable);
-=======
-                                                  keyspace.getName(),
-                                                  name,
-                                                  sstableIdGenerator.get(),
-                                                  format);
-        assert !newDescriptor.fileFor(Component.DATA).exists();
-        return newDescriptor;
->>>>>>>
     }
 
     /**
--- a/src/java/org/apache/cassandra/db/Directories.java
+++ b/src/java/org/apache/cassandra/db/Directories.java
@@ -39,10 +39,7 @@
 import java.util.Spliterator;
 import java.util.concurrent.ThreadLocalRandom;
 import java.util.function.BiPredicate;
-<<<<<<<
-=======
 import java.util.function.Function;
->>>>>>>
 import java.util.function.Supplier;
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
@@ -64,12 +61,6 @@
 import org.apache.cassandra.io.FSNoDiskAvailableForWriteError;
 import org.apache.cassandra.io.FSReadError;
 import org.apache.cassandra.io.FSWriteError;
-<<<<<<<
-import org.apache.cassandra.io.sstable.*;
-import org.apache.cassandra.io.sstable.SnapshotDeletingTask;
-import org.apache.cassandra.io.sstable.format.SSTableReader;
-import org.apache.cassandra.io.util.FileUtils;
-=======
 import org.apache.cassandra.io.sstable.Component;
 import org.apache.cassandra.io.sstable.Descriptor;
 import org.apache.cassandra.io.sstable.SSTable;
@@ -79,7 +70,6 @@
 import org.apache.cassandra.io.util.FileStoreUtils;
 import org.apache.cassandra.io.util.FileUtils;
 import org.apache.cassandra.io.util.PathUtils;
->>>>>>>
 import org.apache.cassandra.schema.SchemaConstants;
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.service.snapshot.SnapshotManifest;
@@ -1000,11 +990,7 @@
         public List<Map.Entry<Descriptor, Set<Component>>> sortedList()
         {
             List<Map.Entry<Descriptor, Set<Component>>> sortedEntries = new ArrayList<>(list().entrySet());
-<<<<<<<
             sortedEntries.sort((o1, o2) -> SSTableIdFactory.COMPARATOR.compare(o1.getKey().id, o2.getKey().id));
-=======
-            sortedEntries.sort(Comparator.comparing(t -> t.getKey().id, SSTableIdFactory.COMPARATOR));
->>>>>>>
             return sortedEntries;
         }
 
--- a/src/java/org/apache/cassandra/db/SystemKeyspace.java
+++ b/src/java/org/apache/cassandra/db/SystemKeyspace.java
@@ -127,16 +127,11 @@
 import static org.apache.cassandra.cql3.QueryProcessor.executeInternal;
 import static org.apache.cassandra.cql3.QueryProcessor.executeInternalWithNowInSec;
 import static org.apache.cassandra.cql3.QueryProcessor.executeOnceInternal;
-<<<<<<<
 import static org.apache.cassandra.service.paxos.Commit.latest;
 import static org.apache.cassandra.utils.CassandraVersion.NULL_VERSION;
 import static org.apache.cassandra.utils.CassandraVersion.UNREADABLE_VERSION;
 import static org.apache.cassandra.utils.Clock.Global.currentTimeMillis;
 import static org.apache.cassandra.utils.FBUtilities.now;
-=======
-import static org.apache.cassandra.utils.CassandraVersion.NULL_VERSION;
-import static org.apache.cassandra.utils.CassandraVersion.UNREADABLE_VERSION;
->>>>>>>
 
 public final class SystemKeyspace
 {
@@ -345,11 +340,7 @@
                 "CREATE TABLE %s ("
                 + "keyspace_name text,"
                 + "table_name text,"
-<<<<<<<
-                + "id blob,"
-=======
                 + "id text,"
->>>>>>>
                 + "rate_120m double,"
                 + "rate_15m double,"
                 + "PRIMARY KEY ((keyspace_name, table_name, id)))")
@@ -1497,12 +1488,7 @@
      */
     public static RestorableMeter getSSTableReadMeter(String keyspace, String table, SSTableId id)
     {
-<<<<<<<
-        String cql = "SELECT * FROM system.%s WHERE keyspace_name=? and table_name=? and id=?";
-        UntypedResultSet results = executeInternal(format(cql, SSTABLE_ACTIVITY_V2), keyspace, table, id.asBytes());
-=======
         UntypedResultSet results = readSSTableActivity(keyspace, table, id);
->>>>>>>
 
         if (results.isEmpty())
             return new RestorableMeter();
@@ -1530,11 +1516,7 @@
         executeInternal(format(cql, SSTABLE_ACTIVITY_V2),
                         keyspace,
                         table,
-<<<<<<<
-                        id.asBytes(),
-=======
                         id.toString(),
->>>>>>>
                         meter.fifteenMinuteRate(),
                         meter.twoHourRate());
 
@@ -1558,11 +1540,7 @@
     public static void clearSSTableReadMeter(String keyspace, String table, SSTableId id)
     {
         String cql = "DELETE FROM system.%s WHERE keyspace_name=? AND table_name=? and id=?";
-<<<<<<<
-        executeInternal(format(cql, SSTABLE_ACTIVITY_V2), keyspace, table, id.asBytes());
-=======
         executeInternal(format(cql, SSTABLE_ACTIVITY_V2), keyspace, table, id.toString());
->>>>>>>
         if (!DatabaseDescriptor.isUUIDSSTableIdentifiersEnabled() && id instanceof SequenceBasedSSTableId)
         {
             // we do this in order to make it possible to downgrade until we switch in cassandra.yaml to UUID based ids
--- a/src/java/org/apache/cassandra/db/compaction/CompactionLogger.java
+++ b/src/java/org/apache/cassandra/db/compaction/CompactionLogger.java
@@ -175,13 +175,8 @@
     private JsonNode formatSSTable(AbstractCompactionStrategy strategy, SSTableReader sstable)
     {
         ObjectNode node = json.objectNode();
-<<<<<<<
-        node.put("generation", sstable.descriptor.id.asString());
-        node.put("version", sstable.descriptor.version.getVersion());
-=======
         node.put("generation", sstable.descriptor.id.toString());
         node.put("version", sstable.descriptor.version.version);
->>>>>>>
         node.put("size", sstable.onDiskLength());
         JsonNode logResult = strategy.strategyLogger().sstable(sstable);
         if (logResult != null)
--- a/src/java/org/apache/cassandra/db/compaction/LeveledGenerations.java
+++ b/src/java/org/apache/cassandra/db/compaction/LeveledGenerations.java
@@ -37,10 +37,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-<<<<<<<
-=======
-import org.apache.cassandra.config.Config;
->>>>>>>
 import org.apache.cassandra.io.sstable.SSTableIdFactory;
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.utils.FBUtilities;
--- a/src/java/org/apache/cassandra/io/sstable/AbstractSSTableSimpleWriter.java
+++ b/src/java/org/apache/cassandra/io/sstable/AbstractSSTableSimpleWriter.java
@@ -17,18 +17,6 @@
  */
 package org.apache.cassandra.io.sstable;
 
-<<<<<<<
-=======
-import java.io.File;
-import java.io.IOException;
-import java.io.Closeable;
-import java.nio.ByteBuffer;
-import java.nio.file.Files;
-import java.nio.file.Path;
-import java.util.Collections;
-import java.util.concurrent.atomic.AtomicReference;
-import java.util.stream.Stream;
->>>>>>>
 
 import java.io.Closeable;
 import java.io.IOException;
@@ -58,11 +46,7 @@
     protected final File directory;
     protected final TableMetadataRef metadata;
     protected final RegularAndStaticColumns columns;
-<<<<<<<
-    protected SSTableFormat.Type formatType = SSTableFormat.Type.current();
-=======
     protected SSTableFormat<?, ?> format = DatabaseDescriptor.getSelectedSSTableFormat();
->>>>>>>
     protected static final AtomicReference<SSTableId> id = new AtomicReference<>(SSTableIdFactory.instance.defaultBuilder().generator(Stream.empty()).get());
     protected boolean makeRangeAware = false;
 
@@ -83,11 +67,7 @@
         this.makeRangeAware = makeRangeAware;
     }
 
-<<<<<<<
-    protected SSTableTxnWriter createWriter() throws IOException
-=======
     protected SSTableTxnWriter createWriter(SSTable.Owner owner) throws IOException
->>>>>>>
     {
         SerializationHeader header = new SerializationHeader(true, metadata.get(), columns, EncodingStats.NO_STATS);
 
@@ -105,11 +85,7 @@
                                        owner);
     }
 
-<<<<<<<
-    private static Descriptor createDescriptor(File directory, final String keyspace, final String columnFamily, final SSTableFormat.Type fmt) throws IOException
-=======
     private static Descriptor createDescriptor(File directory, final String keyspace, final String columnFamily, final SSTableFormat<?, ?> fmt) throws IOException
->>>>>>>
     {
         SSTableId nextGen = getNextId(directory, columnFamily);
         return new Descriptor(directory, keyspace, columnFamily, nextGen, fmt);
@@ -121,13 +97,8 @@
         {
             try (Stream<Path> existingPaths = Files.list(directory.toPath()))
             {
-<<<<<<<
                 Stream<SSTableId> existingIds = existingPaths.map(File::new)
                                                              .map(SSTable::tryDescriptorFromFile)
-=======
-                Stream<SSTableId> existingIds = existingPaths.map(Path::toFile)
-                                                             .map(SSTable::tryDescriptorFromFilename)
->>>>>>>
                                                              .filter(d -> d != null && d.cfname.equals(columnFamily))
                                                              .map(d -> d.id);
 
--- a/src/java/org/apache/cassandra/io/sstable/Descriptor.java
+++ b/src/java/org/apache/cassandra/io/sstable/Descriptor.java
@@ -17,18 +17,10 @@
  */
 package org.apache.cassandra.io.sstable;
 
-<<<<<<<
-import java.io.File;
-import java.io.IOError;
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-=======
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Set;
 import java.util.regex.Matcher;
->>>>>>>
 import java.util.regex.Pattern;
 
 import com.google.common.annotations.VisibleForTesting;
@@ -101,10 +93,6 @@
     public final String ksname;
     public final String cfname;
     public final SSTableId id;
-<<<<<<<
-=======
-    public final SSTableFormat.Type formatType;
->>>>>>>
     private final int hashCode;
     private final String prefix;
     private final File baseFile;
@@ -115,30 +103,12 @@
     @VisibleForTesting
     public Descriptor(File directory, String ksname, String cfname, SSTableId id)
     {
-<<<<<<<
         this(DatabaseDescriptor.getSelectedSSTableFormat().getLatestVersion(), directory, ksname, cfname, id);
-=======
-        this(SSTableFormat.Type.current().info.getLatestVersion(), directory, ksname, cfname, id, SSTableFormat.Type.current());
->>>>>>>
     }
 
     /**
      * Constructor for sstable writers only.
      */
-<<<<<<<
-    public Descriptor(File directory, String ksname, String cfname, SSTableId id, SSTableFormat.Type formatType)
-    {
-        this(formatType.info.getLatestVersion(), directory, ksname, cfname, id, formatType);
-    }
-
-    @VisibleForTesting
-    public Descriptor(String version, File directory, String ksname, String cfname, SSTableId id, SSTableFormat.Type formatType)
-    {
-        this(formatType.info.getVersion(version), directory, ksname, cfname, id, formatType);
-    }
-
-    public Descriptor(Version version, File directory, String ksname, String cfname, SSTableId id, SSTableFormat.Type formatType)
-=======
     public Descriptor(File directory, String ksname, String cfname, SSTableId id, SSTableFormat<?, ?> format)
     {
         this(format.getLatestVersion(), directory, ksname, cfname, id);
@@ -151,7 +121,6 @@
     }
 
     public Descriptor(Version version, File directory, String ksname, String cfname, SSTableId id)
->>>>>>>
     {
         checkNotNull(version);
         checkNotNull(directory);
@@ -163,7 +132,6 @@
         this.ksname = ksname;
         this.cfname = cfname;
         this.id = id;
-<<<<<<<
 
         StringBuilder buf = new StringBuilder();
         appendFileName(buf);
@@ -177,25 +145,11 @@
     private String tmpFilenameFor(Component component)
     {
         return fileFor(component) + TMP_EXT;
-=======
-        this.formatType = formatType;
-
-        hashCode = Objects.hashCode(version, this.directory, id, ksname, cfname, formatType);
-    }
-
-    public Descriptor withGeneration(SSTableId newId)
-    {
-        return new Descriptor(version, directory, ksname, cfname, newId, formatType);
->>>>>>>
     }
 
     public File tmpFileFor(Component component)
     {
-<<<<<<<
-        return new Descriptor(newType.info.getLatestVersion(), directory, ksname, cfname, id, newType);
-=======
         return new File(directory.toPath().resolve(tmpFilenameFor(component)));
->>>>>>>
     }
 
     private String tmpFilenameForStreaming(Component component)
@@ -219,14 +173,6 @@
     }
 
     public File fileFor(Component component)
-<<<<<<<
-=======
-    {
-        return new File(filenameFor(component));
-    }
-
-    public String baseFilename()
->>>>>>>
     {
         return new File(directory.toPath().resolve(filenameFor(component)));
     }
@@ -239,13 +185,8 @@
     private void appendFileName(StringBuilder buff)
     {
         buff.append(version).append(separator);
-<<<<<<<
-        buff.append(id.asString());
-        buff.append(separator).append(formatType.name);
-=======
         buff.append(id.toString());
         buff.append(separator).append(version.format.name());
->>>>>>>
     }
 
     public String relativeFilenameFor(Component component)
@@ -458,21 +399,8 @@
             throw invalidSSTable(name, "the 'id' part (%s) of the name doesn't parse as a valid unique identifier", tokens.get(1));
         }
 
-<<<<<<<
         SSTableFormat<?, ?> format = formatFromName(name, tokens);
         Component component = Component.parse(tokens.get(3), format);
-=======
-        String formatString = tokens.get(2);
-        SSTableFormat.Type format;
-        try
-        {
-            format = SSTableFormat.Type.validate(formatString);
-        }
-        catch (RuntimeException e)
-        {
-            throw invalidSSTable(name, "unknown 'format' part (%s)", formatString);
-        }
->>>>>>>
 
         Version version = format.getVersion(versionString);
         if (!version.isCompatible())
@@ -493,25 +421,6 @@
             this.id = id;
             this.component = component;
         }
-<<<<<<<
-=======
-
-        // Then it can be a backup or a snapshot
-        if (tableDir.getName().equals(Directories.BACKUPS_SUBDIR) && tableDir.getParentFile().getName().contains("-"))
-            tableDir = tableDir.getParentFile();
-        else
-        {
-            File keyspaceOrSnapshotDir = parentOf(name, tableDir);
-            if (keyspaceOrSnapshotDir.getName().equals(Directories.SNAPSHOT_SUBDIR)
-                && parentOf(name, keyspaceOrSnapshotDir).getName().contains("-"))
-                tableDir = parentOf(name, keyspaceOrSnapshotDir);
-        }
-
-        String table = tableDir.getName().split("-")[0] + indexName;
-        String keyspace = parentOf(name, tableDir).getName();
-
-        return Pair.create(new Descriptor(version, directory, keyspace, table, id, format), component);
->>>>>>>
     }
 
     private static File parentOf(String name, File file)
--- a/src/java/org/apache/cassandra/io/sstable/SSTableId.java
+++ b/src/java/org/apache/cassandra/io/sstable/SSTableId.java
@@ -18,19 +18,12 @@
 
 package org.apache.cassandra.io.sstable;
 
-<<<<<<<
-=======
-import java.io.File;
->>>>>>>
 import java.nio.ByteBuffer;
 import java.util.function.Supplier;
 import java.util.stream.Stream;
 
-<<<<<<<
-=======
 import org.apache.cassandra.io.util.File;
 
->>>>>>>
 /**
  * Represents a unique identifier in the sstable descriptor filename.
  * This ensures each sstable file uniqueness for the certain table on a single node. However, new implementations
@@ -40,11 +33,7 @@
  * A new implementation must adhere to the following invariants:
  * - Must be locally sortable - that is, the comparison must reflect the comparison of generation times of identifiers
  * generated on the same node
-<<<<<<<
  * - String representation must *not* include the {@link Descriptor#FILENAME_SEPARATOR} character, see {@link Descriptor#fromFileWithComponent(File)}
-=======
- * - String representation must *not* include the {@link Descriptor#FILENAME_SEPARATOR} character, see {@link Descriptor#fromFilenameWithComponent(File)}
->>>>>>>
  * - must be case-insensitive because the sstables can be stored on case-insensitive file system
  * <p>
  */
@@ -61,16 +50,10 @@
      * {@link Builder#fromString(String)}
      * <p>
      * Must not contain any {@link Descriptor#FILENAME_SEPARATOR} character as it is used in the Descriptor
-<<<<<<<
      * see {@link Descriptor#fromFileWithComponent(File)}
      */
     @Override
     String toString();
-=======
-     * see {@link Descriptor#fromFilenameWithComponent(File)}
-     */
-    String asString();
->>>>>>>
 
     /**
      * Builder that can create instances of certain implementation of {@link SSTableId}.
@@ -90,11 +73,7 @@
         /**
          * Creates an identifier instance from its string representation
          *
-<<<<<<<
-         * @param str string representation as returned by {@link #asString()}
-=======
          * @param str string representation as returned by {@link SSTableId#toString()}
->>>>>>>
          * @throws IllegalArgumentException when the provided string is not a valid string representation of the identifier
          */
         T fromString(String str) throws IllegalArgumentException;
--- a/src/java/org/apache/cassandra/io/sstable/SequenceBasedSSTableId.java
+++ b/src/java/org/apache/cassandra/io/sstable/SequenceBasedSSTableId.java
@@ -78,24 +78,11 @@
     }
 
     @Override
-<<<<<<<
-    public String asString()
-=======
     public String toString()
->>>>>>>
     {
         return String.valueOf(generation);
     }
 
-<<<<<<<
-=======
-    @Override
-    public String toString()
-    {
-        return asString();
-    }
-
->>>>>>>
     public static class Builder implements SSTableId.Builder<SequenceBasedSSTableId>
     {
         public final static Builder instance = new Builder();
--- a/src/java/org/apache/cassandra/io/sstable/UUIDBasedSSTableId.java
+++ b/src/java/org/apache/cassandra/io/sstable/UUIDBasedSSTableId.java
@@ -42,18 +42,12 @@
     public final static int BYTES_LEN = 16;
 
     private final TimeUUID uuid;
-<<<<<<<
-=======
     private final String repr;
->>>>>>>
 
     public UUIDBasedSSTableId(TimeUUID uuid)
     {
         this.uuid = uuid;
-<<<<<<<
-=======
         this.repr = asString();
->>>>>>>
     }
 
     @Override
@@ -65,12 +59,7 @@
                          .putLong(Long.BYTES, uuid.lsb());
     }
 
-<<<<<<<
-    @Override
-    public String asString()
-=======
     private String asString()
->>>>>>>
     {
         long ts = uuid.uuidTimestamp();
         long nanoPart = ts % 10_000_000;
@@ -88,11 +77,7 @@
     @Override
     public String toString()
     {
-<<<<<<<
-        return asString();
-=======
         return repr;
->>>>>>>
     }
 
     @Override
--- a/src/java/org/apache/cassandra/io/sstable/format/SSTableReader.java
+++ b/src/java/org/apache/cassandra/io/sstable/format/SSTableReader.java
@@ -178,20 +178,7 @@
     public static final Comparator<SSTableReader> maxTimestampDescending = maxTimestampAscending.reversed();
 
     // it's just an object, which we use regular Object equality on; we introduce a special class just for easy recognition
-<<<<<<<
     public static final class UniqueIdentifier
-=======
-    public static final class UniqueIdentifier {}
-
-    public static final Comparator<SSTableReader> sstableComparator = (o1, o2) -> o1.first.compareTo(o2.first);
-
-    public static final Comparator<SSTableReader> idComparator = Comparator.comparing(t -> t.descriptor.id, SSTableIdFactory.COMPARATOR);
-    public static final Comparator<SSTableReader> idReverseComparator = idComparator.reversed();
-
-    public static final Ordering<SSTableReader> sstableOrdering = Ordering.from(sstableComparator);
-
-    public static final Comparator<SSTableReader> sizeComparator = new Comparator<SSTableReader>()
->>>>>>>
     {
     }
     public final UniqueIdentifier instanceId = new UniqueIdentifier();
@@ -1525,21 +1512,9 @@
         {
             if (obsoletion == null && DatabaseDescriptor.getSStableReadRatePersistenceEnabled())
             {
-<<<<<<<
                 meterSyncThrottle.acquire();
                 SystemKeyspace.persistSSTableReadMeter(desc.ksname, desc.cfname, desc.id, readMeter);
             }
-=======
-                public void run()
-                {
-                    if (obsoletion == null)
-                    {
-                        meterSyncThrottle.acquire();
-                        SystemKeyspace.persistSSTableReadMeter(desc.ksname, desc.cfname, desc.id, readMeter);
-                    }
-                }
-            }, 1, 5, TimeUnit.MINUTES));
->>>>>>>
         }
 
         private void stopReadMeterPersistence()
--- a/src/java/org/apache/cassandra/io/sstable/format/big/BigTableReader.java
+++ b/src/java/org/apache/cassandra/io/sstable/format/big/BigTableReader.java
@@ -294,13 +294,7 @@
             assert key instanceof DecoratedKey; // EQ only make sense if the key is a valid row key
             if (!isPresentInFilter((IFilter.FilterKey) key))
             {
-<<<<<<<
-                listener.onSSTableSkipped(this, SkippingReason.BLOOM_FILTER);
-                Tracing.trace("Bloom filter allows skipping sstable {}", descriptor.id.asString());
-                bloomFilterTracker.addTrueNegative();
-=======
                 notifySkipped(SkippingReason.BLOOM_FILTER, listener, operator, updateStats);
->>>>>>>
                 return null;
             }
         }
@@ -312,50 +306,11 @@
             AbstractRowIndexEntry cachedPosition = getCachedPosition(decoratedKey, updateStats);
             if (cachedPosition != null && cachedPosition.getSSTableFormat() == descriptor.getFormat())
             {
-<<<<<<<
-                // we do not need to track "true positive" for Bloom Filter here because it has been already tracked
-                // inside getCachedPosition method
-                listener.onSSTableSelected(this, cachedPosition, SelectionReason.KEY_CACHE_HIT);
-                Tracing.trace("Key cache hit for sstable {}", descriptor.id.asString());
-                return cachedPosition;
-            }
-        }
-
-        // check the smallest and greatest keys in the sstable to see if it can't be present
-        boolean skip = false;
-        if (key.compareTo(first) < 0)
-        {
-            if (op == Operator.EQ)
-                skip = true;
-            else
-                key = first;
-
-            op = Operator.EQ;
-        }
-        else
-        {
-            int l = last.compareTo(key);
-            // l <= 0  => we may be looking past the end of the file; we then narrow our behaviour to:
-            //             1) skipping if strictly greater for GE and EQ;
-            //             2) skipping if equal and searching GT, and we aren't permitting matching past last
-            skip = l <= 0 && (l < 0 || (!permitMatchPastLast && op == Operator.GT));
-        }
-        if (skip)
-        {
-            if (op == Operator.EQ && updateCacheAndStats)
-                bloomFilterTracker.addFalsePositive();
-            listener.onSSTableSkipped(this, SkippingReason.MIN_MAX_KEYS);
-            Tracing.trace("Check against min and max keys allows skipping sstable {}", descriptor.id.asString());
-            return null;
-        }
-
-=======
                 notifySelected(SelectionReason.KEY_CACHE_HIT, listener, operator, updateStats, cachedPosition);
                 return (RowIndexEntry) cachedPosition;
             }
         }
 
->>>>>>>
         int binarySearchResult = indexSummary.binarySearch(key);
         long sampledPosition = indexSummary.getScanPositionFromBinarySearchResult(binarySearchResult);
         int sampledIndex = IndexSummary.getIndexFromBinarySearchResult(binarySearchResult);
@@ -396,14 +351,7 @@
                     exactMatch = (comparison == 0);
                     if (v < 0)
                     {
-<<<<<<<
-                        if (op == SSTableReader.Operator.EQ && updateCacheAndStats)
-                            bloomFilterTracker.addFalsePositive();
-                        listener.onSSTableSkipped(this, SkippingReason.PARTITION_INDEX_LOOKUP);
-                        Tracing.trace("Partition index lookup allows skipping sstable {}", descriptor.id.asString());
-=======
                         notifySkipped(SkippingReason.PARTITION_INDEX_LOOKUP, listener, operator, updateStats);
->>>>>>>
                         return null;
                     }
                 }
@@ -431,14 +379,7 @@
                         // store exact match for the key
                         cacheKey(decoratedKey, indexEntry);
                     }
-<<<<<<<
-                    if (op == Operator.EQ && updateCacheAndStats)
-                        bloomFilterTracker.addTruePositive();
-                    listener.onSSTableSelected(this, indexEntry, SelectionReason.INDEX_ENTRY_FOUND);
-                    Tracing.trace("Partition index with {} entries found for sstable {}", indexEntry.columnsIndexCount(), descriptor.id.asString());
-=======
                     notifySelected(SelectionReason.INDEX_ENTRY_FOUND, listener, operator, updateStats, indexEntry);
->>>>>>>
                     return indexEntry;
                 }
 
@@ -451,14 +392,7 @@
             throw new CorruptSSTableException(e, path);
         }
 
-<<<<<<<
-        if (op == SSTableReader.Operator.EQ && updateCacheAndStats)
-            bloomFilterTracker.addFalsePositive();
-        listener.onSSTableSkipped(this, SkippingReason.INDEX_ENTRY_NOT_FOUND);
-        Tracing.trace("Partition index lookup complete (bloom filter false positive) for sstable {}", descriptor.id.asString());
-=======
         notifySkipped(SkippingReason.INDEX_ENTRY_NOT_FOUND, listener, operator, updateStats);
->>>>>>>
         return null;
     }
 
--- a/src/java/org/apache/cassandra/service/CacheService.java
+++ b/src/java/org/apache/cassandra/service/CacheService.java
@@ -53,19 +53,12 @@
 import org.apache.cassandra.db.filter.DataLimits;
 import org.apache.cassandra.db.partitions.CachedBTreePartition;
 import org.apache.cassandra.db.partitions.CachedPartition;
-<<<<<<<
-import org.apache.cassandra.db.rows.*;
-import org.apache.cassandra.io.sstable.SSTableId;
-import org.apache.cassandra.io.sstable.SSTableIdFactory;
-import org.apache.cassandra.io.sstable.SequenceBasedSSTableId;
-=======
 import org.apache.cassandra.db.rows.UnfilteredRowIterator;
 import org.apache.cassandra.io.sstable.AbstractRowIndexEntry;
 import org.apache.cassandra.io.sstable.Descriptor;
 import org.apache.cassandra.io.sstable.SSTableId;
 import org.apache.cassandra.io.sstable.SSTableIdFactory;
 import org.apache.cassandra.io.sstable.format.SSTableFormat;
->>>>>>>
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.io.sstable.keycache.KeyCacheSupport;
 import org.apache.cassandra.io.util.DataInputPlus;
@@ -431,12 +424,6 @@
 
     public static class KeyCacheSerializer extends CacheSerializer<KeyCacheKey, AbstractRowIndexEntry>
     {
-<<<<<<<
-        // For column families with many SSTables the linear nature of getSSTables slowed down KeyCache loading
-        // by orders of magnitude. So we cache the sstables once and rely on cleanupAfterDeserialize to cleanup any
-        // cached state we may have accumulated during the load.
-        Map<Pair<String, String>, Map<SSTableId, SSTableReader>> cachedSSTableReaders = new ConcurrentHashMap<>();
-=======
         private final ArrayList<Pair<KeyCacheSupport<?>, SSTableFormat<?, ?>>> readers = new ArrayList<>();
         private final LinkedHashMap<Descriptor, Pair<Integer, ColumnFamilyStore>> readerOrdinals = new LinkedHashMap<>();
 
@@ -493,7 +480,6 @@
                     readers.add(Pair.create(null, format));
             }
         }
->>>>>>>
 
         public void serialize(KeyCacheKey key, DataOutputPlus out, ColumnFamilyStore cfs) throws IOException
         {
@@ -501,30 +487,10 @@
             if (entry == null)
                 return;
 
-<<<<<<<
-            TableMetadata tableMetadata = cfs.metadata();
-            tableMetadata.id.serialize(out);
-            out.writeUTF(tableMetadata.indexName().orElse(""));
-            ByteArrayUtil.writeWithLength(key.key, out);
-            if (key.desc.id instanceof SequenceBasedSSTableId)
-            {
-                out.writeInt(((SequenceBasedSSTableId) key.desc.id).generation);
-            }
-            else
-            {
-                out.writeInt(Integer.MIN_VALUE); // backwards compatibility for "int based generation only"
-                ByteBufferUtil.writeWithShortLength(key.desc.id.asBytes(), out);
-            }
-            out.writeBoolean(true);
-
-            SerializationHeader header = new SerializationHeader(false, cfs.metadata(), cfs.metadata().regularAndStaticColumns(), EncodingStats.NO_STATS);
-            key.desc.getFormat().getIndexSerializer(cfs.metadata(), key.desc.version, header).serializeForCache(entry, out);
-=======
             writeSSTable(cfs, key.desc, out);
             out.writeInt(key.key.length);
             out.write(key.key);
             entry.serializeForCache(out);
->>>>>>>
         }
 
         public Future<Pair<KeyCacheKey, AbstractRowIndexEntry>> deserialize(DataInputPlus input) throws IOException
@@ -537,35 +503,8 @@
                 throw new IOException(String.format("Corrupted key cache. Key length of %d is longer than maximum of %d",
                                                     keyLength, FBUtilities.MAX_UNSIGNED_SHORT));
             ByteBuffer key = ByteBufferUtil.read(input, keyLength);
-<<<<<<<
 
             if (skipEntry)
-=======
-            int generation = input.readInt();
-            SSTableId generationId = generation == Integer.MIN_VALUE
-                                                   ? SSTableIdFactory.instance.fromBytes(ByteBufferUtil.readWithShortLength(input))
-                                                   : new SequenceBasedSSTableId(generation); // Backwards compatibility for "int based generation sstables"
-            input.readBoolean(); // backwards compatibility for "promoted indexes" boolean
-            SSTableReader reader = null;
-            if (!skipEntry)
-            {
-                Pair<String, String> qualifiedName = Pair.create(cfs.metadata.keyspace, cfs.metadata.name);
-                Map<SSTableId, SSTableReader> generationToSSTableReader = cachedSSTableReaders.get(qualifiedName);
-                if (generationToSSTableReader == null)
-                {
-                    generationToSSTableReader = new HashMap<>(cfs.getLiveSSTables().size());
-                    for (SSTableReader ssTableReader : cfs.getSSTables(SSTableSet.CANONICAL))
-                    {
-                        generationToSSTableReader.put(ssTableReader.descriptor.id, ssTableReader);
-                    }
-
-                    cachedSSTableReaders.putIfAbsent(qualifiedName, generationToSSTableReader);
-                }
-                reader = generationToSSTableReader.get(generationId);
-            }
-
-            if (skipEntry || reader == null)
->>>>>>>
             {
                 // The sstable doesn't exist anymore, so we can't be sure of the exact version and assume its the current version. The only case where we'll be
                 // wrong is during upgrade, in which case we fail at deserialization. This is not a huge deal however since 1) this is unlikely enough that
--- a/src/java/org/apache/cassandra/service/StartupChecks.java
+++ b/src/java/org/apache/cassandra/service/StartupChecks.java
@@ -49,14 +49,7 @@
 import org.slf4j.LoggerFactory;
 
 import net.jpountz.lz4.LZ4Factory;
-<<<<<<<
 import org.apache.cassandra.config.CassandraRelevantProperties;
-=======
-import org.apache.cassandra.cql3.QueryProcessor;
-import org.apache.cassandra.cql3.UntypedResultSet;
-import org.apache.cassandra.io.sstable.UUIDBasedSSTableId;
-import org.apache.cassandra.schema.TableMetadata;
->>>>>>>
 import org.apache.cassandra.config.Config;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.config.StartupChecksOptions;
@@ -77,15 +70,10 @@
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.utils.FBUtilities;
 import org.apache.cassandra.utils.JavaUtils;
-<<<<<<<
 import org.apache.cassandra.utils.NativeLibrary;
 import org.apache.cassandra.utils.SigarLibrary;
 
 import static org.apache.cassandra.config.CassandraRelevantProperties.CASSANDRA_JMX_LOCAL_PORT;
-=======
-import org.apache.cassandra.utils.SigarLibrary;
-
->>>>>>>
 import static org.apache.cassandra.config.CassandraRelevantProperties.COM_SUN_MANAGEMENT_JMXREMOTE_PORT;
 import static org.apache.cassandra.config.CassandraRelevantProperties.JAVA_VERSION;
 import static org.apache.cassandra.config.CassandraRelevantProperties.JAVA_VM_NAME;
@@ -567,11 +555,7 @@
 
                     try
                     {
-<<<<<<<
                         Descriptor desc = Descriptor.fromFileWithComponent(file, false).left;
-=======
-                        Descriptor desc = Descriptor.fromFilename(file);
->>>>>>>
                         if (!desc.isCompatible())
                             invalid.add(file.toString());
 
@@ -655,11 +639,7 @@
                                            "UUID sstable identifiers are disabled but some sstables have been " +
                                            "created with UUID identifiers. You have to either delete those " +
                                            "sstables or enable UUID based sstable identifers in cassandra.yaml " +
-<<<<<<<
-                                           "(enable_uuid_sstable_identifiers). The list of affected sstables is: " +
-=======
                                            "(uuid_sstable_identifiers_enabled). The list of affected sstables is: " +
->>>>>>>
                                            Joiner.on(", ").join(withIllegalGenId) + ". If you decide to delete sstables, " +
                                            "and have that data replicated over other healthy nodes, those will be brought" +
                                            "back during repair");
--- a/src/java/org/apache/cassandra/utils/TimeUUID.java
+++ b/src/java/org/apache/cassandra/utils/TimeUUID.java
@@ -18,7 +18,6 @@
 
 package org.apache.cassandra.utils;
 
-<<<<<<<
 import java.io.DataInput;
 import java.io.DataOutput;
 import java.io.IOException;
@@ -65,12 +64,6 @@
 {
     public static final long serialVersionUID = 1L;
 
-=======
-import java.util.UUID;
-
-public class TimeUUID implements Comparable<TimeUUID>
-{
->>>>>>>
     // A grand day! millis at 00:00:00.000 15 Oct 1582.
     public static final long UUID_EPOCH_UNIX_MILLIS = -12219292800000L;
     protected static final long TIMESTAMP_UUID_VERSION_IN_MSB = 0x1000L;
@@ -90,11 +83,8 @@
     private static final long MIN_CLOCK_SEQ_AND_NODE = 0x8080808080808080L;
     private static final long MAX_CLOCK_SEQ_AND_NODE = 0x7f7f7f7f7f7f7f7fL;
 
-<<<<<<<
-=======
     public static final long TIMEUUID_SIZE = ObjectSizes.measureDeep(new TimeUUID(10, 10));
 
->>>>>>>
     final long uuidTimestamp, lsb;
 
     public TimeUUID(long uuidTimestamp, long lsb)
@@ -125,8 +115,6 @@
         return new TimeUUID(unixMillisToRawTimestamp(unixMillis, 0), MIN_CLOCK_SEQ_AND_NODE);
     }
 
-<<<<<<<
-=======
     /**
      * Returns the biggest possible type 1 UUID having the provided timestamp.
      *
@@ -143,7 +131,6 @@
         return fromUuid(UUID.fromString(uuidString));
     }
 
->>>>>>>
     public static TimeUUID fromUuid(UUID uuid)
     {
         return fromBytes(uuid.getMostSignificantBits(), uuid.getLeastSignificantBits());
@@ -154,8 +141,6 @@
         return new TimeUUID(msbToRawTimestamp(msb), lsb);
     }
 
-<<<<<<<
-=======
     public static TimeUUID deserialize(ByteBuffer buffer)
     {
         return fromBytes(buffer.getLong(buffer.position()), buffer.getLong(buffer.position() + 8));
@@ -197,15 +182,12 @@
         return 16;
     }
 
->>>>>>>
     public UUID asUUID()
     {
         return new UUID(rawTimestampToMsb(uuidTimestamp), lsb);
     }
 
     /**
-<<<<<<<
-=======
      * The Cassandra internal micros-resolution timestamp of the TimeUUID, as of unix epoch
      */
     public long unix(TimeUnit units)
@@ -222,7 +204,6 @@
     }
 
     /**
->>>>>>>
      * The UUID-format timestamp, i.e. 10x micros-resolution, as of UUIDGen.UUID_EPOCH_UNIX_MILLIS
      * The tenths of a microsecond are used to store a flag value.
      */
@@ -241,14 +222,11 @@
         return lsb;
     }
 
-<<<<<<<
-=======
     public static long rawTimestampToUnixMicros(long rawTimestamp)
     {
         return (rawTimestamp / 10) + UUID_EPOCH_UNIX_MILLIS * 1000;
     }
 
->>>>>>>
     public static long unixMillisToRawTimestamp(long unixMillis, long tenthsOfAMicro)
     {
         return unixMillis * 10000 - (UUID_EPOCH_UNIX_MILLIS * 10000) + tenthsOfAMicro;
@@ -263,11 +241,7 @@
     {
         assert (UUID_VERSION_BITS_IN_MSB & msb) == TIMESTAMP_UUID_VERSION_IN_MSB;
         msb &= ~TIMESTAMP_UUID_VERSION_IN_MSB;
-<<<<<<<
-        return   (msb &     0xFFFFL) << 48
-=======
         return (msb & 0xFFFFL) << 48
->>>>>>>
                | (msb & 0xFFFF0000L) << 16
                | (msb >>> 32);
     }
@@ -289,11 +263,7 @@
     @Override
     public boolean equals(Object that)
     {
-<<<<<<<
-        return    (that instanceof UUID && equals((UUID) that))
-=======
         return (that instanceof UUID && equals((UUID) that))
->>>>>>>
                || (that instanceof TimeUUID && equals((TimeUUID) that));
     }
 
@@ -313,8 +283,6 @@
         return asUUID().toString();
     }
 
-<<<<<<<
-=======
     public static String toString(TimeUUID ballot)
     {
         return ballot == null ? "null" : ballot.uuidTimestamp() + ":" + ballot;
@@ -325,7 +293,6 @@
         return ballot == null ? "null" : String.format("%s(%d:%s)", kind, ballot.uuidTimestamp(), ballot);
     }
 
->>>>>>>
     @Override
     public int compareTo(TimeUUID that)
     {
@@ -334,7 +301,6 @@
                : Long.compare(this.lsb, that.lsb);
     }
 
-<<<<<<<
     protected static abstract class AbstractSerializer<T extends TimeUUID> extends TypeSerializer<T>
     {
         public <V> void validate(V value, ValueAccessor<V> accessor) throws MarshalException
@@ -413,23 +379,10 @@
         public static UUID nextTimeAsUUID()
         {
             return atUnixMicrosWithLsbAsUUID(nextUnixMicros(), clockSeqAndNode);
-=======
-    public static class Generator
-    {
-        public static TimeUUID nextTimeUUID()
-        {
-            return TimeUUID.fromUuid(UUIDGen.getTimeUUID());
->>>>>>>
         }
 
         public static TimeUUID atUnixMillis(long unixMillis)
         {
-<<<<<<<
-            return TimeUUID.fromUuid(UUIDGen.getTimeUUID(unixMillis));
-        }
-    }
-}
-=======
             return atUnixMillis(unixMillis, 0);
         }
 
@@ -620,4 +573,3 @@
 //        c.set(Calendar.SECOND, 0);
 //        c.set(Calendar.MILLISECOND, 0);
 //        long START_EPOCH = c.getTimeInMillis();
->>>>>>>
--- a/test/distributed/org/apache/cassandra/distributed/test/FailingTruncationTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/FailingTruncationTest.java
@@ -36,8 +36,6 @@
 
 public class FailingTruncationTest extends TestBaseImpl
 {
-    private static final String BB_FAIL_HELPER_PROP = "test.bbfailhelper.enabled";
-
     @Test
     public void testFailingTruncation() throws IOException
     {
@@ -45,13 +43,8 @@
                                            .withInstanceInitializer(BBFailHelper::install)
                                            .start()))
         {
-<<<<<<<
-
-            System.setProperty(BB_FAIL_HELPER_PROP, "true");
-=======
             cluster.setUncaughtExceptionsFilter(t -> "truncateBlocking".equals(t.getMessage()));
             TEST_BBFAILHELPER_ENABLED.setBoolean(true);
->>>>>>>
             cluster.schemaChange("create table " + KEYSPACE + ".tbl (id int primary key, t int)");
             try
             {
@@ -82,13 +75,8 @@
 
         public static void truncateBlocking()
         {
-<<<<<<<
-            if (Boolean.getBoolean(BB_FAIL_HELPER_PROP))
-                throw new RuntimeException();
-=======
             if (TEST_BBFAILHELPER_ENABLED.getBoolean())
                 throw new RuntimeException("truncateBlocking");
->>>>>>>
         }
     }
 }
--- a/test/distributed/org/apache/cassandra/distributed/test/SSTableIdGenerationTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/SSTableIdGenerationTest.java
@@ -18,10 +18,6 @@
 
 package org.apache.cassandra.distributed.test;
 
-<<<<<<<
-=======
-import java.io.File;
->>>>>>>
 import java.io.IOException;
 import java.nio.file.Files;
 import java.util.Arrays;
@@ -32,24 +28,14 @@
 
 import com.google.common.collect.ImmutableSet;
 import org.apache.commons.io.FileUtils;
-<<<<<<<
-=======
 import org.junit.AfterClass;
->>>>>>>
 import org.junit.BeforeClass;
 import org.junit.Test;
 
 import org.apache.cassandra.cql3.UntypedResultSet;
 import org.apache.cassandra.db.ColumnFamilyStore;
-<<<<<<<
-import org.apache.cassandra.db.Directories;
 import org.apache.cassandra.db.SystemKeyspace;
 import org.apache.cassandra.db.compaction.AbstractCompactionStrategy;
-import org.apache.cassandra.db.compaction.DateTieredCompactionStrategy;
-=======
-import org.apache.cassandra.db.SystemKeyspace;
-import org.apache.cassandra.db.compaction.AbstractCompactionStrategy;
->>>>>>>
 import org.apache.cassandra.db.compaction.LeveledCompactionStrategy;
 import org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy;
 import org.apache.cassandra.db.compaction.TimeWindowCompactionStrategy;
@@ -62,10 +48,7 @@
 import org.apache.cassandra.io.sstable.Descriptor;
 import org.apache.cassandra.io.sstable.SequenceBasedSSTableId;
 import org.apache.cassandra.io.sstable.UUIDBasedSSTableId;
-<<<<<<<
-=======
 import org.apache.cassandra.io.util.File;
->>>>>>>
 import org.apache.cassandra.metrics.RestorableMeter;
 import org.apache.cassandra.tools.SystemExitException;
 import org.apache.cassandra.utils.TimeUUID;
@@ -87,43 +70,30 @@
 
 public class SSTableIdGenerationTest extends TestBaseImpl
 {
-<<<<<<<
-    private final static String ENABLE_UUID_FIELD_NAME = "enable_uuid_sstable_identifiers";
-=======
     private final static String ENABLE_UUID_FIELD_NAME = "uuid_sstable_identifiers_enabled";
->>>>>>>
     private final static String SNAPSHOT_TAG = "test";
 
     private int v;
 
-<<<<<<<
-=======
     private static SecurityManager originalSecurityManager;
 
->>>>>>>
     @BeforeClass
     public static void beforeClass() throws Throwable
     {
         TestBaseImpl.beforeClass();
 
-<<<<<<<
-=======
         originalSecurityManager = System.getSecurityManager();
->>>>>>>
         // we prevent system exit and convert it to exception becuase this is one of the expected test outcomes,
         // and we want to make an assertion on that
         ClusterUtils.preventSystemExit();
     }
 
-<<<<<<<
-=======
     @AfterClass
     public static void afterClass() throws Throwable
     {
         System.setSecurityManager(originalSecurityManager);
     }
 
->>>>>>>
     /**
      * This test verifies that a node with uuid disabled actually creates sstables with sequential ids and
      * both the current and legacy sstable activity tables are updated.
@@ -146,11 +116,7 @@
             restartNode(cluster, 1, true);
 
             createSSTables(cluster.get(1), KEYSPACE, "tbl", 3, 4);
-<<<<<<<
             assertSSTablesCount(cluster.get(1), 2, 2, KEYSPACE, "tbl");
-=======
-            assertSSTablesCount(cluster.get(1), 2, 3, KEYSPACE, "tbl");
->>>>>>>
             verfiySSTableActivity(cluster, false);
 
             checkRowsNumber(cluster.get(1), KEYSPACE, "tbl", 9);
@@ -184,10 +150,6 @@
     public final void testCompactionStrategiesWithMixedSSTables() throws Exception
     {
         testCompactionStrategiesWithMixedSSTables(SizeTieredCompactionStrategy.class,
-<<<<<<<
-=======
-                                                  DateTieredCompactionStrategy.class,
->>>>>>>
                                                   TimeWindowCompactionStrategy.class,
                                                   LeveledCompactionStrategy.class);
     }
@@ -226,11 +188,7 @@
                 createSSTables(cluster.get(1), KEYSPACE, tableName, 3, 4);
 
                 // expect to have a mix of sstables with sequential id and uuid
-<<<<<<<
                 assertSSTablesCount(cluster.get(1), 2, 2, KEYSPACE, tableName);
-=======
-                assertSSTablesCount(cluster.get(1), 2, 3, KEYSPACE, tableName);
->>>>>>>
 
                 // after compaction, we expect to have a single sstable with uuid
                 cluster.get(1).forceCompact(KEYSPACE, tableName);
@@ -280,11 +238,7 @@
             // create 2 sstables with overlapping partitions on node 1 (with UUID ids)
             createSSTables(cluster.get(1), KEYSPACE, "tbl", 3, 4);
 
-<<<<<<<
             assertSSTablesCount(cluster.get(1), 2, 2, KEYSPACE, "tbl");
-=======
-            assertSSTablesCount(cluster.get(1), 2, 3, KEYSPACE, "tbl");
->>>>>>>
 
             // now start node with UUID disabled and perform repair
             cluster.get(2).config().set(ENABLE_UUID_FIELD_NAME, uuidEnabledOnTargetNode);
@@ -293,24 +247,14 @@
             assertSSTablesCount(cluster.get(2), 0, 0, KEYSPACE, "tbl");
 
             // at this point we have sstables with seq and uuid on nodes and no sstables on node
-<<<<<<<
             // when we run repair, we expect streaming all 4 sstables from node 1 to node 2
-=======
-            // when we run repair, we expect streaming all 5 sstables from node 1 to node 2
->>>>>>>
 
             cluster.get(2).nodetool("repair", KEYSPACE);
 
             if (uuidEnabledOnTargetNode)
-<<<<<<<
                 assertSSTablesCount(cluster.get(2), 0, 4, KEYSPACE, "tbl");
             else
                 assertSSTablesCount(cluster.get(2), 4, 0, KEYSPACE, "tbl");
-=======
-                assertSSTablesCount(cluster.get(2), 0, 5, KEYSPACE, "tbl");
-            else
-                assertSSTablesCount(cluster.get(2), 5, 0, KEYSPACE, "tbl");
->>>>>>>
 
             waitOn(cluster.get(1).shutdown());
 
@@ -321,11 +265,7 @@
     @Test
     public void testSnapshot() throws Exception
     {
-<<<<<<<
-        File tmpDir = Files.createTempDirectory("test").toFile();
-=======
         File tmpDir = new File(Files.createTempDirectory("test"));
->>>>>>>
         Set<String> seqOnlyBackupDirs;
         Set<String> seqAndUUIDBackupDirs;
         Set<String> uuidOnlyBackupDirs;
@@ -371,7 +311,6 @@
             uuidOnlyBackupDirs = getBackupDirs(cluster.get(1), KEYSPACE, "tbl_uuid_only");
 
             // at this point, we should have sstables with backups and snapshots for all tables
-<<<<<<<
             assertSSTablesCount(cluster.get(1), 4, 0, KEYSPACE, "tbl_seq_only");
             assertSSTablesCount(cluster.get(1), 2, 2, KEYSPACE, "tbl_seq_and_uuid");
             assertSSTablesCount(cluster.get(1), 0, 4, KEYSPACE, "tbl_uuid_only");
@@ -382,18 +321,6 @@
 
             assertSnapshotSSTablesCount(cluster.get(1), 4, 0, KEYSPACE, "tbl_seq_only");
             assertSnapshotSSTablesCount(cluster.get(1), 2, 2, KEYSPACE, "tbl_seq_and_uuid");
-=======
-            assertSSTablesCount(cluster.get(1), 4, 1, KEYSPACE, "tbl_seq_only");
-            assertSSTablesCount(cluster.get(1), 2, 3, KEYSPACE, "tbl_seq_and_uuid");
-            assertSSTablesCount(cluster.get(1), 0, 4, KEYSPACE, "tbl_uuid_only");
-
-            assertBackupSSTablesCount(cluster.get(1), 4, 1, KEYSPACE, "tbl_seq_only");
-            assertBackupSSTablesCount(cluster.get(1), 2, 3, KEYSPACE, "tbl_seq_and_uuid");
-            assertBackupSSTablesCount(cluster.get(1), 0, 4, KEYSPACE, "tbl_uuid_only");
-
-            assertSnapshotSSTablesCount(cluster.get(1), 4, 1, KEYSPACE, "tbl_seq_only");
-            assertSnapshotSSTablesCount(cluster.get(1), 2, 3, KEYSPACE, "tbl_seq_and_uuid");
->>>>>>>
             assertSnapshotSSTablesCount(cluster.get(1), 0, 4, KEYSPACE, "tbl_uuid_only");
 
             checkRowsNumber(cluster.get(1), KEYSPACE, "tbl_seq_only", 9);
@@ -425,13 +352,8 @@
             {
                 File src = new File(dir);
                 File dest = relativizePath(tmpDir, src, 3);
-<<<<<<<
-                Files.createDirectories(dest.getParentFile().toPath());
-                FileUtils.moveDirectory(src, dest);
-=======
                 Files.createDirectories(dest.parent().toPath());
                 FileUtils.moveDirectory(src.toJavaIOFile(), dest.toJavaIOFile());
->>>>>>>
             }
         }
 
@@ -477,14 +399,8 @@
     {
         Set<String> snapshotDirs = instance.callOnInstance(() -> ColumnFamilyStore.getIfExists(ks, tableName)
                                                                                   .snapshot(SNAPSHOT_TAG)
-<<<<<<<
                                                                                   .getDirectories()
                                                                                   .stream()
-=======
-                                                                                  .stream()
-                                                                                  .map(s -> Directories.getSnapshotDirectory(s.descriptor, SNAPSHOT_TAG).getAbsoluteFile())
-                                                                                  .filter(dir -> !Directories.isSecondaryIndexFolder(dir))
->>>>>>>
                                                                                   .map(File::toString)
                                                                                   .collect(Collectors.toSet()));
         assertThat(snapshotDirs).isNotEmpty();
@@ -514,7 +430,6 @@
 
     private static void assertSSTablesCount(Set<Descriptor> descs, String tableName, int expectedSeqGenIds, int expectedUUIDGenIds)
     {
-<<<<<<<
         List<String> seqSSTables = descs.stream()
                                         .filter(desc -> desc.id instanceof SequenceBasedSSTableId)
                                         .map(descriptor -> descriptor.baseFile().toString())
@@ -525,10 +440,6 @@
                                          .map(descriptor -> descriptor.baseFile().toString())
                                          .sorted()
                                          .collect(Collectors.toList());
-=======
-        List<String> seqSSTables = descs.stream().filter(desc -> desc.id instanceof SequenceBasedSSTableId).map(Descriptor::baseFilename).sorted().collect(Collectors.toList());
-        List<String> uuidSSTables = descs.stream().filter(desc -> desc.id instanceof UUIDBasedSSTableId).map(Descriptor::baseFilename).sorted().collect(Collectors.toList());
->>>>>>>
         assertThat(seqSSTables).describedAs("SSTables of %s with sequence based id", tableName).hasSize(expectedSeqGenIds);
         assertThat(uuidSSTables).describedAs("SSTables of %s with UUID based id", tableName).hasSize(expectedUUIDGenIds);
     }
@@ -565,21 +476,13 @@
             assertThat(SystemKeyspace.getSSTableReadMeter("ks", "tab", seqGenId)).matches(m -> m.fifteenMinuteRate() == meter.fifteenMinuteRate()
                                                                                                && m.twoHourRate() == meter.twoHourRate());
 
-<<<<<<<
-            checkSSTableActivityRow(SSTABLE_ACTIVITY_V2, seqGenId.asBytes(), true);
-=======
             checkSSTableActivityRow(SSTABLE_ACTIVITY_V2, seqGenId.toString(), true);
->>>>>>>
             if (expectLegacyTableIsPopulated)
                 checkSSTableActivityRow(LEGACY_SSTABLE_ACTIVITY, seqGenId.generation, true);
 
             SystemKeyspace.clearSSTableReadMeter("ks", "tab", seqGenId);
 
-<<<<<<<
-            checkSSTableActivityRow(SSTABLE_ACTIVITY_V2, seqGenId.asBytes(), false);
-=======
             checkSSTableActivityRow(SSTABLE_ACTIVITY_V2, seqGenId.toString(), false);
->>>>>>>
             if (expectLegacyTableIsPopulated)
                 checkSSTableActivityRow(LEGACY_SSTABLE_ACTIVITY, seqGenId.generation, false);
 
@@ -588,19 +491,11 @@
             assertThat(SystemKeyspace.getSSTableReadMeter("ks", "tab", uuidGenId)).matches(m -> m.fifteenMinuteRate() == meter.fifteenMinuteRate()
                                                                                                 && m.twoHourRate() == meter.twoHourRate());
 
-<<<<<<<
-            checkSSTableActivityRow(SSTABLE_ACTIVITY_V2, uuidGenId.asBytes(), true);
-
-            SystemKeyspace.clearSSTableReadMeter("ks", "tab", uuidGenId);
-
-            checkSSTableActivityRow(SSTABLE_ACTIVITY_V2, uuidGenId.asBytes(), false);
-=======
             checkSSTableActivityRow(SSTABLE_ACTIVITY_V2, uuidGenId.toString(), true);
 
             SystemKeyspace.clearSSTableReadMeter("ks", "tab", uuidGenId);
 
             checkSSTableActivityRow(SSTABLE_ACTIVITY_V2, uuidGenId.toString(), false);
->>>>>>>
         });
     }
 
@@ -637,10 +532,6 @@
         SimpleQueryResult result = instance.executeInternalWithResult(format("SELECT * FROM %s.%s", ks, tableName));
         Object[][] rows = result.toObjectArrays();
         assertThat(rows).withFailMessage("Invalid results for %s.%s - should have %d rows but has %d: \n%s", ks, tableName, expectedNumber,
-<<<<<<<
                                          rows.length, result.toString()).hasNumberOfRows(expectedNumber);
-=======
-                                         rows.length, result.toString()).hasSize(expectedNumber);
->>>>>>>
     }
 }
--- a/test/unit/org/apache/cassandra/Util.java
+++ b/test/unit/org/apache/cassandra/Util.java
@@ -24,16 +24,11 @@
 import java.io.EOFException;
 import java.io.IOError;
 import java.io.IOException;
-<<<<<<<
 import java.io.InputStream;
 import java.math.BigInteger;
 import java.net.UnknownHostException;
 import java.nio.ByteBuffer;
 import java.nio.channels.FileChannel;
-=======
-import java.net.UnknownHostException;
-import java.nio.ByteBuffer;
->>>>>>>
 import java.nio.file.Path;
 import java.time.Duration;
 import java.util.ArrayList;
@@ -87,28 +82,6 @@
 import org.apache.cassandra.db.compaction.CompactionTasks;
 import org.apache.cassandra.db.compaction.OperationType;
 import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
-<<<<<<<
-=======
-import org.apache.cassandra.io.sstable.SSTableId;
-import org.apache.cassandra.io.sstable.SSTableLoader;
-import org.apache.cassandra.io.sstable.SequenceBasedSSTableId;
-import org.apache.cassandra.io.sstable.UUIDBasedSSTableId;
-import org.apache.cassandra.locator.InetAddressAndPort;
-import org.apache.cassandra.locator.Replica;
-import org.apache.cassandra.locator.ReplicaCollection;
-import org.apache.cassandra.net.MessagingService;
-import org.apache.cassandra.schema.ColumnMetadata;
-import org.apache.cassandra.schema.Schema;
-import org.apache.cassandra.schema.TableId;
-import org.apache.cassandra.schema.TableMetadata;
-import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.cql3.ColumnIdentifier;
-
-import org.apache.cassandra.db.*;
-import org.apache.cassandra.db.Directories.DataDirectory;
-import org.apache.cassandra.db.compaction.AbstractCompactionTask;
-import org.apache.cassandra.db.compaction.CompactionManager;
->>>>>>>
 import org.apache.cassandra.db.marshal.AbstractType;
 import org.apache.cassandra.db.marshal.AsciiType;
 import org.apache.cassandra.db.marshal.Int32Type;
@@ -143,8 +116,6 @@
 import org.apache.cassandra.io.sstable.SequenceBasedSSTableId;
 import org.apache.cassandra.io.sstable.UUIDBasedSSTableId;
 import org.apache.cassandra.io.sstable.format.SSTableReader;
-<<<<<<<
-=======
 import org.apache.cassandra.io.sstable.format.SSTableReaderWithFilter;
 import org.apache.cassandra.io.util.DataInputPlus;
 import org.apache.cassandra.io.util.File;
@@ -156,7 +127,6 @@
 import org.apache.cassandra.schema.Schema;
 import org.apache.cassandra.schema.TableId;
 import org.apache.cassandra.schema.TableMetadata;
->>>>>>>
 import org.apache.cassandra.schema.TableMetadataRef;
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.service.pager.PagingState;
@@ -887,11 +857,7 @@
             {
                 if (sst.name().contains("Data"))
                 {
-<<<<<<<
                     Descriptor d = Descriptor.fromFileWithComponent(sst, false).left;
-=======
-                    Descriptor d = Descriptor.fromFilename(sst.getAbsolutePath());
->>>>>>>
                     assertTrue(liveIdentifiers.contains(d.id));
                     fileCount++;
                 }
@@ -1139,8 +1105,6 @@
         Gossiper.instance.expireUpgradeFromVersion();
     }
 
-<<<<<<<
-=======
     /**
      * Sets the length of the file to given size. File will be created if not exist.
      *
@@ -1164,7 +1128,6 @@
         }
     }
 
->>>>>>>
     public static Supplier<SequenceBasedSSTableId> newSeqGen(int ... existing)
     {
         return SequenceBasedSSTableId.Builder.instance.generator(IntStream.of(existing).mapToObj(SequenceBasedSSTableId::new));
@@ -1242,7 +1205,6 @@
         Preconditions.checkArgument(components > 0);
         Preconditions.checkArgument(path.toPath().getNameCount() >= components);
         Path relative = path.toPath().subpath(path.toPath().getNameCount() - components, path.toPath().getNameCount());
-<<<<<<<
         return new File(targetBasePath.toPath().resolve(relative));
     }
 
@@ -1299,9 +1261,4 @@
     {
         return new UnsupportedOperationException("Test must be implemented for sstable format " + DatabaseDescriptor.getSelectedSSTableFormat().getClass().getName());
     }
-=======
-        return targetBasePath.toPath().resolve(relative).toFile();
-    }
-
->>>>>>>
 }
--- a/test/unit/org/apache/cassandra/db/ColumnFamilyStoreTest.java
+++ b/test/unit/org/apache/cassandra/db/ColumnFamilyStoreTest.java
@@ -28,7 +28,6 @@
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
-<<<<<<<
 import java.util.Optional;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
@@ -37,13 +36,6 @@
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.collect.Iterators;
 import org.junit.Assert;
-=======
-import java.util.Set;
-
-import com.google.common.collect.Iterators;
-import org.junit.Assert;
-import org.junit.Assume;
->>>>>>>
 import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -53,7 +45,6 @@
 import org.apache.cassandra.UpdateBuilder;
 import org.apache.cassandra.Util;
 import org.apache.cassandra.cql3.Operator;
-<<<<<<<
 import org.apache.cassandra.db.ColumnFamilyStore.FlushReason;
 import org.apache.cassandra.db.commitlog.CommitLogPosition;
 import org.apache.cassandra.db.filter.ColumnFilter;
@@ -68,24 +59,13 @@
 import org.apache.cassandra.db.rows.EncodingStats;
 import org.apache.cassandra.db.rows.Row;
 import org.apache.cassandra.db.rows.UnfilteredRowIterator;
-=======
-import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
-import org.apache.cassandra.db.lifecycle.SSTableSet;
-import org.apache.cassandra.db.partitions.FilteredPartition;
-import org.apache.cassandra.db.rows.Cell;
-import org.apache.cassandra.db.rows.EncodingStats;
-import org.apache.cassandra.db.rows.Row;
->>>>>>>
 import org.apache.cassandra.exceptions.ConfigurationException;
 import org.apache.cassandra.index.transactions.UpdateTransaction;
 import org.apache.cassandra.io.sstable.Component;
 import org.apache.cassandra.io.sstable.Descriptor;
-<<<<<<<
-=======
 import org.apache.cassandra.io.sstable.SSTableReadsListener;
 import org.apache.cassandra.io.sstable.ScrubTest;
 import org.apache.cassandra.io.sstable.format.SSTableFormat.Components;
->>>>>>>
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.io.util.File;
 import org.apache.cassandra.io.util.FileUtils;
@@ -99,7 +79,6 @@
 import org.apache.cassandra.utils.ByteBufferUtil;
 import org.apache.cassandra.utils.FBUtilities;
 import org.apache.cassandra.utils.WrappedRunnable;
-<<<<<<<
 import org.apache.cassandra.utils.concurrent.OpOrder.Barrier;
 import org.apache.cassandra.utils.concurrent.OpOrder.Group;
 
@@ -107,15 +86,6 @@
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
-=======
-import org.json.simple.JSONArray;
-import org.json.simple.JSONObject;
-import org.json.simple.parser.JSONParser;
-
-import static junit.framework.Assert.assertNotNull;
-import static org.assertj.core.api.Assertions.assertThat;
-import static org.junit.Assert.assertEquals;
->>>>>>>
 import static org.junit.Assert.assertTrue;
 
 public class ColumnFamilyStoreTest
@@ -379,15 +349,9 @@
                                              KEYSPACE2,
                                              CF_STANDARD1,
                                              liveSSTable.descriptor.id,
-<<<<<<<
-                                             liveSSTable.descriptor.formatType);
-            for (Component c : liveSSTable.getComponents())
-                assertTrue("Cannot find backed-up file:" + desc.filenameFor(c), new File(desc.filenameFor(c)).exists());
-=======
                                              liveSSTable.descriptor.version.format);
             for (Component c : liveSSTable.getComponents())
                 assertTrue("Cannot find backed-up file:" + desc.fileFor(c), desc.fileFor(c).exists());
->>>>>>>
         }
     }
 
@@ -609,19 +573,6 @@
         assertThat(manifest.getFiles()).hasSize(2);
 
         // Snapshot of the secondary index is stored in the subfolder with the same file name
-<<<<<<<
-        String baseTableFile = (String) files.get(0);
-        String indexTableFile = (String) files.get(1);
-        assertThat(baseTableFile).isNotEqualTo(indexTableFile);
-        assertThat(Directories.isSecondaryIndexFolder(new File(indexTableFile).getParentFile())).isTrue();
-
-        Set<String> originalFiles = new HashSet<>();
-        Iterables.toList(cfs.concatWithIndexes()).stream()
-                 .flatMap(c -> c.getLiveSSTables().stream().map(t -> t.descriptor.filenameFor(Component.DATA)))
-                 .forEach(originalFiles::add);
-        assertThat(originalFiles.stream().anyMatch(f -> f.endsWith(indexTableFile))).isTrue();
-        assertThat(originalFiles.stream().anyMatch(f -> f.endsWith(baseTableFile))).isTrue();
-=======
         String baseTableFile = manifest.getFiles().get(0);
         String indexTableFile = manifest.getFiles().get(1);
         assertThat(baseTableFile).isNotEqualTo(indexTableFile);
@@ -685,7 +636,6 @@
         createSnapshotAndDelete(KEYSPACE1, CF_STANDARD1, true);
         createSnapshotAndDelete(KEYSPACE1, CF_STANDARD2, true);
         createSnapshotAndDelete(KEYSPACE2, CF_STANDARD1, true);
->>>>>>>
     }
 
     @Test
--- a/test/unit/org/apache/cassandra/db/DirectoriesTest.java
+++ b/test/unit/org/apache/cassandra/db/DirectoriesTest.java
@@ -39,11 +39,8 @@
 import java.util.concurrent.Callable;
 import java.util.concurrent.Executors;
 import java.util.concurrent.Future;
-<<<<<<<
-=======
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.function.Function;
->>>>>>>
 import java.util.function.Supplier;
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
@@ -69,18 +66,6 @@
 import ch.qos.logback.core.read.ListAppender;
 
 import org.apache.cassandra.Util;
-<<<<<<<
-=======
-import org.apache.cassandra.cql3.ColumnIdentifier;
-import org.apache.cassandra.io.sstable.SSTableId;
-import org.apache.cassandra.io.sstable.SequenceBasedSSTableId;
-import org.apache.cassandra.io.sstable.UUIDBasedSSTableId;
-import org.apache.cassandra.schema.Indexes;
-import org.apache.cassandra.schema.MockSchema;
-import org.apache.cassandra.schema.SchemaConstants;
-import org.apache.cassandra.schema.SchemaKeyspaceTables;
-import org.apache.cassandra.schema.TableMetadata;
->>>>>>>
 import org.apache.cassandra.auth.AuthKeyspace;
 import org.apache.cassandra.config.Config.DiskFailurePolicy;
 import org.apache.cassandra.config.DatabaseDescriptor;
@@ -113,11 +98,8 @@
 import org.apache.cassandra.utils.JVMStabilityInspector;
 
 import static org.apache.cassandra.schema.MockSchema.sstableId;
-<<<<<<<
-=======
 import static org.apache.cassandra.utils.Clock.Global.nanoTime;
 import static org.apache.cassandra.utils.FBUtilities.now;
->>>>>>>
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
@@ -147,18 +129,6 @@
     private int myDiyId = -1;
     private static Logger logger;
     private ListAppender<ILoggingEvent> listAppender;
-    @Parameterized.Parameter(0)
-    public SSTableId.Builder<? extends SSTableId> idBuilder;
-
-    @Parameterized.Parameter(1)
-    public Supplier<? extends SSTableId> idGenerator;
-
-    @Parameterized.Parameters
-    public static Collection<Object[]> idBuilders()
-    {
-        return Arrays.asList(new Object[]{ SequenceBasedSSTableId.Builder.instance, Util.newSeqGen() },
-                             new Object[]{ UUIDBasedSSTableId.Builder.instance, Util.newUUIDGen() });
-    }
 
     @Parameterized.Parameter
     public SSTableId.Builder<? extends SSTableId> idBuilder;
@@ -221,21 +191,7 @@
         return new DataDirectory[] { new DataDirectory(location) };
     }
 
-<<<<<<<
-    private static DataDirectory[] toDataDirectories(File[] locations)
-    {
-        DataDirectory[] dirs = new DataDirectory[locations.length];
-        for (int i=0; i<locations.length; i++)
-        {
-            dirs[i] = new DataDirectory(locations[i]);
-        }
-        return dirs;
-    }
-
-    private void createTestFiles() throws IOException
-=======
     private void createTestFiles()
->>>>>>>
     {
         for (TableMetadata cfm : CFM)
         {
@@ -257,34 +213,6 @@
         }
     }
 
-<<<<<<<
-    private void createFakeSSTable(File dir, String cf, int gen, List<File> addTo) throws IOException
-    {
-        Descriptor desc = new Descriptor(dir, KS, cf, sstableId(gen), SSTableFormat.Type.BIG);
-        for (Component c : new Component[]{ Component.DATA, Component.PRIMARY_INDEX, Component.FILTER })
-        {
-            File f = desc.fileFor(c);
-            assert f.createNewFile();
-            addTo.add(f);
-        }
-    }
-
-    private List<File> createFakeSSTable(File dir, String cf, int gen) throws IOException
-    {
-        Descriptor desc = new Descriptor(dir, KS, cf, sstableId(gen), SSTableFormat.Type.BIG);
-        return createFakeSSTable(desc);
-    }
-
-    private List<File> createFakeSSTable(Descriptor desc) throws IOException
-    {
-        List<File> components = new ArrayList<>(3);
-        for (Component c : new Component[]{ Component.DATA, Component.PRIMARY_INDEX, Component.FILTER })
-        {
-            File f = new File(desc.filenameFor(c));
-            assert f.createNewFile();
-            components.add(f);
-        }
-=======
     static class FakeSnapshot {
         final TableMetadata table;
         final String tag;
@@ -357,7 +285,6 @@
             f.createFileIfNotExists();
             components.add(f);
         }
->>>>>>>
         return components;
     }
 
@@ -387,7 +314,6 @@
             Directories directories = new Directories(cfm, toDataDirectories(tempDataDir));
             assertEquals(cfDir(cfm), directories.getDirectoryForNewSSTables());
 
-<<<<<<<
             Descriptor desc = new Descriptor(cfDir(cfm), KS, cfm.name, sstableId(1), DatabaseDescriptor.getSelectedSSTableFormat());
             File snapshotDir = new File(cfDir(cfm), File.pathSeparator() + Directories.SNAPSHOT_SUBDIR + File.pathSeparator() + LEGACY_SNAPSHOT_NAME);
             assertEquals(snapshotDir.toCanonical(), Directories.getSnapshotDirectory(desc, LEGACY_SNAPSHOT_NAME));
@@ -482,17 +408,6 @@
             SnapshotManifest loadedManifest = Directories.maybeLoadManifest(KS, cfm.name, tag, dirs);
 
             assertEquals(manifest, loadedManifest);
-=======
-            Descriptor desc = new Descriptor(cfDir(cfm), KS, cfm.name, sstableId(1), SSTableFormat.Type.BIG);
-            File snapshotDir = new File(cfDir(cfm),  File.separator + Directories.SNAPSHOT_SUBDIR + File.separator + "42");
-            assertEquals(snapshotDir.getCanonicalFile(), Directories.getSnapshotDirectory(desc, "42"));
-
-            File backupsDir = new File(cfDir(cfm), File.separator + Directories.BACKUPS_SUBDIR);
-            assertEquals(backupsDir.getCanonicalFile(), Directories.getBackupsDirectory(desc));
-
-            Supplier<? extends SSTableId> uidGen = directories.getUIDGenerator(idBuilder);
-            assertThat(Stream.generate(uidGen).limit(100).filter(MockSchema.sstableIds::containsValue).collect(Collectors.toList())).isEmpty();
->>>>>>>
         }
     }
 
@@ -522,13 +437,8 @@
         {
             assertEquals(cfDir(INDEX_CFM), dir);
         }
-<<<<<<<
         Descriptor parentDesc = new Descriptor(parentDirectories.getDirectoryForNewSSTables(), KS, PARENT_CFM.name, sstableId(0), DatabaseDescriptor.getSelectedSSTableFormat());
         Descriptor indexDesc = new Descriptor(indexDirectories.getDirectoryForNewSSTables(), KS, INDEX_CFM.name, sstableId(0), DatabaseDescriptor.getSelectedSSTableFormat());
-=======
-        Descriptor parentDesc = new Descriptor(parentDirectories.getDirectoryForNewSSTables(), KS, PARENT_CFM.name, sstableId(0), SSTableFormat.Type.BIG);
-        Descriptor indexDesc = new Descriptor(indexDirectories.getDirectoryForNewSSTables(), KS, INDEX_CFM.name, sstableId(0), SSTableFormat.Type.BIG);
->>>>>>>
 
         // snapshot dir should be created under its parent's
         File parentSnapshotDirectory = Directories.getSnapshotDirectory(parentDesc, "test");
@@ -541,17 +451,10 @@
         assertTrue(indexDirectories.snapshotExists("test"));
 
         // check true snapshot size
-<<<<<<<
         Descriptor parentSnapshot = new Descriptor(parentSnapshotDirectory, KS, PARENT_CFM.name, sstableId(0), DatabaseDescriptor.getSelectedSSTableFormat());
         createFile(parentSnapshot.fileFor(Components.DATA), 30);
         Descriptor indexSnapshot = new Descriptor(indexSnapshotDirectory, KS, INDEX_CFM.name, sstableId(0), DatabaseDescriptor.getSelectedSSTableFormat());
         createFile(indexSnapshot.fileFor(Components.DATA), 40);
-=======
-        Descriptor parentSnapshot = new Descriptor(parentSnapshotDirectory, KS, PARENT_CFM.name, sstableId(0), SSTableFormat.Type.BIG);
-        createFile(parentSnapshot.filenameFor(Component.DATA), 30);
-        Descriptor indexSnapshot = new Descriptor(indexSnapshotDirectory, KS, INDEX_CFM.name, sstableId(0), SSTableFormat.Type.BIG);
-        createFile(indexSnapshot.filenameFor(Component.DATA), 40);
->>>>>>>
 
         assertEquals(30, parentDirectories.trueSnapshotsSize());
         assertEquals(40, indexDirectories.trueSnapshotsSize());
@@ -678,10 +581,6 @@
 
             File file = new File(first.location, new File(KS, "bad").path());
             assertTrue(DisallowedDirectories.isUnwritable(file));
-<<<<<<<
-=======
-
->>>>>>>
         }
         finally 
         {
@@ -696,20 +595,11 @@
         {
             final Directories directories = new Directories(cfm, toDataDirectories(tempDataDir));
             assertEquals(cfDir(cfm), directories.getDirectoryForNewSSTables());
-<<<<<<<
-            final String n = Long.toString(System.nanoTime());
-            Callable<File> directoryGetter = new Callable<File>() {
-                public File call() throws Exception {
-                    Descriptor desc = new Descriptor(cfDir(cfm), KS, cfm.name, sstableId(1), SSTableFormat.Type.BIG);
-                    return Directories.getSnapshotDirectory(desc, n);
-                }
-=======
             final String n = Long.toString(nanoTime());
             Callable<File> directoryGetter = () ->
             {
                 Descriptor desc = new Descriptor(cfDir(cfm), KS, cfm.name, sstableId(1), DatabaseDescriptor.getSelectedSSTableFormat());
                 return Directories.getSnapshotDirectory(desc, n);
->>>>>>>
             };
             List<Future<File>> invoked = Executors.newFixedThreadPool(2).invokeAll(Arrays.asList(directoryGetter, directoryGetter));
             for(Future<File> fut:invoked) {
--- a/test/unit/org/apache/cassandra/db/SerializationHeaderTest.java
+++ b/test/unit/org/apache/cassandra/db/SerializationHeaderTest.java
@@ -26,11 +26,8 @@
 import java.util.function.Supplier;
 
 import com.google.common.io.Files;
-<<<<<<<
-=======
 import org.junit.Assert;
 import org.junit.Test;
->>>>>>>
 
 import org.apache.cassandra.Util;
 import org.apache.cassandra.config.DatabaseDescriptor;
@@ -56,19 +53,6 @@
 import org.apache.cassandra.schema.ColumnMetadata;
 import org.apache.cassandra.schema.TableMetadata;
 import org.apache.cassandra.schema.TableMetadataRef;
-<<<<<<<
-=======
-import org.junit.Assert;
-import org.junit.Test;
-
-import java.io.File;
-import java.nio.ByteBuffer;
-import java.util.Collections;
-import java.util.concurrent.Callable;
-import java.util.function.BiFunction;
-import java.util.function.Function;
-import java.util.function.Supplier;
->>>>>>>
 
 public class SerializationHeaderTest
 {
@@ -100,7 +84,6 @@
         schemaWithStatic = schemaWithStatic.unbuild().recordColumnDrop(columnRegular, 0L).build();
         schemaWithRegular = schemaWithRegular.unbuild().recordColumnDrop(columnStatic, 0L).build();
 
-<<<<<<<
         SSTableReader readerWithStatic = null;
         SSTableReader readerWithRegular = null;
         Supplier<SequenceBasedSSTableId> id = Util.newSeqGen();
@@ -109,14 +92,6 @@
         {
             BiFunction<TableMetadata, Function<ByteBuffer, Clustering<?>>, Callable<Descriptor>> writer = (schema, clusteringFunction) -> () -> {
                 Descriptor descriptor = new Descriptor(format.getLatestVersion(), dir, schema.keyspace, schema.name, id.get());
-=======
-        Supplier<SequenceBasedSSTableId> id = Util.newSeqGen();
-        File dir = Files.createTempDir();
-        try
-        {
-            BiFunction<TableMetadata, Function<ByteBuffer, Clustering<?>>, Callable<Descriptor>> writer = (schema, clusteringFunction) -> () -> {
-                Descriptor descriptor = new Descriptor(BigFormat.latestVersion, dir, schema.keyspace, schema.name, id.get(), SSTableFormat.Type.BIG);
->>>>>>>
 
                 SerializationHeader header = SerializationHeader.makeWithoutStats(schema);
                 try (LifecycleTransaction txn = LifecycleTransaction.offline(OperationType.WRITE);
--- a/test/unit/org/apache/cassandra/db/SystemKeyspaceMigrator41Test.java
+++ b/test/unit/org/apache/cassandra/db/SystemKeyspaceMigrator41Test.java
@@ -43,11 +43,7 @@
 import org.apache.cassandra.schema.SchemaConstants;
 import org.apache.cassandra.utils.CassandraVersion;
 import org.apache.cassandra.utils.FBUtilities;
-<<<<<<<
 import org.apache.cassandra.utils.TimeUUID;
-=======
-import org.apache.cassandra.utils.UUIDGen;
->>>>>>>
 
 import static org.apache.cassandra.utils.Clock.Global.currentTimeMillis;
 import static org.apache.cassandra.utils.FBUtilities.now;
@@ -73,13 +69,8 @@
                                       + "tokens) "
                                       + " values ( ?, ?, ? , ? , ?, ?, ?, ?, ?)",
                                       legacyTab);
-<<<<<<<
         UUID hostId = UUID.randomUUID();
         UUID schemaVersion = UUID.randomUUID();
-=======
-        UUID hostId = UUIDGen.getTimeUUID();
-        UUID schemaVersion = UUIDGen.getTimeUUID();
->>>>>>>
         execute(insert,
                 InetAddress.getByName("127.0.0.1"),
                 "dcFoo",
@@ -89,11 +80,7 @@
                 InetAddress.getByName("127.0.0.3"),
                 schemaVersion,
                 ImmutableSet.of("foobar"));
-<<<<<<<
-        SystemKeyspaceMigrator40.migratePeers();
-=======
         SystemKeyspaceMigrator41.migratePeers();
->>>>>>>
 
         int rowCount = 0;
         for (UntypedResultSet.Row row : execute(String.format("SELECT * FROM %s", tab)))
@@ -119,13 +106,8 @@
         execute(String.format("TRUNCATE %s", tab));
 
         execute(String.format("INSERT INTO %s (peer) VALUES (?)", legacyTab),
-<<<<<<<
                               InetAddress.getByName("127.0.0.1"));
         SystemKeyspaceMigrator41.migratePeers();
-=======
-                InetAddress.getByName("127.0.0.1"));
-        SystemKeyspaceMigrator40.migratePeers();
->>>>>>>
 
         rowCount = 0;
         for (UntypedResultSet.Row row : execute(String.format("SELECT * FROM %s", tab)))
@@ -145,19 +127,11 @@
                                       + "hints_dropped) "
                                       + " values ( ?, ? )",
                                       legacyTab);
-<<<<<<<
         TimeUUID uuid = nextTimeUUID();
         execute(insert,
                 InetAddress.getByName("127.0.0.1"),
                 ImmutableMap.of(uuid, 42));
         SystemKeyspaceMigrator41.migratePeerEvents();
-=======
-        UUID uuid = UUIDGen.getTimeUUID();
-        execute(insert,
-                InetAddress.getByName("127.0.0.1"),
-                ImmutableMap.of(uuid, 42));
-        SystemKeyspaceMigrator40.migratePeerEvents();
->>>>>>>
 
         int rowCount = 0;
         for (UntypedResultSet.Row row : execute(String.format("SELECT * FROM %s", tab)))
@@ -175,11 +149,7 @@
 
         execute(String.format("INSERT INTO %s (peer) VALUES (?)", legacyTab),
                 InetAddress.getByName("127.0.0.1"));
-<<<<<<<
-        SystemKeyspaceMigrator40.migratePeerEvents();
-=======
         SystemKeyspaceMigrator41.migratePeerEvents();
->>>>>>>
 
         rowCount = 0;
         for (UntypedResultSet.Row row : execute(String.format("SELECT * FROM %s", tab)))
@@ -205,13 +175,8 @@
                 "foo",
                 InetAddress.getByName("127.0.0.1"),
                 "bar",
-<<<<<<<
                 ImmutableSet.of(ByteBuffer.wrap(new byte[] { 42 })));
         SystemKeyspaceMigrator41.migrateTransferredRanges();
-=======
-                ImmutableSet.of(ByteBuffer.wrap(new byte[]{ 42 })));
-        SystemKeyspaceMigrator40.migrateTransferredRanges();
->>>>>>>
 
         int rowCount = 0;
         for (UntypedResultSet.Row row : execute(String.format("SELECT * FROM %s", tab)))
@@ -233,11 +198,7 @@
                 "foo",
                 InetAddress.getByName("127.0.0.1"),
                 "bar");
-<<<<<<<
-        SystemKeyspaceMigrator40.migrateTransferredRanges();
-=======
         SystemKeyspaceMigrator41.migrateTransferredRanges();
->>>>>>>
 
         rowCount = 0;
         for (UntypedResultSet.Row row : execute(String.format("SELECT * FROM %s", tab)))
@@ -261,11 +222,7 @@
         execute(insert,
                 "foo",
                 ImmutableSet.of(SystemKeyspace.rangeToBytes(testRange)));
-<<<<<<<
-        SystemKeyspaceMigrator40.migrateAvailableRanges();
-=======
         SystemKeyspaceMigrator41.migrateAvailableRanges();
->>>>>>>
 
         int rowCount = 0;
         for (UntypedResultSet.Row row : execute(String.format("SELECT * FROM %s", tab)))
@@ -286,19 +243,11 @@
 
         String insert = String.format("INSERT INTO %s (%s) VALUES (%s)",
                                       legacyTab,
-<<<<<<<
                                       StringUtils.join(new String[] {"keyspace_name",
                                                        "columnfamily_name",
                                                        "generation",
                                                        "rate_120m",
                                                        "rate_15m"}, ", "),
-=======
-                                      StringUtils.join(new String[]{ "keyspace_name",
-                                                                     "columnfamily_name",
-                                                                     "generation",
-                                                                     "rate_120m",
-                                                                     "rate_15m" }, ", "),
->>>>>>>
                                       StringUtils.repeat("?", ", ", 5));
 
         execute(insert, "ks", "tab", 5, 123.234d, 345.456d);
@@ -306,11 +255,7 @@
         ColumnFamilyStore cf = getColumnFamilyStore(SchemaConstants.SYSTEM_KEYSPACE_NAME, SystemKeyspace.SSTABLE_ACTIVITY_V2);
         cf.truncateBlocking();
         cf.clearUnsafe();
-<<<<<<<
-        SystemKeyspaceMigrator40.migrateSSTableActivity();
-=======
         SystemKeyspaceMigrator41.migrateSSTableActivity();
->>>>>>>
 
         int rowCount = 0;
         for (UntypedResultSet.Row row : execute(String.format("SELECT * FROM %s", tab)))
@@ -318,18 +263,12 @@
             rowCount++;
             assertEquals("ks", row.getString("keyspace_name"));
             assertEquals("tab", row.getString("table_name"));
-<<<<<<<
-            assertEquals(new SequenceBasedSSTableId(5).asBytes(), row.getBytes("id"));
-=======
             assertEquals(new SequenceBasedSSTableId(5).toString(), row.getString("id"));
->>>>>>>
             assertEquals(123.234d, row.getDouble("rate_120m"), 0.001d);
             assertEquals(345.456d, row.getDouble("rate_15m"), 0.001d);
         }
         assertEquals(1, rowCount);
     }
-<<<<<<<
-=======
     
     @Test
     public void testMigrateCompactionHistory() throws Throwable
@@ -381,5 +320,4 @@
 
         assertEquals(1, execute(String.format("SELECT * FROM %s", table)).size());
     }
->>>>>>>
 }
--- a/test/unit/org/apache/cassandra/db/compaction/CompactionsTest.java
+++ b/test/unit/org/apache/cassandra/db/compaction/CompactionsTest.java
@@ -65,10 +65,7 @@
 import org.apache.cassandra.io.sstable.ISSTableScanner;
 import org.apache.cassandra.io.sstable.SSTableId;
 import org.apache.cassandra.io.sstable.SSTableIdFactory;
-<<<<<<<
-=======
 import org.apache.cassandra.io.sstable.format.SSTableFormat.Components;
->>>>>>>
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.io.sstable.metadata.StatsMetadata;
 import org.apache.cassandra.schema.CompactionParams;
@@ -284,11 +281,7 @@
         SSTableReader sstable = sstables.iterator().next();
 
         SSTableId prevGeneration = sstable.descriptor.id;
-<<<<<<<
-        String file = new File(sstable.descriptor.filenameFor(Component.DATA)).getAbsolutePath();
-=======
         String file = sstable.descriptor.fileFor(Components.DATA).absolutePath();
->>>>>>>
         // submit user defined compaction on flushed sstable
         CompactionManager.instance.forceUserDefinedCompaction(file);
         // wait until user defined compaction finishes
--- a/test/unit/org/apache/cassandra/db/compaction/LeveledGenerationsTest.java
+++ b/test/unit/org/apache/cassandra/db/compaction/LeveledGenerationsTest.java
@@ -194,10 +194,6 @@
 
     private void print(SSTableReader sstable)
     {
-<<<<<<<
-        System.out.println(String.format("%d %s %s %d", sstable.descriptor.id, sstable.first, sstable.last, sstable.getSSTableLevel()));
-=======
         System.out.println(String.format("%d %s %s %d", sstable.descriptor.id, sstable.getFirst(), sstable.getLast(), sstable.getSSTableLevel()));
->>>>>>>
     }
 }
--- a/test/unit/org/apache/cassandra/db/lifecycle/LogTransactionTest.java
+++ b/test/unit/org/apache/cassandra/db/lifecycle/LogTransactionTest.java
@@ -50,10 +50,6 @@
 import org.apache.cassandra.io.sstable.Component;
 import org.apache.cassandra.io.sstable.Descriptor;
 import org.apache.cassandra.io.sstable.SequenceBasedSSTableId;
-<<<<<<<
-=======
-import org.apache.cassandra.io.sstable.format.SSTableFormat;
->>>>>>>
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.io.sstable.format.big.BigFormat;
 import org.apache.cassandra.io.sstable.format.big.BigFormat.Components;
@@ -1267,14 +1263,8 @@
 
     private static SSTableReader sstable(File dataFolder, ColumnFamilyStore cfs, int generation, int size) throws IOException
     {
-<<<<<<<
         Descriptor descriptor = new Descriptor(dataFolder, cfs.getKeyspaceName(), cfs.getTableName(), new SequenceBasedSSTableId(generation), DatabaseDescriptor.getSelectedSSTableFormat());
         if (BigFormat.isSelected())
-=======
-        Descriptor descriptor = new Descriptor(dataFolder, cfs.keyspace.getName(), cfs.getTableName(), new SequenceBasedSSTableId(generation), SSTableFormat.Type.BIG);
-        Set<Component> components = ImmutableSet.of(Component.DATA, Component.PRIMARY_INDEX, Component.FILTER, Component.TOC);
-        for (Component component : components)
->>>>>>>
         {
             Set<Component> components = ImmutableSet.of(Components.DATA, Components.PRIMARY_INDEX, Components.FILTER, Components.TOC);
             for (Component component : components)
--- a/test/unit/org/apache/cassandra/index/sasi/SASIIndexTest.java
+++ b/test/unit/org/apache/cassandra/index/sasi/SASIIndexTest.java
@@ -226,11 +226,7 @@
                                                             sstable.getKeyspaceName(),
                                                             sstable.getColumnFamilyName(),
                                                             sstable.descriptor.id,
-<<<<<<<
-                                                            sstable.descriptor.formatType);
-=======
                                                             sstable.descriptor.version.format);
->>>>>>>
 
                 Set<Component> components = snapshotSSTables.get(snapshotSSTable);
 
--- a/test/unit/org/apache/cassandra/io/sstable/DescriptorTest.java
+++ b/test/unit/org/apache/cassandra/io/sstable/DescriptorTest.java
@@ -87,21 +87,12 @@
 
     private void testFromFilenameFor(File dir)
     {
-<<<<<<<
         checkFromFilename(new Descriptor(dir, ksname, cfname, new SequenceBasedSSTableId(1), DatabaseDescriptor.getSelectedSSTableFormat()));
 
         // secondary index
         String idxName = "myidx";
         File idxDir = new File(dir.absolutePath() + File.pathSeparator() + Directories.SECONDARY_INDEX_NAME_SEPARATOR + idxName);
         checkFromFilename(new Descriptor(idxDir, ksname, cfname + Directories.SECONDARY_INDEX_NAME_SEPARATOR + idxName, new SequenceBasedSSTableId(4), DatabaseDescriptor.getSelectedSSTableFormat()));
-=======
-        checkFromFilename(new Descriptor(dir, ksname, cfname, new SequenceBasedSSTableId(1), SSTableFormat.Type.BIG));
-
-        // secondary index
-        String idxName = "myidx";
-        File idxDir = new File(dir.getAbsolutePath() + File.separator + Directories.SECONDARY_INDEX_NAME_SEPARATOR + idxName);
-        checkFromFilename(new Descriptor(idxDir, ksname, cfname + Directories.SECONDARY_INDEX_NAME_SEPARATOR + idxName, new SequenceBasedSSTableId(4), SSTableFormat.Type.BIG));
->>>>>>>
     }
 
     private void checkFromFilename(Descriptor original)
@@ -116,11 +107,7 @@
         assertEquals(original.cfname, desc.cfname);
         assertEquals(original.version, desc.version);
         assertEquals(original.id, desc.id);
-<<<<<<<
-        assertEquals(Component.DATA, pair.right);
-=======
         assertEquals(Components.DATA, pair.right);
->>>>>>>
     }
 
     @Test
@@ -128,13 +115,8 @@
     {
         // Descriptor should be equal when parent directory points to the same directory
         File dir = new File(".");
-<<<<<<<
         Descriptor desc1 = new Descriptor(dir, "ks", "cf", new SequenceBasedSSTableId(1), DatabaseDescriptor.getSelectedSSTableFormat());
         Descriptor desc2 = new Descriptor(dir.toAbsolute(), "ks", "cf", new SequenceBasedSSTableId(1), DatabaseDescriptor.getSelectedSSTableFormat());
-=======
-        Descriptor desc1 = new Descriptor(dir, "ks", "cf", new SequenceBasedSSTableId(1), SSTableFormat.Type.BIG);
-        Descriptor desc2 = new Descriptor(dir.getAbsoluteFile(), "ks", "cf", new SequenceBasedSSTableId(1), SSTableFormat.Type.BIG);
->>>>>>>
         assertEquals(desc1, desc2);
         assertEquals(desc1.hashCode(), desc2.hashCode());
     }
--- a/test/unit/org/apache/cassandra/io/sstable/LegacySSTableTest.java
+++ b/test/unit/org/apache/cassandra/io/sstable/LegacySSTableTest.java
@@ -19,8 +19,6 @@
 
 
 import java.io.IOException;
-import java.nio.file.Files;
-import java.nio.file.Path;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
@@ -55,6 +53,7 @@
 import org.apache.cassandra.dht.Range;
 import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.exceptions.ConfigurationException;
+import org.apache.cassandra.io.sstable.format.SSTableFormat;
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.io.sstable.format.Version;
 import org.apache.cassandra.io.sstable.keycache.KeyCacheSupport;
@@ -156,14 +155,9 @@
      */
     protected Descriptor getDescriptor(String legacyVersion, String table) throws IOException
     {
-<<<<<<<
         File[] files = getTableDir(legacyVersion, table).list();
         Preconditions.checkArgument(files.length > 0, "No files for version=%s and table=%s", legacyVersion, table);
         return Descriptor.fromFileWithComponent(files[0]).left;
-=======
-        Path file = Files.list(getTableDir(legacyVersion, table).toPath()).findFirst().orElseThrow(() -> new RuntimeException(String.format("No files for version=%s and table=%s", legacyVersion, table)));
-        return Descriptor.fromFilename(file.toFile());
->>>>>>>
     }
 
     @Test
--- a/test/unit/org/apache/cassandra/io/sstable/SSTableIdTest.java
+++ b/test/unit/org/apache/cassandra/io/sstable/SSTableIdTest.java
@@ -37,18 +37,11 @@
 import com.google.common.primitives.UnsignedBytes;
 import org.junit.Test;
 
-<<<<<<<
-import org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor;
-import org.apache.cassandra.utils.TimeUUID;
-import org.awaitility.Awaitility;
-
-=======
 import org.apache.cassandra.concurrent.ExecutorPlus;
 import org.apache.cassandra.utils.TimeUUID;
 import org.awaitility.Awaitility;
 
 import static org.apache.cassandra.concurrent.ExecutorFactory.Global.executorFactory;
->>>>>>>
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.quicktheories.QuickTheory.qt;
 import static org.quicktheories.generators.SourceDSL.longs;
@@ -80,11 +73,7 @@
         List<SSTableId> deserIds = serIds.stream().map(builder::fromBytes).collect(Collectors.toList());
         assertThat(deserIds).containsExactlyElementsOf(ids);
 
-<<<<<<<
-        List<String> stringifiedIds = ids.stream().map(SSTableId::asString).collect(Collectors.toList());
-=======
         List<String> stringifiedIds = ids.stream().map(SSTableId::toString).collect(Collectors.toList());
->>>>>>>
         if (!(builder instanceof SequenceBasedSSTableId.Builder))
         {
             // the legacy string representation is not sortable
@@ -122,11 +111,7 @@
 
     private void testStringSerialization(UUIDBasedSSTableId id)
     {
-<<<<<<<
-        String s = id.asString();
-=======
         String s = id.toString();
->>>>>>>
         assertThat(s).hasSize(UUIDBasedSSTableId.STRING_LEN);
         assertThat(s).matches(Pattern.compile("[0-9a-z]{4}_[0-9a-z]{4}_[0-9a-z]{18}"));
         assertThat(UUIDBasedSSTableId.Builder.instance.isUniqueIdentifier(s)).isTrue();
@@ -142,11 +127,7 @@
         for (int i = 0; i < 100; i++)
         {
             ids.set(i + 100, new SequenceBasedSSTableId(ThreadLocalRandom.current().nextInt(1000000)));
-<<<<<<<
-            ids.set(i, new UUIDBasedSSTableId(TimeUUID.Generator.atUnixMillis(ThreadLocalRandom.current().nextLong(10000))));
-=======
             ids.set(i, new UUIDBasedSSTableId(TimeUUID.Generator.atUnixMillis(ThreadLocalRandom.current().nextLong(10000), 0)));
->>>>>>>
         }
 
         List<SSTableId> shuffledIds = new ArrayList<>(ids);
@@ -171,11 +152,7 @@
         final int NUM_THREADS = 10, IDS_PER_THREAD = 10;
         Set<SSTableId> ids = new CopyOnWriteArraySet<>();
         Supplier<T> generator = builder.generator(Stream.empty());
-<<<<<<<
-        DebuggableThreadPoolExecutor service = DebuggableThreadPoolExecutor.createWithFixedPoolSize("test", NUM_THREADS);
-=======
         ExecutorPlus service = executorFactory().pooled("test", NUM_THREADS);
->>>>>>>
         CyclicBarrier barrier = new CyclicBarrier(NUM_THREADS);
         for (int i = 0; i < NUM_THREADS; i++)
         {
--- a/test/unit/org/apache/cassandra/io/sstable/SSTableReaderTest.java
+++ b/test/unit/org/apache/cassandra/io/sstable/SSTableReaderTest.java
@@ -20,11 +20,6 @@
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.nio.file.Files;
-<<<<<<<
-import java.nio.file.Path;
-import java.util.*;
-import java.util.concurrent.*;
-=======
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
@@ -35,7 +30,6 @@
 import java.util.concurrent.ScheduledThreadPoolExecutor;
 import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
->>>>>>>
 import java.util.stream.Stream;
 
 import com.google.common.collect.Sets;
@@ -1100,11 +1094,7 @@
         Keyspace keyspace = Keyspace.open(KEYSPACE1);
         ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF_STANDARD);
         SSTableReader sstable = getNewSSTable(cfs);
-<<<<<<<
         Descriptor notLiveDesc = new Descriptor(new File("/testdir"), "", "", SSTableIdFactory.instance.defaultBuilder().generator(Stream.empty()).get());
-=======
-        Descriptor notLiveDesc = new Descriptor(new File("/tmp"), "", "", SSTableIdFactory.instance.defaultBuilder().generator(Stream.empty()).get());
->>>>>>>
         SSTableReader.moveAndOpenSSTable(cfs, sstable.descriptor, notLiveDesc, sstable.components, false);
     }
 
@@ -1114,11 +1104,7 @@
         Keyspace keyspace = Keyspace.open(KEYSPACE1);
         ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF_STANDARD);
         SSTableReader sstable = getNewSSTable(cfs);
-<<<<<<<
         Descriptor notLiveDesc = new Descriptor(new File("/testdir"), "", "", SSTableIdFactory.instance.defaultBuilder().generator(Stream.empty()).get());
-=======
-        Descriptor notLiveDesc = new Descriptor(new File("/tmp"), "", "", SSTableIdFactory.instance.defaultBuilder().generator(Stream.empty()).get());
->>>>>>>
         SSTableReader.moveAndOpenSSTable(cfs, notLiveDesc, sstable.descriptor, sstable.components, false);
     }
 
@@ -1147,11 +1133,7 @@
         {
             File f = notLiveDesc.fileFor(c);
             assertTrue(f.exists());
-<<<<<<<
-            assertTrue(f.toString().contains(String.format("-%s-", id.asString())));
-=======
             assertTrue(f.toString().contains(format("-%s-", id)));
->>>>>>>
             f.deleteOnExit();
             assertFalse(sstable.descriptor.fileFor(c).exists());
         }
--- a/test/unit/org/apache/cassandra/io/sstable/SSTableUtils.java
+++ b/test/unit/org/apache/cassandra/io/sstable/SSTableUtils.java
@@ -83,13 +83,8 @@
         File cfDir = new File(tempdir, keyspaceName + File.pathSeparator() + cfname);
         cfDir.tryCreateDirectories();
         cfDir.deleteOnExit();
-<<<<<<<
         File datafile = new Descriptor(cfDir, keyspaceName, cfname, id, DatabaseDescriptor.getSelectedSSTableFormat()).fileFor(Components.DATA);
         if (!datafile.createFileIfNotExists())
-=======
-        File datafile = new File(new Descriptor(cfDir, keyspaceName, cfname, id, SSTableFormat.Type.BIG).filenameFor(Component.DATA));
-        if (!datafile.createNewFile())
->>>>>>>
             throw new IOException("unable to create file " + datafile);
         datafile.delete();
         return datafile;
@@ -224,11 +219,7 @@
 
         public Collection<SSTableReader> write(int expectedSize, Appender appender) throws IOException
         {
-<<<<<<<
             File datafile = (dest == null) ? tempSSTableFile(ksname, cfname, id) : dest.fileFor(Components.DATA);
-=======
-            File datafile = (dest == null) ? tempSSTableFile(ksname, cfname, id) : new File(dest.filenameFor(Component.DATA));
->>>>>>>
             TableMetadata metadata = Schema.instance.getTableMetadata(ksname, cfname);
             ColumnFamilyStore cfs = Schema.instance.getColumnFamilyStoreInstance(metadata.id);
             SerializationHeader header = appender.header();
--- a/test/unit/org/apache/cassandra/io/sstable/SSTableWriterTestBase.java
+++ b/test/unit/org/apache/cassandra/io/sstable/SSTableWriterTestBase.java
@@ -140,11 +140,7 @@
             {
                 if (f.name().contains("Data"))
                 {
-<<<<<<<
                     Descriptor d = Descriptor.fromFileWithComponent(f, false).left;
-=======
-                    Descriptor d = Descriptor.fromFilename(f.getAbsolutePath());
->>>>>>>
                     assertTrue(d.toString(), liveDescriptors.contains(d.id));
                 }
             }
--- a/test/unit/org/apache/cassandra/io/sstable/metadata/MetadataSerializerTest.java
+++ b/test/unit/org/apache/cassandra/io/sstable/metadata/MetadataSerializerTest.java
@@ -17,12 +17,6 @@
  */
 package org.apache.cassandra.io.sstable.metadata;
 
-<<<<<<<
-=======
-import org.apache.cassandra.io.sstable.SequenceBasedSSTableId;
-import java.io.File;
-import java.io.FileOutputStream;
->>>>>>>
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.util.ArrayList;
@@ -84,11 +78,7 @@
         MetadataSerializer serializer = new MetadataSerializer();
         File statsFile = serialize(originalMetadata, serializer, DatabaseDescriptor.getSelectedSSTableFormat().getLatestVersion());
 
-<<<<<<<
-        Descriptor desc = new Descriptor(statsFile.getParentFile(), "", "", new SequenceBasedSSTableId(0), SSTableFormat.Type.BIG);
-=======
         Descriptor desc = new Descriptor(statsFile.parent(), "", "", new SequenceBasedSSTableId(0), DatabaseDescriptor.getSelectedSSTableFormat());
->>>>>>>
         try (RandomAccessReader in = RandomAccessReader.open(statsFile))
         {
             Map<MetadataType, MetadataComponent> deserialized = serializer.deserialize(desc, in, EnumSet.allOf(MetadataType.class));
@@ -114,13 +104,8 @@
 
         // Serialize w/ overflowed histograms:
         MetadataSerializer serializer = new MetadataSerializer();
-<<<<<<<
-        File statsFile = serialize(originalMetadata, serializer, BigFormat.latestVersion);
-        Descriptor desc = new Descriptor(statsFile.getParentFile(), "", "", new SequenceBasedSSTableId(0), SSTableFormat.Type.BIG);
-=======
         File statsFile = serialize(originalMetadata, serializer, format.getLatestVersion());
         Descriptor desc = new Descriptor(statsFile.parent(), "", "", new SequenceBasedSSTableId(0), format);
->>>>>>>
 
         try (RandomAccessReader in = RandomAccessReader.open(statsFile))
         {
@@ -219,12 +204,7 @@
         File statsFileLb = serialize(originalMetadata, serializer, format.getVersion(newV));
         File statsFileLa = serialize(originalMetadata, serializer, format.getVersion(oldV));
         // Reading both as earlier version should yield identical results.
-<<<<<<<
         Descriptor desc = new Descriptor(format.getVersion(oldV), statsFileLb.parent(), "", "", new SequenceBasedSSTableId(0));
-=======
-        SSTableFormat.Type stype = SSTableFormat.Type.current();
-        Descriptor desc = new Descriptor(stype.info.getVersion(oldV), statsFileLb.getParentFile(), "", "", new SequenceBasedSSTableId(0), stype);
->>>>>>>
         try (RandomAccessReader inLb = RandomAccessReader.open(statsFileLb);
              RandomAccessReader inLa = RandomAccessReader.open(statsFileLa))
         {
--- a/test/unit/org/apache/cassandra/schema/MockSchema.java
+++ b/test/unit/org/apache/cassandra/schema/MockSchema.java
@@ -19,15 +19,10 @@
 package org.apache.cassandra.schema;
 
 import java.io.IOException;
-<<<<<<<
-import java.io.RandomAccessFile;
-import java.util.*;
-=======
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Set;
->>>>>>>
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.atomic.AtomicInteger;
@@ -50,10 +45,6 @@
 import org.apache.cassandra.dht.Murmur3Partitioner;
 import org.apache.cassandra.io.sstable.Component;
 import org.apache.cassandra.io.sstable.Descriptor;
-<<<<<<<
-=======
-import org.apache.cassandra.io.sstable.IndexSummary;
->>>>>>>
 import org.apache.cassandra.io.sstable.SSTableId;
 import org.apache.cassandra.io.sstable.format.SSTableFormat;
 import org.apache.cassandra.io.sstable.format.SSTableReader;
@@ -97,11 +88,8 @@
                              new Object[]{ Util.newUUIDGen() });
     }
 
-<<<<<<<
-=======
     private static final File tempFile = temp("mocksegmentedfile");
 
->>>>>>>
     static
     {
         Memory offsets = Memory.allocate(4);
@@ -193,7 +181,6 @@
         Descriptor descriptor = new Descriptor(cfs.getDirectories().getDirectoryForNewSSTables(),
                                                cfs.getKeyspaceName(),
                                                cfs.getTableName(),
-<<<<<<<
                                                sstableId(generation),
                                                format);
 
@@ -292,11 +279,6 @@
     private static void maybeSetDataLength(Descriptor descriptor, long size)
     {
         if (size > 0)
-=======
-                                               sstableId(generation), SSTableFormat.Type.BIG);
-        Set<Component> components = ImmutableSet.of(Component.DATA, Component.PRIMARY_INDEX, Component.FILTER, Component.TOC);
-        for (Component component : components)
->>>>>>>
         {
             try
             {
--- a/test/unit/org/apache/cassandra/service/SSTablesGlobalTrackerTest.java
+++ b/test/unit/org/apache/cassandra/service/SSTablesGlobalTrackerTest.java
@@ -110,11 +110,7 @@
                                         tables(),
                                         generations(),
                                         sstableVersionString(),
-<<<<<<<
-                                        (f, k, t, g, v) -> new Descriptor(v, Files.currentFolder(), k, t, new SequenceBasedSSTableId(g), f));
-=======
                                         (f, k, t, g, v) -> new Descriptor(v, new File(Files.currentFolder()), k, t, new SequenceBasedSSTableId(g), f));
->>>>>>>
     }
 
     private Gen<List<Descriptor>> descriptorLists(int minSize)
--- a/test/unit/org/apache/cassandra/streaming/compression/CompressedInputStreamTest.java
+++ b/test/unit/org/apache/cassandra/streaming/compression/CompressedInputStreamTest.java
@@ -33,19 +33,6 @@
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.ClusteringComparator;
 import org.apache.cassandra.db.marshal.BytesType;
-<<<<<<<
-=======
-import org.apache.cassandra.io.compress.CompressedSequentialWriter;
-import org.apache.cassandra.io.compress.CompressionMetadata;
-import org.apache.cassandra.io.sstable.SequenceBasedSSTableId;
-import org.apache.cassandra.io.sstable.format.SSTableReader;
-import org.apache.cassandra.io.util.DataInputPlus.DataInputStreamPlus;
-import org.apache.cassandra.io.util.SequentialWriterOption;
-import org.apache.cassandra.schema.CompressionParams;
-import org.apache.cassandra.io.sstable.Component;
-import org.apache.cassandra.io.sstable.Descriptor;
-import org.apache.cassandra.io.sstable.metadata.MetadataCollector;
->>>>>>>
 import org.apache.cassandra.db.streaming.CompressedInputStream;
 import org.apache.cassandra.db.streaming.CompressionInfo;
 import org.apache.cassandra.io.compress.CompressedSequentialWriter;
@@ -135,15 +122,9 @@
         assert valuesToCheck != null && valuesToCheck.length > 0;
 
         // write compressed data file of longs
-<<<<<<<
         File parentDir = new File(tempFolder.newFolder());
         Descriptor desc = new Descriptor(parentDir, "ks", "cf", new SequenceBasedSSTableId(1));
         File tmp = desc.fileFor(Components.DATA);
-=======
-        File parentDir = tempFolder.newFolder();
-        Descriptor desc = new Descriptor(parentDir, "ks", "cf", new SequenceBasedSSTableId(1));
-        File tmp = new File(desc.filenameFor(Component.DATA));
->>>>>>>
         MetadataCollector collector = new MetadataCollector(new ClusteringComparator(BytesType.instance));
         CompressionParams param = CompressionParams.snappy(32, minCompressRatio);
         Map<Long, Long> index = new HashMap<Long, Long>();
--- a/test/unit/org/apache/cassandra/tools/JMXCompatabilityTest.java
+++ b/test/unit/org/apache/cassandra/tools/JMXCompatabilityTest.java
@@ -196,13 +196,6 @@
     @Test
     public void diff41() throws Throwable
     {
-<<<<<<<
-        List<String> excludeObjects = Arrays.asList();
-        List<String> excludeAttributes = Arrays.asList();
-        List<String> excludeOperations = Arrays.asList();
-
-        diff(excludeObjects, excludeAttributes, excludeOperations, "test/data/jmxdump/cassandra-4.0-cc-jmx.yaml");
-=======
         List<String> excludeObjects = newArrayList("org.apache.cassandra.metrics:type=BufferPool,name=(Misses|Size)" // removed in CASSANDRA-18313
         );
         List<String> excludeAttributes = newArrayList();
@@ -215,7 +208,6 @@
         }
 
         diff(excludeObjects, excludeAttributes, excludeOperations, "test/data/jmxdump/cassandra-4.1-jmx.yaml");
->>>>>>>
     }
 
     private void diff(List<String> excludeObjects, List<String> excludeAttributes, List<String> excludeOperations, String original) throws Throwable
diff --git a/conf/cassandra.yaml b/conf/cassandra.yaml
index f1e30d80da..fb6f454bb9 100644
--- a/conf/cassandra.yaml
+++ b/conf/cassandra.yaml
@@ -1123,14 +1123,6 @@ sstable_preemptive_open_interval: 50MiB
 # and eventually get removed from the configuration.
 uuid_sstable_identifiers_enabled: false
 
-# Starting from 4.1 sstables support UUID based generation identifiers. They are disabled by default
-# because once enabled, there is no easy way to downgrade. When the node is restarted with this option
-# set to true, each newly created sstable will have a UUID based generation identifier and such files are
-# not readable by previous Cassandra versions. At some point, this option will become true by default
-# and eventually get removed from the configuration.
-# In Converged Cassandra, we enable this option by default
-enable_uuid_sstable_identifiers: true
-
 # When enabled, permits Cassandra to zero-copy stream entire eligible
 # SSTables between nodes, including every component.
 # This speeds up the network transfer significantly subject to
diff --git a/src/java/org/apache/cassandra/io/sstable/SSTable.java b/src/java/org/apache/cassandra/io/sstable/SSTable.java
index ce9483d6e3..475f92beeb 100644
--- a/src/java/org/apache/cassandra/io/sstable/SSTable.java
+++ b/src/java/org/apache/cassandra/io/sstable/SSTable.java
@@ -163,12 +163,6 @@ public abstract class SSTable
         return ImmutableSet.copyOf(components);
     }
 
-    @VisibleForTesting
-    public Set<Component> getComponents()
-    {
-        return ImmutableSet.copyOf(components);
-    }
-
     /**
      * Returns all SSTable components that should be streamed.
      */
diff --git a/test/distributed/org/apache/cassandra/distributed/test/FailingTruncationTest.java b/test/distributed/org/apache/cassandra/distributed/test/FailingTruncationTest.java
index f0a9354021..9ce2bf339d 100644
--- a/test/distributed/org/apache/cassandra/distributed/test/FailingTruncationTest.java
+++ b/test/distributed/org/apache/cassandra/distributed/test/FailingTruncationTest.java
@@ -36,8 +36,6 @@ import static org.junit.Assert.fail;
 
 public class FailingTruncationTest extends TestBaseImpl
 {
-    private static final String BB_FAIL_HELPER_PROP = "test.bbfailhelper.enabled";
-
     @Test
     public void testFailingTruncation() throws IOException
     {
diff --git a/test/unit/org/apache/cassandra/db/DirectoriesTest.java b/test/unit/org/apache/cassandra/db/DirectoriesTest.java
index 67c8b8a47b..a5d5b2bef8 100644
--- a/test/unit/org/apache/cassandra/db/DirectoriesTest.java
+++ b/test/unit/org/apache/cassandra/db/DirectoriesTest.java
@@ -129,18 +129,6 @@ public class DirectoriesTest
     private int myDiyId = -1;
     private static Logger logger;
     private ListAppender<ILoggingEvent> listAppender;
-    @Parameterized.Parameter(0)
-    public SSTableId.Builder<? extends SSTableId> idBuilder;
-
-    @Parameterized.Parameter(1)
-    public Supplier<? extends SSTableId> idGenerator;
-
-    @Parameterized.Parameters
-    public static Collection<Object[]> idBuilders()
-    {
-        return Arrays.asList(new Object[]{ SequenceBasedSSTableId.Builder.instance, Util.newSeqGen() },
-                             new Object[]{ UUIDBasedSSTableId.Builder.instance, Util.newUUIDGen() });
-    }
 
     @Parameterized.Parameter
     public SSTableId.Builder<? extends SSTableId> idBuilder;
diff --git a/test/unit/org/apache/cassandra/io/sstable/LegacySSTableTest.java b/test/unit/org/apache/cassandra/io/sstable/LegacySSTableTest.java
index 366ff7c381..0fd8489850 100644
--- a/test/unit/org/apache/cassandra/io/sstable/LegacySSTableTest.java
+++ b/test/unit/org/apache/cassandra/io/sstable/LegacySSTableTest.java
@@ -19,8 +19,6 @@ package org.apache.cassandra.io.sstable;
 
 
 import java.io.IOException;
-import java.nio.file.Files;
-import java.nio.file.Path;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
@@ -55,6 +53,7 @@ import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.Range;
 import org.apache.cassandra.dht.Token;
 import org.apache.cassandra.exceptions.ConfigurationException;
+import org.apache.cassandra.io.sstable.format.SSTableFormat;
 import org.apache.cassandra.io.sstable.format.SSTableReader;
 import org.apache.cassandra.io.sstable.format.Version;
 import org.apache.cassandra.io.sstable.keycache.KeyCacheSupport;
