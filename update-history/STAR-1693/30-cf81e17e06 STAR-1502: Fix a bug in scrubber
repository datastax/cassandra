--- a/build.xml
+++ b/build.xml
@@ -1189,11 +1189,11 @@
     </target>
 
     <!-- creates release tarballs -->
-<<<<<<<
-    <target name="artifacts" depends="_artifacts-init,eclipse-warnings,gen-doc,sources-jar,javadoc-jar"
-=======
+<<<<<<< HEAD
     <target name="artifacts" depends="_artifacts-init,gen-doc,sources-jar"
->>>>>>>
+=======
+    <target name="artifacts" depends="_artifacts-init,eclipse-warnings,gen-doc,sources-jar,javadoc-jar"
+>>>>>>> 2c63a3b936 (STAR-1147: Improve unit-test performance (#360))
             description="Create DSE DB release artifacts">
       <tar compression="gzip" longfile="gnu"
         destfile="${build.dir}/${final.name}-bin.tar.gz">
--- a/src/java/org/apache/cassandra/db/partitions/PartitionUpdate.java
+++ b/src/java/org/apache/cassandra/db/partitions/PartitionUpdate.java
@@ -22,11 +22,11 @@
 import java.util.ArrayList;
 import java.util.List;
 
-<<<<<<<
+<<<<<<< HEAD
 import com.google.common.annotations.VisibleForTesting;
 =======
 import com.google.common.base.Preconditions;
->>>>>>>
+>>>>>>> 6e77c155f2 (STAR-985: allow substituting StorageProxy::mutateAtomically implementation (#316))
 import com.google.common.collect.Iterables;
 import com.google.common.collect.Lists;
 import net.openhft.chronicle.core.util.ThrowingFunction;
--- a/test/unit/org/apache/cassandra/db/ScrubTest.java
+++ b/test/unit/org/apache/cassandra/db/ScrubTest.java
@@ -178,17 +178,32 @@
     }
 
     @Test
-<<<<<<<
     public void testScrubLastBrokenPartition() throws ExecutionException, InterruptedException, IOException
     {
         CompactionManager.instance.disableAutoCompaction();
         ColumnFamilyStore cfs = ColumnFamilyStore.getIfExists(ksName, CF);
-=======
+
+        // insert data and verify we get it back w/ range query
+        fillCF(cfs, 1);
+        assertOrderedAll(cfs, 1);
+
+        Set<SSTableReader> liveSSTables = cfs.getLiveSSTables();
+        assertThat(liveSSTables).hasSize(1);
+        String fileName = liveSSTables.iterator().next().getFilename();
+        Files.write(Paths.get(fileName), new byte[10], StandardOpenOption.CREATE, StandardOpenOption.TRUNCATE_EXISTING);
+        ChunkCache.instance.invalidateFile(fileName);
+
+        CompactionManager.instance.performScrub(cfs, true, true, false, 2);
+
+        // check data is still there
+        assertOrderedAll(cfs, 0);
+    }
+
+    @Test
     public void testScrubOneBrokenPartition() throws ExecutionException, InterruptedException, IOException
     {
         CompactionManager.instance.disableAutoCompaction();
         ColumnFamilyStore cfs = keyspace.getColumnFamilyStore(CF);
->>>>>>>
 
         // insert data and verify we get it back w/ range query
         fillCF(cfs, 1);
@@ -196,13 +211,7 @@
 
         Set<SSTableReader> liveSSTables = cfs.getLiveSSTables();
         assertThat(liveSSTables).hasSize(1);
-<<<<<<<
         Files.write(liveSSTables.iterator().next().getDataFile().toPath(), new byte[10], StandardOpenOption.CREATE, StandardOpenOption.TRUNCATE_EXISTING);
-=======
-        String fileName = liveSSTables.iterator().next().getFilename();
-        Files.write(Paths.get(fileName), new byte[10], StandardOpenOption.CREATE, StandardOpenOption.TRUNCATE_EXISTING);
-        ChunkCache.instance.invalidateFile(fileName);
->>>>>>>
 
         CompactionManager.instance.performScrub(cfs, true, true, false, 2);
 
