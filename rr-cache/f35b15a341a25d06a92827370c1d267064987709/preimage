/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.cassandra.index.sai.plan;

import java.io.IOException;
import java.io.UncheckedIOException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.List;
import java.util.NavigableSet;
import java.util.stream.Collectors;

import javax.annotation.Nullable;

import com.google.common.collect.Lists;

import org.apache.cassandra.cql3.Operator;
import org.apache.cassandra.db.Clustering;
import org.apache.cassandra.db.ColumnFamilyStore;
import org.apache.cassandra.db.DataRange;
import org.apache.cassandra.db.DecoratedKey;
import org.apache.cassandra.db.MessageParams;
import org.apache.cassandra.db.PartitionPosition;
import org.apache.cassandra.db.PartitionRangeReadCommand;
import org.apache.cassandra.db.ReadCommand;
import org.apache.cassandra.db.ReadExecutionController;
import org.apache.cassandra.db.SinglePartitionReadCommand;
import org.apache.cassandra.db.filter.ClusteringIndexFilter;
import org.apache.cassandra.db.filter.ClusteringIndexNamesFilter;
import org.apache.cassandra.db.filter.DataLimits;
import org.apache.cassandra.db.filter.RowFilter;
import org.apache.cassandra.db.guardrails.Guardrails;
import org.apache.cassandra.db.rows.Row;
import org.apache.cassandra.db.rows.UnfilteredRowIterator;
import org.apache.cassandra.dht.AbstractBounds;
import org.apache.cassandra.index.sai.QueryContext;
import org.apache.cassandra.index.sai.StorageAttachedIndex;
import org.apache.cassandra.index.sai.VectorQueryContext;
import org.apache.cassandra.index.sai.disk.IndexSearchResultIterator;
import org.apache.cassandra.index.sai.disk.SSTableIndex;
import org.apache.cassandra.index.sai.iterators.KeyRangeConcatIterator;
import org.apache.cassandra.index.sai.iterators.KeyRangeIntersectionIterator;
import org.apache.cassandra.index.sai.iterators.KeyRangeIterator;
import org.apache.cassandra.index.sai.iterators.KeyRangeOrderingIterator;
import org.apache.cassandra.index.sai.iterators.KeyRangeUnionIterator;
import org.apache.cassandra.index.sai.utils.PrimaryKey;
import org.apache.cassandra.net.ParamType;
import org.apache.cassandra.schema.TableMetadata;
import org.apache.cassandra.tracing.Tracing;
import org.apache.cassandra.utils.InsertionOrderedNavigableSet;
import org.apache.cassandra.utils.Throwables;

import static org.apache.cassandra.config.CassandraRelevantProperties.SAI_VECTOR_SEARCH_ORDER_CHUNK_SIZE;

public class QueryController
{
    final QueryContext queryContext;

    private final ColumnFamilyStore cfs;
    private final ReadCommand command;
    private final RowFilter indexFilter;
    private final List<DataRange> ranges;
    private final AbstractBounds<PartitionPosition> mergeRange;
    private final PrimaryKey.Factory keyFactory;
    private final PrimaryKey firstPrimaryKey;
    private final PrimaryKey lastPrimaryKey;
    private final int orderChunkSize;

    private final NavigableSet<Clustering<?>> nextClusterings;

    public QueryController(ColumnFamilyStore cfs,
                           ReadCommand command,
                           RowFilter indexFilter,
                           QueryContext queryContext)
    {
        this.cfs = cfs;
        this.command = command;
        this.queryContext = queryContext;
        this.indexFilter = indexFilter;
        this.ranges = dataRanges(command);
        DataRange first = ranges.get(0);
        DataRange last = ranges.get(ranges.size() - 1);
        this.mergeRange = ranges.size() == 1 ? first.keyRange() : first.keyRange().withNewRight(last.keyRange().right);
        this.keyFactory = new PrimaryKey.Factory(cfs.getPartitioner(), cfs.getComparator());
        this.firstPrimaryKey = keyFactory.create(mergeRange.left.getToken());
        this.lastPrimaryKey = keyFactory.create(mergeRange.right.getToken());
        this.orderChunkSize = SAI_VECTOR_SEARCH_ORDER_CHUNK_SIZE.getInt();
        this.nextClusterings = new InsertionOrderedNavigableSet<>(cfs.metadata().comparator);
    }

    public PrimaryKey.Factory primaryKeyFactory()
    {
        return keyFactory;
    }

    public PrimaryKey firstPrimaryKeyInRange()
    {
        return firstPrimaryKey;
    }

    public PrimaryKey lastPrimaryKeyInRange()
    {
        return lastPrimaryKey;
    }

    public TableMetadata metadata()
    {
        return command.metadata();
    }

    public RowFilter indexFilter()
    {
        return this.indexFilter;
    }
    
    public boolean usesStrictFiltering()
    {
        return command.rowFilter().isStrict();
    }

    /**
     * @return token ranges used in the read command
     */
    public List<DataRange> dataRanges()
    {
        return ranges;
    }

<<<<<<<
    /**
     * Note: merged range may contain subrange that no longer belongs to the local node after range movement.
     * It should only be used as an optimization to reduce search space. Use {@link #dataRanges()} instead to filter data.
     *
     * @return merged token range
     */
    AbstractBounds<PartitionPosition> mergeRange()
    {
        return mergeRange;
    }

    /**
     * @return indexed {@code ColumnContext} if index is found; otherwise return non-indexed {@code ColumnContext}.
     */
    public IndexContext getContext(RowFilter.Expression expression)
    {
        StorageAttachedIndex index = getBestIndexFor(expression);

        if (index != null)
            return index.getIndexContext();

        return new IndexContext(cfs.metadata().keyspace,
                                cfs.metadata().name,
                                cfs.metadata().id,
                                cfs.metadata().partitionKeyType,
                                cfs.metadata().comparator,
                                expression.column(),
                                determineIndexTargetType(expression),
                                null,
                                cfs);
    }

    /**
     * Determines the {@link IndexTarget.Type} for the expression. In this case we are only interested in map types and
     * the operator being used in the expression.
     */
    public static IndexTarget.Type determineIndexTargetType(RowFilter.Expression expression)
    {
        AbstractType<?> type  = expression.column().type;
        IndexTarget.Type indexTargetType = IndexTarget.Type.SIMPLE;
        if (type.isCollection() && type.isMultiCell())
        {
            CollectionType<?> collection = ((CollectionType<?>) type);
            if (collection.kind == CollectionType.Kind.MAP)
            {
                Operator operator = expression.operator();
                switch (operator)
                {
                    case EQ:
                    case NEQ:
                    case LT:
                    case LTE:
                    case GT:
                    case GTE:
                        indexTargetType = IndexTarget.Type.KEYS_AND_VALUES;
                        break;
                    case CONTAINS:
                    case NOT_CONTAINS:
                        indexTargetType = IndexTarget.Type.VALUES;
                        break;
                    case CONTAINS_KEY:
                    case NOT_CONTAINS_KEY:
                        indexTargetType = IndexTarget.Type.KEYS;
                        break;
                    default:
                        throw new InvalidRequestException("Invalid operator " + operator + " for map type");
                }
            }
        }
        return indexTargetType;
    }

    /**
     * Get an iterator over the rows for this partition key. Builds a search view that includes all memtables and all
     * {@link SSTableSet#LIVE} sstables.
     * @param key
     * @param executionController
     * @return
     */
    public UnfilteredRowIterator getPartition(PrimaryKey key, ReadExecutionController executionController)
    {
        if (key == null)
            throw new IllegalArgumentException("At least one primary key is required!");

        SinglePartitionReadCommand partition = getPartitionReadCommand(key, executionController);
        return partition.queryMemtableAndDisk(cfs, executionController);
    }

    /**
     * Get an iterator over the rows for this partition key. Restrict the search to the specified view.
     * @param key
     * @param executionController
     * @return
     */
    public UnfilteredRowIterator getPartition(PrimaryKey key, ColumnFamilyStore.ViewFragment view, ReadExecutionController executionController)
    {
        if (key == null)
            throw new IllegalArgumentException("non-null key required");

        SinglePartitionReadCommand partition = getPartitionReadCommand(key, executionController);

        // Class to transform the row to include its source table.
        Function<Object, Transformation<BaseRowIterator<?>>> rowTransformer = (Object sourceTable) -> new Transformation<>()
        {
            @Override
            protected Row applyToRow(Row row)
            {
                return new RowWithSourceTable(row, sourceTable);
            }
        };

        return partition.queryMemtableAndDisk(cfs, view, rowTransformer, executionController);
    }

    public SinglePartitionReadCommand getPartitionReadCommand(PrimaryKey key, ReadExecutionController executionController)
    {
        if (key == null)
            throw new IllegalArgumentException("non-null key required");

        return SinglePartitionReadCommand.create(cfs.metadata(),
                                                 command.nowInSec(),
                                                 command.columnFilter(),
                                                 RowFilter.none(),
                                                 DataLimits.NONE,
                                                 key.partitionKey(),
                                                 makeFilter(key));
    }

    Plan buildPlan()
    {
        Plan.KeysIteration keysIterationPlan = buildKeysIterationPlan();
        Plan.RowsIteration rowsIteration = planFactory.fetch(keysIterationPlan);
        rowsIteration = planFactory.recheckFilter(command.rowFilter(), rowsIteration);
        rowsIteration = planFactory.limit(rowsIteration, command.limits().rows());

        // Limit the number of intersected clauses before optimizing so we reduce the size of the
        // plan given to the optimizer and hence reduce the plan search space and speed up optimization.
        // It is possible that some index operators like ':' expand to a huge number of MATCH predicates
        // (see CNDB-10085) and could overload the optimizer.
        // The intersected subplans are ordered by selectivity in the way the best ones are at the beginning
        // of the list, therefore this limit is unlikely to remove good branches of the tree.
        // The limit here is higher than the final limit, so that the optimizer has a bit more freedom
        // in which predicates it leaves in the plan and the probability of accidentally removing a good branch
        // here is even lower.
        Plan plan = rowsIteration.limitIntersectedClauses(KeyRangeIntersectionIterator.INTERSECTION_CLAUSE_LIMIT * 3);

        if (QUERY_OPT_LEVEL > 0)
            plan = plan.optimize();

        plan = plan.limitIntersectedClauses(KeyRangeIntersectionIterator.INTERSECTION_CLAUSE_LIMIT);

        if (plan.contains(node -> node instanceof Plan.AnnIndexScan))
            queryContext.setFilterSortOrder(QueryContext.FilterSortOrder.SCAN_THEN_FILTER);
        if (plan.contains(node -> node instanceof Plan.KeysSort))
            queryContext.setFilterSortOrder(QueryContext.FilterSortOrder.SEARCH_THEN_ORDER);

        if (logger.isTraceEnabled())
            logger.trace("Query execution plan:\n" + plan.toStringRecursive());

        if (Tracing.isTracing())
        {
            Tracing.trace("Query execution plan:\n" + plan.toStringRecursive());
            List<Plan.IndexScan> origIndexScans = keysIterationPlan.nodesOfType(Plan.IndexScan.class);
            List<Plan.IndexScan> selectedIndexScans = plan.nodesOfType(Plan.IndexScan.class);
            Tracing.trace("Selecting {} {} of {} out of {} indexes",
                          selectedIndexScans.size(),
                          selectedIndexScans.size() > 1 ? "indexes with cardinalities" : "index with cardinality",
                          selectedIndexScans.stream().map(s -> "" + ((long) s.expectedKeys())).collect(Collectors.joining(", ")),
                          origIndexScans.size());
        }
        return plan;
    }

    private Plan.KeysIteration buildKeysIterationPlan()
    {
        // Remove the ORDER BY filter expression from the filter tree, as it is added below.
        var filterElement = filterOperation().filter(e -> !Orderer.isFilterExpressionOrderer(e));
        Plan.KeysIteration keysIterationPlan = Operation.Node.buildTree(this, filterElement)
                                                             .analyzeTree(this)
                                                             .plan(this);

        // Because the orderer has a specific queue view
        if (orderer != null)
            keysIterationPlan = planFactory.sort(keysIterationPlan, orderer);

        // This would mean we have no WHERE nor ANN clauses at all; this can happen in case an index was dropped after the
        // query was initiated
        if (keysIterationPlan == planFactory.everything)
            throw invalidRequest(INDEX_MAY_HAVE_BEEN_DROPPED);

        return keysIterationPlan;
    }


    public Iterator<? extends PrimaryKey> buildIterator(Plan plan)
    {
        try
        {
            Plan.KeysIteration keysIteration = plan.firstNodeOfType(Plan.KeysIteration.class);
            assert keysIteration != null : "No index scan found";
            return keysIteration.execute(this);
        }
        finally
        {
            // Because we optimize the plan, it is possible that there exist iterators that we
            // constructed but which weren't used by the final plan.
            // Let's close them here, so they don't hold the resources.
            closeUnusedIterators();
        }
    }

    /**
     * Creates an iterator over keys of rows that match given WHERE predicate.
     * Does not cache the iterator!
     */
    private KeyRangeIterator buildIterator(Expression predicate)
    {
        QueryView view = getQueryView(predicate.context);
        return KeyRangeTermIterator.build(predicate, view.referencedIndexes, mergeRange, queryContext, false, Integer.MAX_VALUE);
    }

    /**
     * Creates a consistent view of indexes.
     * Invocations are memorized - multiple calls for the same context return the same view.
     * The views are kept for the lifetime of this {@code QueryController}.
     */
    QueryView getQueryView(IndexContext context) throws QueryView.Builder.MissingIndexException
    {
        return queryViews.computeIfAbsent(context,
                                          c -> new QueryView.Builder(c, mergeRange, queryContext).build());

    }


    private float avgCellsPerRow()
    {
        long cells = 0;
        long rows = 0;
        for (SSTableReader sstable : cfs.getLiveSSTables())
        {
            rows += sstable.getTotalRows();
            cells += sstable.getEstimatedCellPerPartitionCount().mean() * sstable.getEstimatedCellPerPartitionCount().count();
        }
        return rows == 0 ? 0.0f : ((float) cells) / rows;
    }

    private float avgRowSizeInBytes()
    {
        long totalLength = 0;
        long rows = 0;
        for (SSTableReader sstable : cfs.getLiveSSTables())
        {
            rows += sstable.getTotalRows();
            totalLength += sstable.uncompressedLength();
        }
        return rows == 0 ? 0.0f : ((float) totalLength) / rows;
    }


    public FilterTree buildFilter()
    {
        return Operation.Node.buildTree(this, filterOperation()).analyzeTree(this).filterTree();
    }

    private Plan.KeysIteration buildHalfRangeFromInequality(Expression originPredicate, Operator op)
    {
        assert originPredicate.getOp() == Expression.Op.NOT_EQ : "assumes inequality";
        assert originPredicate.lower.value == originPredicate.upper.value : "assumes lower and upper are the same in inequality";

        Expression halfRange = new Expression(originPredicate.context);
        halfRange.add(op, originPredicate.lower.value.raw);
        long matchingRowCount = Math.min(estimateMatchingRowCount(halfRange), planFactory.tableMetrics.rows);
        return planFactory.indexScan(halfRange, matchingRowCount);
    }

    /**
     * Builds a plan for a restriction with inequality. It's implemented as
     * union of two ranges, before the value and after the value.
     * If the column type is truncatable, e.g., BigInteger or BigDecimal,
     * then it returns a full index scan, since the ranges might result
     * in false negatives when a truncated value is equivalent to
     * the value to exclude.
     * @param predicate Inequality expression with indexContext
     * @return A plan on the index, which can also result false positives.
     */
    private Plan.KeysIteration buildInequalityPlan(Expression predicate)
    {
        assert predicate.getOp()== Expression.Op.NOT_EQ : "Only inequality predicate is expected";

        if (TypeUtil.supportsRounding(predicate.validator))
            return planFactory.fullIndexScan(predicate.context);
        else
        {
            Plan.KeysIteration left = buildHalfRangeFromInequality(predicate, Operator.LT);
            Plan.KeysIteration right = buildHalfRangeFromInequality(predicate, Operator.GT);
            return planFactory.union(new ArrayList<>(Arrays.asList(left, right)));
        }
    }

    /**
     * Build a {@link Plan} from the given list of expressions by applying given operation (OR/AND).
     * Building of such builder involves index search, results of which are persisted in the internal resources list
     *
     * @param builder The plan node builder which receives the built index scans
     * @param expressions The expressions to build the plan from
     */
    void buildPlanForExpressions(Plan.Builder builder, Collection<Expression> expressions)
    {
        Operation.OperationType op = builder.type;
        assert !expressions.isEmpty() : "expressions should not be empty for " + op + " in " + command.rowFilter().root();

        assert !expressions.stream().anyMatch(e -> e.operation == Expression.Op.ORDER_BY);

        // we cannot use indexes with OR if we have a mix of indexed and non-indexed columns (see CNDB-10142)
        if (op == Operation.OperationType.OR && !expressions.stream().allMatch(e -> e.context.isIndexed()))
        {
            builder.add(planFactory.everything);
            return;
        }

        for (Expression expression : expressions)
        {
            if (expression.context.isIndexed())
            {
                if ( expression.getOp() == Expression.Op.NOT_EQ)
                    builder.add(buildInequalityPlan(expression));
                else
                {
                    long expectedMatchingRowCount = Math.min(estimateMatchingRowCount(expression), planFactory.tableMetrics.rows);
                    builder.add(planFactory.indexScan(expression, expectedMatchingRowCount));
                }
            }
        }
    }

    @Override
    public Iterator<? extends PrimaryKey> getKeysFromIndex(Expression predicate)
    {
        Collection<KeyRangeIterator> rangeIterators = keyIterators.get(predicate);
        // This will be non-empty only if we created the iterator as part of the query planning process.
        if (!rangeIterators.isEmpty())
        {
            KeyRangeIterator iterator = rangeIterators.iterator().next();
            keyIterators.remove(predicate, iterator);  // remove so we never accidentally reuse the same iterator
            return iterator;
        }

        return buildIterator(predicate);
    }

    /**
     * Use the configured {@link Orderer} to create an iterator that sorts the whole table by a specific column.
     */
    @Override
    public CloseableIterator<PrimaryKeyWithSortKey> getTopKRows(Expression predicate, int softLimit)
    {
        List<CloseableIterator<PrimaryKeyWithSortKey>> memtableResults = new ArrayList<>();
        try
        {
            QueryView view = getQueryView(orderer.context);
            for (MemtableIndex index : view.memtableIndexes)
                memtableResults.addAll(index.orderBy(queryContext, orderer, predicate, mergeRange, softLimit));

            var totalRows = view.getTotalSStableRows();
            SSTableSearcher searcher = index -> index.orderBy(orderer, predicate, mergeRange, queryContext, softLimit, totalRows);
            var sstableResults = searchSSTables(view, searcher);
            sstableResults.addAll(memtableResults);
            return MergeIterator.getNonReducingCloseable(sstableResults, orderer.getComparator());
        }
        catch (QueryView.Builder.MissingIndexException e)
        {
            if (orderer.context.isDropped())
                throw invalidRequest(TopKProcessor.INDEX_MAY_HAVE_BEEN_DROPPED);
            else
                throw new IllegalStateException("Index not found but hasn't been dropped", e);
        }
        catch (Throwable t)
        {
            FileUtils.closeQuietly(memtableResults);
            throw t;
        }
    }

    /**
     * Use the configured {@link Orderer} to sort the rows from the given source iterator.
     */
    public CloseableIterator<PrimaryKeyWithSortKey> getTopKRows(KeyRangeIterator source, int softLimit)
    {
        try
        {
            var primaryKeys = materializeKeys(source);
            if (primaryKeys.isEmpty())
            {
                FileUtils.closeQuietly(source);
                return CloseableIterator.emptyIterator();
            }
            var result = getTopKRows(primaryKeys, softLimit);
            // We cannot close the source iterator eagerly because it produces partially loaded PrimaryKeys
            // that might not be needed until a deeper search into the ordering index, which happens after
            // we exit this block.
            return CloseableIterator.withOnClose(result, source);
        }
        catch (Throwable t)
        {
            FileUtils.closeQuietly(source);
            throw t;
        }
    }

    /**
     * Materialize the keys from the given source iterator. If there is a meaningful {@link #mergeRange}, the keys
     * are filtered to only include those within the range. Note: does not close the source iterator.
     * @param source The source iterator to materialize keys from.
     * @return The list of materialized keys within the {@link #mergeRange}.
     */
    private List<PrimaryKey> materializeKeys(KeyRangeIterator source)
    {
        // Skip to the first key in the range
        source.skipTo(primaryKeyFactory().createTokenOnly(mergeRange.left.getToken()));
        if (!source.hasNext())
            return List.of();

        var maxToken = primaryKeyFactory().createTokenOnly(mergeRange.right.getToken());
        var hasLimitingMaxToken = !maxToken.token().isMinimum() && maxToken.compareTo(source.getMaximum()) < 0;
        List<PrimaryKey> primaryKeys = new ArrayList<>();
        while (source.hasNext())
        {
            var next = source.next();
            if (hasLimitingMaxToken && next.compareTo(maxToken) > 0)
                break;
            primaryKeys.add(next);
        }
        return primaryKeys;
    }

    private CloseableIterator<PrimaryKeyWithSortKey> getTopKRows(List<PrimaryKey> sourceKeys, int softLimit)
    {
        Tracing.logAndTrace(logger, "SAI predicates produced {} keys", sourceKeys.size());
        List<CloseableIterator<PrimaryKeyWithSortKey>> memtableResults = null;
        try
        {
            QueryView view = getQueryView(orderer.context);
            memtableResults = view.memtableIndexes.stream()
                                                  .map(index -> index.orderResultsBy(queryContext,
                                                                                     sourceKeys,
                                                                                     orderer,
                                                                                     softLimit))
                                                  .collect(Collectors.toList());
            var totalRows = view.getTotalSStableRows();
            SSTableSearcher ssTableSearcher = index -> index.orderResultsBy(queryContext,
                                                                            sourceKeys,
                                                                            orderer,
                                                                            softLimit,
                                                                            totalRows);
            var sstableScoredPrimaryKeyIterators = searchSSTables(view, ssTableSearcher);
            sstableScoredPrimaryKeyIterators.addAll(memtableResults);
            return MergeIterator.getNonReducingCloseable(sstableScoredPrimaryKeyIterators, orderer.getComparator());
        }
        catch (QueryView.Builder.MissingIndexException e)
        {
            if (orderer.context.isDropped())
                throw invalidRequest(TopKProcessor.INDEX_MAY_HAVE_BEEN_DROPPED);
            else
                throw new IllegalStateException("Index not found but hasn't been dropped", e);
        }
        catch (Throwable t)
        {
            if (memtableResults != null)
                FileUtils.closeQuietly(memtableResults);
            throw t;
        }

    }


    @FunctionalInterface
    interface SSTableSearcher
    {
        List<CloseableIterator<PrimaryKeyWithSortKey>> search(SSTableIndex index) throws Exception;
    }

    /**
     * Create the list of iterators over {@link PrimaryKeyWithSortKey} from the given {@link QueryView}.
     * @param queryView The view to use to create the iterators.
     * @return The list of iterators over {@link PrimaryKeyWithSortKey}.
     */
    private List<CloseableIterator<PrimaryKeyWithSortKey>> searchSSTables(QueryView queryView, SSTableSearcher searcher)
    {
        List<CloseableIterator<PrimaryKeyWithSortKey>> results = new ArrayList<>();
        for (var index : queryView.referencedIndexes)
        {
            try
            {
                var iterators = searcher.search(index);
                results.addAll(iterators);
            }
            catch (Throwable ex)
            {
                // Close any iterators that were successfully opened before the exception
                FileUtils.closeQuietly(results);
                if (logger.isDebugEnabled() && !(ex instanceof AbortedOperationException))
                {
                    var msg = String.format("Failed search on index %s, aborting query.", index.getSSTable());
                    logger.debug(index.getIndexContext().logMessage(msg), ex);
                }
                throw Throwables.cleaned(ex);
            }
        }
        return results;
    }

    public IndexFeatureSet indexFeatureSet()
    {
        return indexFeatureSet;
    }

    public Orderer getOrderer()
    {
        return orderer;
    }

    /**
     * Returns whether this query is selecting the {@link PrimaryKey}.
     * The query selects the key if any of the following statements is true:
     *  1. The query is not row-aware
     *  2. The table associated with the query is not using clustering keys
     *  3. The clustering index filter for the command wants the row.
     *
     *  Item 3 is important in paged queries where the {@link ClusteringIndexSliceFilter} for
     *  subsequent paged queries may not select rows that are returned by the index
     *  search because that is initially partition based.
     *
     * @param key The {@link PrimaryKey} to be tested
     * @return true if the key is selected by the query
     */
    public boolean selects(PrimaryKey key)
    {
        return !indexFeatureSet.isRowAware() ||
               key.hasEmptyClustering() ||
               command.clusteringIndexFilter(key.partitionKey()).selects(key.clustering());
    }

    private StorageAttachedIndex getBestIndexFor(RowFilter.Expression expression)
=======
    @Nullable
    public StorageAttachedIndex indexFor(RowFilter.Expression expression)
>>>>>>>
    {
        return cfs.indexManager.getBestIndexFor(expression, StorageAttachedIndex.class).orElse(null);
    }

    public boolean hasAnalyzer(RowFilter.Expression expression)
    {
        StorageAttachedIndex index = indexFor(expression);
        return index != null && index.hasAnalyzer();
    }

    public UnfilteredRowIterator queryStorage(List<PrimaryKey> keys, ReadExecutionController executionController)
    {
        if (keys.isEmpty())
            throw new IllegalArgumentException("At least one primary key is required!");

        SinglePartitionReadCommand partition = SinglePartitionReadCommand.create(cfs.metadata(),
                                                                                 command.nowInSec(),
                                                                                 command.columnFilter(),
                                                                                 RowFilter.none(),
                                                                                 DataLimits.NONE,
                                                                                 keys.get(0).partitionKey(),
                                                                                 makeFilter(keys));

        return partition.queryMemtableAndDisk(cfs, executionController);
    }

    /**
     * Build a {@link KeyRangeIterator.Builder} from the given list of {@link Expression}s.
     * <p>
     * This is achieved by creating an on-disk view of the query that maps the expressions to
     * the {@link SSTableIndex}s that will satisfy the expression.
     * <p>
     * Each {@link QueryViewBuilder.QueryExpressionView} is then passed to
     * {@link IndexSearchResultIterator#build(QueryViewBuilder.QueryExpressionView, AbstractBounds, QueryContext, boolean, Runnable)}
     * to search the in-memory indexes associated with the expression and the SSTable indexes, the results of
     * which are unioned and returned.
     * <p>
     * The results from each call to {@link IndexSearchResultIterator#build(QueryViewBuilder.QueryExpressionView, AbstractBounds, QueryContext, boolean, Runnable)}
     * are added to a {@link KeyRangeIntersectionIterator} and returned if strict filtering is allowed.
     * <p>
     * If strict filtering is not allowed, indexes are split into two groups according to the repaired status of their 
     * backing SSTables. Results from searches over the repaired group are added to a 
     * {@link KeyRangeIntersectionIterator}, which is then added, along with results from searches on the unrepaired
     * set, to a top-level {@link KeyRangeUnionIterator}, and returned. This is done to ensure that AND queries do not
     * prematurely filter out matches on un-repaired partial updates. Post-filtering must also take this into
     * account. (see {@link FilterTree#isSatisfiedBy(DecoratedKey, Row, Row)}) Note that Memtable-attached 
     * indexes are treated as part of the unrepaired set.
     */
    public KeyRangeIterator.Builder getIndexQueryResults(Collection<Expression> expressions)
    {
        // VSTODO move ANN out of expressions and into its own abstraction? That will help get generic ORDER BY support
        expressions = expressions.stream().filter(e -> e.getIndexOperator() != Expression.IndexOperator.ANN).collect(Collectors.toList());

        QueryViewBuilder.QueryView queryView = new QueryViewBuilder(expressions, mergeRange).build();
        Runnable onClose = () -> queryView.referencedIndexes.forEach(SSTableIndex::releaseQuietly);
        KeyRangeIterator.Builder builder = command.rowFilter().isStrict()
                                           ? KeyRangeIntersectionIterator.builder(expressions.size(), onClose)
                                           : KeyRangeUnionIterator.builder(expressions.size(), onClose);

        try
        {
            maybeTriggerGuardrails(queryView);

            if (command.rowFilter().isStrict())
            {
                // If strict filtering is enabled, evaluate indexes for both repaired and un-repaired SSTables together.
                // This usually means we are making this local index query in the context of a user query that reads 
                // from a single replica and thus can safely perform local intersections.
                for (QueryViewBuilder.QueryExpressionView queryExpressionView : queryView.view)
                    builder.add(IndexSearchResultIterator.build(queryExpressionView, mergeRange, queryContext, true, () -> {}));
            }
            else
            {
                KeyRangeIterator.Builder repairedBuilder = KeyRangeIntersectionIterator.builder(expressions.size(), () -> {});

                for (QueryViewBuilder.QueryExpressionView queryExpressionView : queryView.view)
                {
                    Expression expression = queryExpressionView.expression;
                    // The initial sizes here reflect little more than an effort to avoid resizing for 
                    // partition-restricted searches w/ LCS:
                    List<SSTableIndex> repaired = new ArrayList<>(5);
                    List<SSTableIndex> unrepaired = new ArrayList<>(5);

                    // Split SSTable indexes into repaired and un-reparired:
                    for (SSTableIndex index : queryExpressionView.sstableIndexes)
                        if (index.getSSTable().isRepaired())
                            repaired.add(index);
                        else
                            unrepaired.add(index);

                    // Always build an iterator for the un-repaired set, given this must include Memtable indexes...  
                    IndexSearchResultIterator unrepairedIterator =
                            IndexSearchResultIterator.build(expression, queryExpressionView.memtableIndexes, unrepaired, mergeRange, queryContext, true, () -> {});

                    // ...but ignore it if our combined results are empty.
                    if (unrepairedIterator.getMaxKeys() > 0)
                    {
                        builder.add(unrepairedIterator);
                        queryContext.hasUnrepairedMatches = true;
                    }
                    else
                    {
                        // We're not going to use this, so release the resources it holds.
                        unrepairedIterator.close();
                    }

                    // ...then only add an iterator to the repaired intersection if repaired SSTable indexes exist. 
                    if (!repaired.isEmpty())
                        repairedBuilder.add(IndexSearchResultIterator.build(expression, Collections.emptyList(), repaired, mergeRange, queryContext, false, () -> {}));
                }

                if (repairedBuilder.rangeCount() > 0)
                    builder.add(repairedBuilder.build());
            }
        }
        catch (Throwable t)
        {
            // all sstable indexes in view have been referenced, need to clean up when exception is thrown
            builder.cleanup();
            throw t;
        }
        return builder;
    }

    private void maybeTriggerGuardrails(QueryViewBuilder.QueryView queryView)
    {
        int referencedIndexes = 0;

        // We want to make sure that no individual column expression touches too many SSTable-attached indexes:
        for (QueryViewBuilder.QueryExpressionView expressionSSTables : queryView.view)
            referencedIndexes = Math.max(referencedIndexes, expressionSSTables.sstableIndexes.size());

        if (Guardrails.saiSSTableIndexesPerQuery.failsOn(referencedIndexes, null))
        {
            String msg = String.format("Query %s attempted to read from too many indexes (%s) but max allowed is %s; " +
                                       "query aborted (see sai_sstable_indexes_per_query_fail_threshold)",
                                       command.toCQLString(),
                                       referencedIndexes,
                                       Guardrails.CONFIG_PROVIDER.getOrCreate(null).getSaiSSTableIndexesPerQueryFailThreshold());
            Tracing.trace(msg);
            MessageParams.add(ParamType.TOO_MANY_REFERENCED_INDEXES_FAIL, referencedIndexes);
            throw new QueryReferencingTooManyIndexesException(msg);
        }
        else if (Guardrails.saiSSTableIndexesPerQuery.warnsOn(referencedIndexes, null))
        {
            MessageParams.add(ParamType.TOO_MANY_REFERENCED_INDEXES_WARN, referencedIndexes);
        }
    }

    /**
     * Returns whether this query is not selecting the {@link PrimaryKey}.
     * The query does not select the key if both of the following statements are false:
     *  1. The table associated with the query is not using clustering keys
     *  2. The clustering index filter for the command wants the row.
     * <p>
     *  Item 2 is important in paged queries where the {@link org.apache.cassandra.db.filter.ClusteringIndexSliceFilter} for
     *  subsequent paged queries may not select rows that are returned by the index
     *  search because that is initially partition based.
     *
     * @param key The {@link PrimaryKey} to be tested
     * @return true if the key is not selected by the query
     */
    public boolean doesNotSelect(PrimaryKey key)
    {
        return key.kind() == PrimaryKey.Kind.WIDE && !command.clusteringIndexFilter(key.partitionKey()).selects(key.clustering());
    }

    // This is an ANN only query
    public KeyRangeIterator getTopKRows(RowFilter.Expression expression)
    {
        assert expression.operator() == Operator.ANN;
        StorageAttachedIndex index = indexFor(expression);
        assert index != null;
        Expression planExpression = Expression.create(index).add(Operator.ANN, expression.getIndexValue().duplicate());

        QueryViewBuilder.QueryView queryView = new QueryViewBuilder(Collections.singleton(planExpression), mergeRange).build();
        Runnable onClose = () -> queryView.referencedIndexes.forEach(SSTableIndex::releaseQuietly);

        try
        {
            List<KeyRangeIterator> memtableResults = queryView.view
                                                              .stream()
                                                              .map(v -> v.memtableIndexes)
                                                              .flatMap(Collection::stream)
                                                              .map(idx -> idx.search(queryContext, planExpression, mergeRange))
                                                              .collect(Collectors.toList());

            List<KeyRangeIterator> sstableIntersections = queryView.view
                                                                   .stream()
                                                                   .map(this::createRowIdIterator)
                                                                   .collect(Collectors.toList());

            return IndexSearchResultIterator.build(sstableIntersections, memtableResults, queryView.referencedIndexes, queryContext, onClose);
        }
        catch (Throwable t)
        {
            // all sstable indexes in view have been referenced, need to clean up when exception is thrown
            onClose.run();
            throw t;
        }
    }

    // This is a hybrid query. We apply all other predicates before ordering and limiting.
    public KeyRangeIterator getTopKRows(KeyRangeIterator source, RowFilter.Expression expression)
    {
        return new KeyRangeOrderingIterator(source, orderChunkSize, list -> this.getTopKRows(list, expression));
    }

    private KeyRangeIterator getTopKRows(List<PrimaryKey> rawSourceKeys, RowFilter.Expression expression)
    {
        VectorQueryContext vectorQueryContext = queryContext.vectorContext();
        // Filter out PKs now. Each PK is passed to every segment of the ANN index, so filtering shadowed keys
        // eagerly can save some work when going from PK to row id for on disk segments.
        // Since the result is shared with multiple streams, we use an unmodifiable list.
        List<PrimaryKey> sourceKeys = rawSourceKeys.stream().filter(vectorQueryContext::shouldInclude).collect(Collectors.toList());
        StorageAttachedIndex index = indexFor(expression);
        assert index != null : "Cannot do ANN ordering on an unindexed column";
        Expression planExpression = Expression.create(index);
        planExpression.add(Operator.ANN, expression.getIndexValue().duplicate());

        QueryViewBuilder.QueryView queryView = new QueryViewBuilder(Collections.singleton(planExpression), mergeRange).build();
        Runnable onClose = () -> queryView.referencedIndexes.forEach(SSTableIndex::releaseQuietly);

        try
        {
            List<KeyRangeIterator> memtableResults = queryView.view
                                                              .stream()
                                                              .map(v -> v.memtableIndexes)
                                                              .flatMap(Collection::stream)
                                                              .map(idx -> idx.limitToTopResults(sourceKeys, planExpression, vectorQueryContext.limit()))
                                                              .collect(Collectors.toList());

            List<KeyRangeIterator> sstableIntersections = queryView.view
                                                                   .stream()
                                                                   .flatMap(pair -> pair.sstableIndexes.stream())
                                                                   .map(idx -> {
                                                                       try
                                                                       {
                                                                           return idx.limitToTopKResults(queryContext, sourceKeys, planExpression);
                                                                       }
                                                                       catch (IOException e)
                                                                       {
                                                                           throw new UncheckedIOException(e);
                                                                       }
                                                                   })
                                                                   .collect(Collectors.toList());

            return IndexSearchResultIterator.build(sstableIntersections, memtableResults, queryView.referencedIndexes, queryContext, onClose);
        }
        catch (Throwable t)
        {
            // all sstable indexes in view have been referenced, need to clean up when exception is thrown
            onClose.run();
            throw t;
        }
    }

    /**
     * Create row id iterator from different indexes' on-disk searcher of the same sstable
     */
    private KeyRangeIterator createRowIdIterator(QueryViewBuilder.QueryExpressionView indexExpression)
    {
        List<KeyRangeIterator> subIterators = indexExpression.sstableIndexes
                           .stream()
                           .map(index ->
                                {
                                    try
                                    {
                                        List<KeyRangeIterator> iterators = index.search(indexExpression.expression, mergeRange, queryContext);
                                        // concat the result from multiple segments for the same index
                                        return KeyRangeConcatIterator.builder(iterators.size()).add(iterators).build();
                                    }
                                    catch (Throwable ex)
                                    {
                                        throw Throwables.cleaned(ex);
                                    }
                                }).collect(Collectors.toList());

        return KeyRangeUnionIterator.build(subIterators);
    }

    // Note: This method assumes that the selects method has already been called for the
    // key to avoid having to (potentially) call selects twice
    private ClusteringIndexFilter makeFilter(List<PrimaryKey> keys)
    {
        PrimaryKey firstKey = keys.get(0);

        assert cfs.metadata().comparator.size() == 0 && !firstKey.kind().hasClustering ||
               cfs.metadata().comparator.size() > 0 && firstKey.kind().hasClustering :
               "PrimaryKey " + firstKey + " clustering does not match table. There should be a clustering of size " + cfs.metadata().comparator.size();

        ClusteringIndexFilter clusteringIndexFilter = command.clusteringIndexFilter(firstKey.partitionKey());

        // If we have skinny partitions or the key is for a static row then we need to get the partition as
        // requested by the original query.
        if (cfs.metadata().comparator.size() == 0 || firstKey.kind() == PrimaryKey.Kind.STATIC)
        {
            return clusteringIndexFilter;
        }
        else
        {
            nextClusterings.clear();
            for (PrimaryKey key : keys)
                nextClusterings.add(key.clustering());
            return new ClusteringIndexNamesFilter(nextClusterings, clusteringIndexFilter.isReversed());
        }
    }

    /**
     * Returns the {@link DataRange} list covered by the specified {@link ReadCommand}.
     *
     * @param command a read command
     * @return the data ranges covered by {@code command}
     */
    private static List<DataRange> dataRanges(ReadCommand command)
    {
        if (command instanceof SinglePartitionReadCommand)
        {
            return Lists.newArrayList(command.dataRange());
        }
        else if (command instanceof PartitionRangeReadCommand)
        {
            return Lists.newArrayList(command.dataRange());
        }
        else
        {
            throw new AssertionError("Unsupported read command type: " + command.getClass().getName());
        }
    }
}
